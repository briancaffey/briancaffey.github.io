<!doctype html>
<html data-n-head-ssr lang="en" data-n-head="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>Rocket League BotChat powered by TensorRT-LLM: My submission for NVIDIA's Generative AI on RTX PCs Developer Contest</title><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="viewport" content="width=device-width,initial-scale=1"><meta data-n-head="ssr" data-hid="description" name="description" content="Brian Caffey's personal website"><meta data-n-head="ssr" name="robots" content="all"><meta data-n-head="ssr" property="twitter:creator" content="@briancaffey"><meta data-n-head="ssr" property="twitter:site" content="@briancaffey"><meta data-n-head="ssr" property="og:title" content="Rocket League BotChat powered by TensorRT-LLM: My submission for NVIDIA's Generative AI on RTX PCs Developer Contest"><meta data-n-head="ssr" property="og:description" content="This article discusses my entry for NVIDIA's Generative AI on RTX PCs Developer Contest: Rocket Leauge BotChat"><meta data-n-head="ssr" property="og:image" content="https://briancaffey.github.io/img/rlbc/cover.png"><meta data-n-head="ssr" property="twitter:image" content="https://briancaffey.github.io/img/rlbc/cover.png"><meta data-n-head="ssr" property="twitter:card" content="summary_large_image"><link data-n-head="ssr" rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" href="/_nuxt/8369139.js" as="script"><link rel="preload" href="/_nuxt/8bfa011.js" as="script"><link rel="preload" href="/_nuxt/b575c49.js" as="script"><link rel="preload" href="/_nuxt/691d3dd.js" as="script"><link rel="preload" href="/_nuxt/c259e4a.js" as="script"><style data-vue-ssr-id="38dfa7e4:0 f52d43e0:0 9592d830:0 517a8dd7:0 072b2f8a:0 fa7ff0ca:0 56b15182:0 507279a1:0 32d0cba6:0 a0fa61ae:0 68e9f29f:0 00a52ce3:0 23961490:0">/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}details{display:block}summary{display:list-item}[hidden],template{display:none}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}button{background-color:transparent;background-image:none}button:focus{outline:1px dotted;outline:5px auto -webkit-focus-ring-color}fieldset,ol,ul{margin:0;padding:0}ol,ul{list-style:none}html{font-family:system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Cantarell,Noto Sans,sans-serif,BlinkMacSystemFont,"Segoe UI","Helvetica Neue",Arial,"Noto Sans","Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,:after,:before{box-sizing:border-box;border:0 solid #e2e8f0}hr{border-top-width:1px}img{border-style:solid}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{color:#a0aec0}input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#a0aec0}input::placeholder,textarea::placeholder{color:#a0aec0}[role=button],button{cursor:pointer}table{border-collapse:collapse}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}button,input,optgroup,select,textarea{padding:0;line-height:inherit;color:inherit}code,kbd,pre,samp{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}.container{width:100%}@media (min-width:640px){.container{max-width:640px}}@media (min-width:768px){.container{max-width:768px}}@media (min-width:1024px){.container{max-width:1024px}}@media (min-width:1280px){.container{max-width:1280px}}.bg-black{--bg-opacity:1;background-color:#000;background-color:rgba(0,0,0,var(--bg-opacity))}.bg-white{--bg-opacity:1;background-color:#fff;background-color:rgba(255,255,255,var(--bg-opacity))}.bg-red-300{--bg-opacity:1;background-color:#feb2b2;background-color:rgba(254,178,178,var(--bg-opacity))}.bg-green-100{--bg-opacity:1;background-color:#f0fff4;background-color:rgba(240,255,244,var(--bg-opacity))}.border-white{--border-opacity:1;border-color:#fff;border-color:rgba(255,255,255,var(--border-opacity))}.rounded{border-radius:.25rem}.rounded-md{border-radius:.375rem}.rounded-lg{border-radius:.5rem}.rounded-full{border-radius:9999px}.rounded-t{border-top-left-radius:.25rem;border-top-right-radius:.25rem}.rounded-t-lg{border-top-left-radius:.5rem;border-top-right-radius:.5rem}.border{border-width:1px}.cursor-pointer{cursor:pointer}.block{display:block}.inline-block{display:inline-block}.inline{display:inline}.flex{display:flex}.table{display:table}.grid{display:grid}.contents{display:contents}.hidden{display:none}.flex-wrap{flex-wrap:wrap}.items-center{align-items:center}.justify-end{justify-content:flex-end}.justify-center{justify-content:center}.flex-1{flex:1 1 0%}.flex-grow{flex-grow:1}.flex-shrink{flex-shrink:1}.float-right{float:right}.font-bold{font-weight:700}.h-3{height:.75rem}.h-4{height:1rem}.h-12{height:3rem}.h-32{height:8rem}.h-64{height:16rem}.text-lg{font-size:1.125rem}.text-xl{font-size:1.25rem}.text-2xl{font-size:1.5rem}.text-3xl{font-size:1.875rem}.text-4xl{font-size:2.25rem}.leading-8{line-height:2rem}.leading-9{line-height:2.25rem}.m-2{margin:.5rem}.m-4{margin:1rem}.mx-1{margin-left:.25rem;margin-right:.25rem}.my-4{margin-top:1rem;margin-bottom:1rem}.mx-auto{margin-left:auto;margin-right:auto}.mt-1{margin-top:.25rem}.mb-1{margin-bottom:.25rem}.mt-2{margin-top:.5rem}.mt-4{margin-top:1rem}.mb-4{margin-bottom:1rem}.mt-8{margin-top:2rem}.mb-8{margin-bottom:2rem}.-ml-1{margin-left:-.25rem}.max-w-5xl{max-width:64rem}.max-w-6xl{max-width:72rem}.object-cover{-o-object-fit:cover;object-fit:cover}.p-2{padding:.5rem}.p-3{padding:.75rem}.p-4{padding:1rem}.py-1{padding-top:.25rem;padding-bottom:.25rem}.px-1{padding-left:.25rem;padding-right:.25rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.px-2{padding-left:.5rem;padding-right:.5rem}.py-3{padding-top:.75rem;padding-bottom:.75rem}.px-3{padding-left:.75rem;padding-right:.75rem}.py-4{padding-top:1rem;padding-bottom:1rem}.px-4{padding-left:1rem;padding-right:1rem}.py-8{padding-top:2rem;padding-bottom:2rem}.px-16{padding-left:4rem;padding-right:4rem}.py-32{padding-top:8rem;padding-bottom:8rem}.pt-2{padding-top:.5rem}.pb-2{padding-bottom:.5rem}.pt-4{padding-top:1rem}.pr-4{padding-right:1rem}.pb-4{padding-bottom:1rem}.pt-8{padding-top:2rem}.pb-8{padding-bottom:2rem}.pt-16{padding-top:4rem}.static{position:static}.fixed{position:fixed}.absolute{position:absolute}.relative{position:relative}.inset-0{top:0;right:0;bottom:0;left:0}.top-0{top:0}.right-0{right:0}.bottom-0{bottom:0}.left-0{left:0}.resize{resize:both}.shadow{box-shadow:0 1px 3px 0 rgba(0,0,0,.1),0 1px 2px 0 rgba(0,0,0,.06)}.shadow-md{box-shadow:0 4px 6px -1px rgba(0,0,0,.1),0 2px 4px -1px rgba(0,0,0,.06)}.fill-current{fill:currentColor}.text-left{text-align:left}.text-center{text-align:center}.text-right{text-align:right}.text-black{--text-opacity:1;color:#000;color:rgba(0,0,0,var(--text-opacity))}.text-white{--text-opacity:1;color:#fff;color:rgba(255,255,255,var(--text-opacity))}.text-gray-500{--text-opacity:1;color:#a0aec0;color:rgba(160,174,192,var(--text-opacity))}.text-gray-600{--text-opacity:1;color:#718096;color:rgba(113,128,150,var(--text-opacity))}.text-red-400{--text-opacity:1;color:#fc8181;color:rgba(252,129,129,var(--text-opacity))}.text-red-600{--text-opacity:1;color:#e53e3e;color:rgba(229,62,62,var(--text-opacity))}.uppercase{text-transform:uppercase}.visible{visibility:visible}.w-3{width:.75rem}.w-4{width:1rem}.w-12{width:3rem}.w-32{width:8rem}.w-full{width:100%}.z-10{z-index:10}.gap-4{grid-gap:1rem;gap:1rem}.gap-6{grid-gap:1.5rem;gap:1.5rem}.gap-16{grid-gap:4rem;gap:4rem}.grid-cols-1{grid-template-columns:repeat(1,minmax(0,1fr))}.grid-cols-4{grid-template-columns:repeat(4,minmax(0,1fr))}.grid-cols-5{grid-template-columns:repeat(5,minmax(0,1fr))}.transform{--transform-translate-x:0;--transform-translate-y:0;--transform-rotate:0;--transform-skew-x:0;--transform-skew-y:0;--transform-scale-x:1;--transform-scale-y:1;transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y))}.transition-all{transition-property:all}.transition{transition-property:background-color,border-color,color,fill,stroke,opacity,box-shadow,transform}.duration-150{transition-duration:.15s}.delay-150{transition-delay:.15s}@-webkit-keyframes spin{to{transform:rotate(1turn)}}@keyframes spin{to{transform:rotate(1turn)}}@-webkit-keyframes ping{75%,to{transform:scale(2);opacity:0}}@keyframes ping{75%,to{transform:scale(2);opacity:0}}@-webkit-keyframes pulse{50%{opacity:.5}}@keyframes pulse{50%{opacity:.5}}@-webkit-keyframes bounce{0%,to{transform:translateY(-25%);-webkit-animation-timing-function:cubic-bezier(.8,0,1,1);animation-timing-function:cubic-bezier(.8,0,1,1)}50%{transform:none;-webkit-animation-timing-function:cubic-bezier(0,0,.2,1);animation-timing-function:cubic-bezier(0,0,.2,1)}}@keyframes bounce{0%,to{transform:translateY(-25%);-webkit-animation-timing-function:cubic-bezier(.8,0,1,1);animation-timing-function:cubic-bezier(.8,0,1,1)}50%{transform:none;-webkit-animation-timing-function:cubic-bezier(0,0,.2,1);animation-timing-function:cubic-bezier(0,0,.2,1)}}@media (min-width:640px){.sm\:inline{display:inline}.sm\:hidden{display:none}.sm\:p-16{padding:4rem}.sm\:px-4{padding-left:1rem;padding-right:1rem}.sm\:py-16{padding-top:4rem;padding-bottom:4rem}.sm\:w-2\/3{width:66.666667%}.sm\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}}@media (min-width:768px){.md\:flex{display:flex}.md\:hidden{display:none}.md\:px-1{padding-left:.25rem;padding-right:.25rem}.md\:px-4{padding-left:1rem;padding-right:1rem}.md\:w-1\/2{width:50%}.md\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}.md\:grid-cols-3{grid-template-columns:repeat(3,minmax(0,1fr))}}@media (min-width:1024px){.lg\:px-16{padding-left:4rem;padding-right:4rem}.lg\:px-32{padding-left:8rem;padding-right:8rem}.lg\:pl-64{padding-left:16rem}.lg\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}}@media (min-width:1280px){.xl\:pb-16{padding-bottom:4rem}}:root{--color:#243746;--color-primary:#158876;--color-secondary:#0e2233;--bg:#f3f5f4;--bg-secondary:#fff;--bg-code:#ddd;--border-color:#ddd}.dark-mode{--color:#ebf4f1;--color-primary:#41b38a;--color-secondary:#fdf9f3;--bg:#091a28;--bg-secondary:#071521;--bg-code:#ddd;--border-color:#0d2538}.sepia-mode{--color:#433422;--color-primary:#504231;--color-secondary:#504231;--bg:#f1e7d0;--bg-code:#ddd;--bg-secondary:#eae0c9;--border-color:#ded0bf}body{font-family:Montserrat,Arial,Sans Serif;background-color:#f3f5f4;background-color:var(--bg);color:#243746;color:var(--color);transition:background-color .7s}a{color:#158876;color:var(--color-primary)}.py-05{padding-top:.125rem;padding-bottom:.125rem}.markdown{--text-opacity:1;color:#1a202c;color:rgba(26,32,44,var(--text-opacity));line-height:1.5;color:#0e2233;color:var(--color-secondary)}.markdown .token.operator{background:0 0}.markdown>*+*{margin-top:0;margin-bottom:1rem}.markdown li+li{margin-top:.25rem}.markdown li>p+p{margin-top:1.5rem;color:#158876;color:var(--color-primary)}.markdown img{margin:auto;margin-top:1.5rem;margin-bottom:1.5rem}.markdown a,.markdown strong{font-weight:600}.markdown strong a{font-weight:700}.markdown h1{font-size:2.25rem}.markdown h1,.markdown h2{border-color:#158876;border-color:var(--color-primary);line-height:1.25;border-bottom-width:1px;font-weight:600;margin-bottom:1rem;margin-top:1.5rem;padding-bottom:.5rem}.markdown h2{font-size:1.5rem}.markdown h3{line-height:1.375;font-size:1.125rem}.markdown h3,.markdown h4{border-color:#158876;border-color:var(--color-primary);font-weight:600;margin-bottom:1rem;margin-top:1.5rem}.markdown h4{line-height:1;font-size:1rem}.markdown h5{border-color:#158876;border-color:var(--color-primary)}.markdown h5,.markdown h6{line-height:1.25;font-size:.875rem;font-weight:600;margin-bottom:1rem;margin-top:1.5rem}.markdown blockquote,.markdown h6{--text-opacity:1;color:#718096;color:rgba(113,128,150,var(--text-opacity))}.markdown blockquote{font-size:1rem;border-left-width:4px;--border-opacity:1;border-color:#e2e8f0;border-color:rgba(226,232,240,var(--border-opacity));padding-left:1rem;padding-right:1rem;border-color:#158876;border-color:var(--color-primary)}.markdown code{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:.875rem;display:inline;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity));padding:.125rem .25rem;background-color:#ddd;background-color:var(--bg-code);color:#000}.markdown code,.markdown pre{--bg-opacity:1;border-radius:.25rem}.markdown pre{background-color:#f7fafc;background-color:rgba(247,250,252,var(--bg-opacity));padding:1rem}.markdown pre code{display:block;background-color:transparent;padding:0;overflow:visible;border-radius:0;color:#000}.markdown p{margin-bottom:10px}code[class*=language-],pre[class*=language-]{background:#ddd!important;background:var(--bg-code)!important;text-shadow:none!important}.markdown ul{list-style-type:disc}.markdown ol,.markdown ul{font-size:1rem;padding-left:2rem}.markdown ol{list-style-type:decimal}.markdown kbd{font-size:.75rem;display:inline-block;border-radius:.25rem;border-width:1px;padding:.125rem .25rem;vertical-align:middle;font-weight:400;font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;box-shadow:0 1px 3px 0 rgba(0,0,0,.1),0 1px 2px 0 rgba(0,0,0,.06)}.markdown table,td,th{font-size:1rem;border:1px solid #243746;border-color:var(--color)}.markdown table{overflow-x:scroll}.markdown td,.markdown th{border-width:1px;padding:.25rem .75rem}.markdown .highlight pre{--bg-opacity:1!important;background-color:#f7fafc!important;background-color:rgba(247,250,252,var(--bg-opacity))!important}.article-card{box-shadow:0 0 0 0 #0e2233;box-shadow:0 0 0 0 var(--color-secondary);transition:box-shadow .2s,transform .2s;height:100%}.article-card:hover{box-shadow:0 0 30px 2px #0e2233;box-shadow:0 0 30px 2px var(--color-secondary);transform:scale(1.025)}.blog-card-description,.blog-date{color:#0e2233;color:var(--color-secondary)}.blog-date{font-size:smaller}hr{background-color:#243746;background-color:var(--color);border:none;height:1px}.menu-icon{background-color:#ddd;background-color:var(--border-color)}.menu-icon,.mobile-menu{color:#243746;color:var(--color)}.mobile-menu{background-color:#fff;background-color:var(--bg-secondary)}.btn{border-radius:1;border-color:#158876;border-color:var(--color-primary)}.btn:hover{background-color:#fff;background-color:var(--bg-secondary)}.hero{border-color:#158876;border-color:var(--color-primary);color:#158876;color:var(--color-primary)}.markdown{word-wrap:break-word}.markdown h2:before,.markdown h3:before{content:" ";margin-top:-85px;pointer-events:none}.markdown h2>a,.markdown h3>a{margin-left:1.25rem}.markdown h2>a:before,.markdown h3>a:before{content:"#";font-weight:400;font-size:1.25rem;line-height:2rem;margin-left:-1.25rem;padding-right:.5rem;position:absolute;opacity:1}@media (min-width:1024px){.markdown h2>a,.markdown h3>a{margin-left:0}.markdown h2>a:before,.markdown h3>a:before{opacity:0}}.markdown h2:hover>a:before,.markdown h3:hover>a:before{opacity:1}& pre[class*=language-]{--bg-opacity:1;background-color:#2d3748;background-color:rgba(45,55,72,var(--bg-opacity));position:static}.mc{background-color:#f3f5f4;background-color:var(--bg);border-color:#158876;border-color:var(--color-primary);border-width:1px;color:#158876;color:var(--color-primary);justify-content:center;padding:5px 10px;border-radius:5px;width:100%}.mc-btn{color:#fff;color:var(--bg-secondary);background-color:#0e2233;background-color:var(--color-secondary);cursor:pointer}.page-enter-active,.page-leave-active{transition:filter 2s linear;transition:margin-top .15s,opacity .15s}.page-enter,.page-leave-to{opacity:0;margin-top:5px}code[class*=language-],pre[class*=language-]{color:#000;background:0 0;text-shadow:0 1px #fff;font-family:Consolas,Monaco,"Andale Mono","Ubuntu Mono",monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-] ::-moz-selection,code[class*=language-]::-moz-selection,pre[class*=language-] ::-moz-selection,pre[class*=language-]::-moz-selection{text-shadow:none;background:#b3d4fc}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{text-shadow:none;background:#b3d4fc}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto}:not(pre)>code[class*=language-],pre[class*=language-]{background:#f5f2f0}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#999}.token.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#905}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#690}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url{color:#9a6e3a;background:hsla(0,0%,100%,.5)}.token.atrule,.token.attr-value,.token.keyword{color:#07a}.token.class-name,.token.function{color:#dd4a68}.token.important,.token.regex,.token.variable{color:#e90}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.emoji-mart,.emoji-mart *{-webkit-box-sizing:border-box;box-sizing:border-box;line-height:1.15}.emoji-mart{font-family:-apple-system,BlinkMacSystemFont,"Helvetica Neue",sans-serif;font-size:16px;display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:vertical;-webkit-box-direction:normal;-ms-flex-direction:column;flex-direction:column;height:420px;color:#222427;border:1px solid #d9d9d9;border-radius:5px;background:#fff}.emoji-mart-emoji{padding:6px;border:none;background:0 0;-webkit-box-shadow:none;box-shadow:none}.emoji-mart-emoji span{display:inline-block}.emoji-mart-preview-emoji .emoji-mart-emoji span{width:38px;height:38px;font-size:32px}.emoji-type-native{font-family:"Segoe UI Emoji","Segoe UI Symbol","Segoe UI","Apple Color Emoji","Twemoji Mozilla","Noto Color Emoji","EmojiOne Color","Android Emoji";word-break:keep-all}.emoji-type-image{background-size:5700%}.emoji-type-image.emoji-set-apple{background-image:url(https://unpkg.com/emoji-datasource-apple@6.0.1/img/apple/sheets-256/64.png)}.emoji-type-image.emoji-set-facebook{background-image:url(https://unpkg.com/emoji-datasource-facebook@6.0.1/img/facebook/sheets-256/64.png)}.emoji-type-image.emoji-set-google{background-image:url(https://unpkg.com/emoji-datasource-google@6.0.1/img/google/sheets-256/64.png)}.emoji-type-image.emoji-set-twitter{background-image:url(https://unpkg.com/emoji-datasource-twitter@6.0.1/img/twitter/sheets-256/64.png)}.emoji-mart-bar{border:0 solid #d9d9d9}.emoji-mart-bar:first-child{border-bottom-width:1px;border-top-left-radius:5px;border-top-right-radius:5px}.emoji-mart-bar:last-child{border-top-width:1px;border-bottom-left-radius:5px;border-bottom-right-radius:5px}.emoji-mart-scroll{position:relative;overflow-y:scroll;-webkit-box-flex:1;-ms-flex:1;flex:1;padding:0 6px 6px;z-index:0;will-change:transform;-webkit-overflow-scrolling:touch}.emoji-mart-anchors{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-ms-flex-pack:justify;justify-content:space-between;padding:0 6px;color:#858585;line-height:0}.emoji-mart-anchor{position:relative;display:block;-webkit-box-flex:1;-ms-flex:1 1 auto;flex:1 1 auto;text-align:center;padding:12px 4px;overflow:hidden;-webkit-transition:color .1s ease-out;-o-transition:color .1s ease-out;transition:color .1s ease-out;border:none;background:0 0;-webkit-box-shadow:none;box-shadow:none}.emoji-mart-anchor-selected,.emoji-mart-anchor:hover{color:#464646}.emoji-mart-anchor-selected .emoji-mart-anchor-bar{bottom:0}.emoji-mart-anchor-bar{position:absolute;bottom:-3px;left:0;width:100%;height:3px;background-color:#464646}.emoji-mart-anchors i{display:inline-block;width:100%;max-width:22px}.emoji-mart-anchors svg{fill:currentColor;max-height:18px}.emoji-mart .scroller{height:250px;position:relative;-webkit-box-flex:1;-ms-flex:1;flex:1;padding:0 6px 6px;z-index:0;will-change:transform;-webkit-overflow-scrolling:touch}.emoji-mart-search{margin-top:6px;padding:0 6px}.emoji-mart-search input{font-size:16px;display:block;width:100%;padding:.2em .6em;border-radius:25px;border:1px solid #d9d9d9;outline:0}.emoji-mart-search-results{height:250px;overflow-y:scroll}.emoji-mart-category{position:relative}.emoji-mart-category .emoji-mart-emoji span{z-index:1;position:relative;text-align:center;cursor:default}.emoji-mart-category .emoji-mart-emoji:hover:before,.emoji-mart-emoji-selected:before{z-index:0;content:"";position:absolute;top:0;left:0;width:100%;height:100%;background-color:#f4f4f4;border-radius:100%;opacity:0;opacity:1}.emoji-mart-category-label{position:-webkit-sticky;position:sticky;top:0}.emoji-mart-static .emoji-mart-category-label{z-index:2;position:relative}.emoji-mart-category-label h3{display:block;font-size:16px;width:100%;font-weight:500;padding:5px 6px;background-color:#fff;background-color:hsla(0,0%,100%,.95)}.emoji-mart-emoji{position:relative;display:inline-block;font-size:0}.emoji-mart-no-results{font-size:14px;text-align:center;padding-top:70px;color:#858585}.emoji-mart-no-results .emoji-mart-category-label{display:none}.emoji-mart-no-results .emoji-mart-no-results-label{margin-top:.2em}.emoji-mart-no-results .emoji-mart-emoji:hover:before{content:none}.emoji-mart-preview{position:relative;height:70px}.emoji-mart-preview-data,.emoji-mart-preview-emoji,.emoji-mart-preview-skins{position:absolute;top:50%;-webkit-transform:translateY(-50%);-ms-transform:translateY(-50%);transform:translateY(-50%)}.emoji-mart-preview-emoji{left:12px}.emoji-mart-preview-data{left:68px;right:12px;word-break:break-all}.emoji-mart-preview-skins{right:30px;text-align:right}.emoji-mart-preview-name{font-size:14px}.emoji-mart-preview-shortname{font-size:12px;color:#888}.emoji-mart-preview-emoticon+.emoji-mart-preview-emoticon,.emoji-mart-preview-shortname+.emoji-mart-preview-emoticon,.emoji-mart-preview-shortname+.emoji-mart-preview-shortname{margin-left:.5em}.emoji-mart-preview-emoticon{font-size:11px;color:#bbb}.emoji-mart-title span{display:inline-block;vertical-align:middle}.emoji-mart-title .emoji-mart-emoji{padding:0}.emoji-mart-title-label{color:#999a9c;font-size:21px;font-weight:300}.emoji-mart-skin-swatches{font-size:0;padding:2px 0;border:1px solid #d9d9d9;border-radius:12px;background-color:#fff}.emoji-mart-skin-swatches-opened .emoji-mart-skin-swatch{width:16px;padding:0 2px}.emoji-mart-skin-swatches-opened .emoji-mart-skin-swatch-selected:after{opacity:.75}.emoji-mart-skin-swatch{display:inline-block;width:0;vertical-align:middle;-webkit-transition-property:width,padding;-o-transition-property:width,padding;transition-property:width,padding;-webkit-transition-duration:.125s;-o-transition-duration:.125s;transition-duration:.125s;-webkit-transition-timing-function:ease-out;-o-transition-timing-function:ease-out;transition-timing-function:ease-out}.emoji-mart-skin-swatch:first-child{-webkit-transition-delay:0s;-o-transition-delay:0s;transition-delay:0s}.emoji-mart-skin-swatch:nth-child(2){-webkit-transition-delay:.03s;-o-transition-delay:.03s;transition-delay:.03s}.emoji-mart-skin-swatch:nth-child(3){-webkit-transition-delay:.06s;-o-transition-delay:.06s;transition-delay:.06s}.emoji-mart-skin-swatch:nth-child(4){-webkit-transition-delay:.09s;-o-transition-delay:.09s;transition-delay:.09s}.emoji-mart-skin-swatch:nth-child(5){-webkit-transition-delay:.12s;-o-transition-delay:.12s;transition-delay:.12s}.emoji-mart-skin-swatch:nth-child(6){-webkit-transition-delay:.15s;-o-transition-delay:.15s;transition-delay:.15s}.emoji-mart-skin-swatch-selected{position:relative;width:16px;padding:0 2px}.emoji-mart-skin-swatch-selected:after{content:"";position:absolute;top:50%;left:50%;width:4px;height:4px;margin:-2px 0 0 -2px;background-color:#fff;border-radius:100%;pointer-events:none;opacity:0;-webkit-transition:opacity .2s ease-out;-o-transition:opacity .2s ease-out;transition:opacity .2s ease-out}.emoji-mart-skin{display:inline-block;width:100%;padding-top:100%;max-width:12px;border-radius:100%}.emoji-mart-skin-tone-1{background-color:#ffc93a}.emoji-mart-skin-tone-2{background-color:#fadcbc}.emoji-mart-skin-tone-3{background-color:#e0bb95}.emoji-mart-skin-tone-4{background-color:#bf8f68}.emoji-mart-skin-tone-5{background-color:#9b643d}.emoji-mart-skin-tone-6{background-color:#594539}.emoji-mart .vue-recycle-scroller{position:relative}.emoji-mart .vue-recycle-scroller.direction-vertical:not(.page-mode){overflow-y:auto}.emoji-mart .vue-recycle-scroller.direction-horizontal:not(.page-mode){overflow-x:auto}.emoji-mart .vue-recycle-scroller.direction-horizontal{display:-webkit-box;display:-ms-flexbox;display:flex}.emoji-mart .vue-recycle-scroller__slot{-webkit-box-flex:1;-ms-flex:auto 0 0px;flex:auto 0 0}.emoji-mart .vue-recycle-scroller__item-wrapper{-webkit-box-flex:1;-ms-flex:1;flex:1;-webkit-box-sizing:border-box;box-sizing:border-box;overflow:hidden;position:relative}.emoji-mart .vue-recycle-scroller.ready .vue-recycle-scroller__item-view{position:absolute;top:0;left:0;will-change:transform}.emoji-mart .vue-recycle-scroller.direction-vertical .vue-recycle-scroller__item-wrapper{width:100%}.emoji-mart .vue-recycle-scroller.direction-horizontal .vue-recycle-scroller__item-wrapper{height:100%}.emoji-mart .vue-recycle-scroller.ready.direction-vertical .vue-recycle-scroller__item-view{width:100%}.emoji-mart .vue-recycle-scroller.ready.direction-horizontal .vue-recycle-scroller__item-view{height:100%}.emoji-mart .resize-observer[data-v-b329ee4c]{border:none;background-color:transparent;opacity:0}.emoji-mart .resize-observer[data-v-b329ee4c],.emoji-mart .resize-observer[data-v-b329ee4c] object{position:absolute;top:0;left:0;z-index:-1;width:100%;height:100%;pointer-events:none;display:block;overflow:hidden}.emoji-mart-search .hidden{display:none;visibility:hidden}.nuxt-progress{position:fixed;top:0;left:0;right:0;height:2px;width:0;opacity:1;transition:width .1s,opacity .4s;background-color:#000;z-index:999999}.nuxt-progress.nuxt-progress-notransition{transition:none}.nuxt-progress-failed{background-color:red}html{font-family:Montserrat,Arial,Sans Serif;font-size:16px;word-spacing:1px;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;box-sizing:border-box}*,:after,:before{box-sizing:border-box;margin:0}.button--green{display:inline-block;border-radius:4px;border:1px solid #3b8070;color:#3b8070;text-decoration:none;padding:10px 30px}.button--green:hover{color:#fff;background-color:#3b8070}.button--grey{display:inline-block;border-radius:4px;border:1px solid #35495e;color:#35495e;text-decoration:none;padding:10px 30px;margin-left:15px}.button--grey:hover{color:#fff;background-color:#35495e}span.emoji-mart-emoji[data-v-913fe8d6]{padding:0}.selected[data-v-913fe8d6]{text-shadow:.25px 0 0 #000}.picker[data-v-913fe8d6]{position:absolute;top:10px;margin-left:auto;margin-right:auto;transform:translate(50%,50%)}.top[data-v-913fe8d6]{width:100%;background-color:var(--color-primary);height:3px}.selected[data-v-4365f19e]{text-shadow:.9px 0 0}span.emoji-mart-emoji[data-v-288717a6]{padding:0;transition:transform .2s}span.emoji-mart-emoji[data-v-288717a6]:hover{transform:scale(1.3)}.centered[data-v-288717a6]{position:absolute;left:50vw;right:50vw;margin-left:auto;margin-right:auto}span.emoji-mart-emoji[data-v-40f34933]{padding:0;transition:transform .2s}span.emoji-mart-emoji[data-v-40f34933]:hover{transform:scale(1.3)}.modal[data-v-40f34933]{z-index:100000000;top:0;-webkit-backdrop-filter:blur(.4px);backdrop-filter:blur(.4px);background-color:rgba(0,0,0,.2)}.modal[data-v-40f34933],.picker[data-v-40f34933]{position:absolute;left:0}.picker[data-v-40f34933]{z-index:10000000000;right:0;margin-left:auto;margin-right:auto}.tag[data-v-d8ade784]{background-color:var(--color-primary);transition:transform .2s}.tag[data-v-d8ade784]:hover{transform:scale(1.05)}</style><link rel="preload" href="/_nuxt/static/1708308010/zh/2024/02/17/rocket-league-botchat-nvidia-generative-ai-on-rtx-pcs-developer-contest/state.js" as="script"><link rel="preload" href="/_nuxt/static/1708308010/zh/2024/02/17/rocket-league-botchat-nvidia-generative-ai-on-rtx-pcs-developer-contest/payload.js" as="script"><link rel="preload" href="/_nuxt/static/1708308010/manifest.js" as="script">
  </head>
  <body>
    <script data-n-head="ssr" data-hid="nuxt-color-mode-script" data-pbody="true">!function(){"use strict";var t=window,r=document,s=r.documentElement,n=["dark","light"],e=function(){for(var e="nuxt-color-mode=",t=r.cookie.split(";"),s=0;s<t.length;s++){for(var n=t[s];" "===n.charAt(0);)n=n.substring(1,n.length);if(0===n.indexOf(e))return n.substring(e.length,n.length)}return null}()||"system",a="system"===e?l():e;function c(e){e+="-mode";s.classList?s.classList.add(e):s.className+=" "+e}function o(e){return t.matchMedia("(prefers-color-scheme"+e+")")}function l(){if(t.matchMedia&&"not all"!==o("").media)for(var e of n)if(o(":"+e).matches)return e;return"light"}c(a),t.__NUXT_COLOR_MODE__={preference:e,value:a,getColorScheme:l,addClass:c,removeClass:function(e){e+="-mode";s.classList?s.classList.remove(e):s.className=s.className.replace(new RegExp(e,"g"),"")}}}()</script><div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div><div data-v-913fe8d6><div class="mx-auto flex py-2 px-2 sm:px-4 items-center max-w-6xl justify-center" data-v-913fe8d6><div class="justify-left flex-grow flex-cols-4" data-v-913fe8d6><a href="/zh" class="text-xl nuxt-link-active" data-v-913fe8d6><span class="hidden sm:inline text-2xl" data-v-913fe8d6>布莱恩</span><span class="inline sm:hidden" data-v-913fe8d6>JBC</span></a></div> <div class="flex-grow relative" data-v-913fe8d6><nav z-index="10000" data-v-4365f19e data-v-913fe8d6><div data-v-4365f19e><ul class="items-right float-right hidden md:flex" data-v-4365f19e><li class="px-4 text-lg" data-v-4365f19e><a href="/zh/blog/1" data-v-4365f19e>
          博客
        </a></li> <li class="px-4 text-lg" data-v-4365f19e><a href="/zh/contact" data-v-4365f19e>
          联系
        </a></li></ul> <div class="flex justify-end md:hidden z-1000" data-v-4365f19e><button class="flex items-center px-3 py-2 border rounded menu-icon" data-v-4365f19e><svg viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg" class="fill-current h-3 w-3" data-v-4365f19e><title data-v-4365f19e>Menu</title> <path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0v-2z" data-v-4365f19e></path></svg></button></div> <!----></div></nav></div></div> <div class="picker" data-v-913fe8d6><div class="centered" data-v-288717a6 data-v-913fe8d6><div class="grid items-center justify-center" data-v-288717a6><ul class="flex px-4" data-v-288717a6><li class="md:px-1 px-1 cursor-pointer" data-v-288717a6><span aria-label="🖥️, desktop_computer" class="emoji-mart-emoji" data-v-288717a6><span class="emoji-set-apple emoji-type-image" style="background-position:52.63% 12.28%;width:32px;height:32px"></span></span></li><li class="md:px-1 px-1 cursor-pointer" data-v-288717a6><span aria-label="🌞, sun_with_face" class="emoji-mart-emoji" data-v-288717a6><span class="emoji-set-apple emoji-type-image" style="background-position:8.77% 77.19%;width:32px;height:32px"></span></span></li><li class="md:px-1 px-1 cursor-pointer" data-v-288717a6><span aria-label="🌚, new_moon_with_face" class="emoji-mart-emoji" data-v-288717a6><span class="emoji-set-apple emoji-type-image" style="background-position:8.77% 70.18%;width:32px;height:32px"></span></span></li><li class="md:px-1 px-1 cursor-pointer" data-v-288717a6><span aria-label="☕, coffee" class="emoji-mart-emoji" data-v-288717a6><span class="emoji-set-apple emoji-type-image" style="background-position:94.74% 8.77%;width:32px;height:32px"></span></span></li> <li class="md:px-1 px-1 cursor-pointer" data-v-288717a6><div data-v-40f34933 data-v-288717a6><!----> <ul data-v-40f34933><li class="md:px-1 px-1 cursor-pointer" data-v-40f34933><span aria-label="🇨🇳, cn, flag-cn" class="emoji-mart-emoji" data-v-40f34933><span class="emoji-set-apple emoji-type-image" style="background-position:1.75% 36.84%;width:32px;height:32px"></span></span></li></ul> <div class="rounded-md z-10 picker" data-v-40f34933><div class="bg-white shadow-md rounded px-4 py-2 w-32 text" style="display:none" data-v-40f34933><a href="/2024/02/17/rocket-league-botchat-nvidia-generative-ai-on-rtx-pcs-developer-contest" data-v-40f34933><span aria-label="🇺🇸, us, flag-us" class="emoji-mart-emoji" data-v-40f34933><span class="emoji-set-apple emoji-type-image" style="background-position:7.02% 68.42%;width:16px;height:16px"></span></span> English <br data-v-40f34933></a><a href="/fr/2024/02/17/rocket-league-botchat-nvidia-generative-ai-on-rtx-pcs-developer-contest" data-v-40f34933><span aria-label="🇫🇷, fr, flag-fr" class="emoji-mart-emoji" data-v-40f34933><span class="emoji-set-apple emoji-type-image" style="background-position:1.75% 91.23%;width:16px;height:16px"></span></span> Français <br data-v-40f34933></a><a href="/zh/2024/02/17/rocket-league-botchat-nvidia-generative-ai-on-rtx-pcs-developer-contest" aria-current="page" class="nuxt-link-exact-active nuxt-link-active" data-v-40f34933><span aria-label="🇨🇳, cn, flag-cn" class="emoji-mart-emoji" data-v-40f34933><span class="emoji-set-apple emoji-type-image" style="background-position:1.75% 36.84%;width:16px;height:16px"></span></span> 简体中文 <br data-v-40f34933></a><a href="/ru/2024/02/17/rocket-league-botchat-nvidia-generative-ai-on-rtx-pcs-developer-contest" data-v-40f34933><span aria-label="🇷🇺, ru, flag-ru" class="emoji-mart-emoji" data-v-40f34933><span class="emoji-set-apple emoji-type-image" style="background-position:5.26% 92.98%;width:16px;height:16px"></span></span> Русский <br data-v-40f34933></a><a href="/jp/2024/02/17/rocket-league-botchat-nvidia-generative-ai-on-rtx-pcs-developer-contest" data-v-40f34933><span aria-label="🇯🇵, jp, flag-jp" class="emoji-mart-emoji" data-v-40f34933><span class="emoji-set-apple emoji-type-image" style="background-position:3.51% 59.65%;width:16px;height:16px"></span></span> 日本語 <br data-v-40f34933></a><a href="/in/2024/02/17/rocket-league-botchat-nvidia-generative-ai-on-rtx-pcs-developer-contest" data-v-40f34933><span aria-label="🇮🇳, flag-in" class="emoji-mart-emoji" data-v-40f34933><span class="emoji-set-apple emoji-type-image" style="background-position:3.51% 43.86%;width:16px;height:16px"></span></span> हिंदी <br data-v-40f34933></a></div></div></div></li></ul></div></div></div></div> <article data-v-142b09b6><img src="/img/rlbc/cover.png" class="pt-2 w-full object-cover cover-image" style="height:32rem" data-v-142b09b6> <div class="mx-auto max-w-5xl px-2 sm:px-4 md:px-4 lg:px-16 mt-2" data-v-142b09b6><h1 class="prose text-4xl leading-9 py-4 font-bold" data-v-142b09b6>
      Rocket League BotChat powered by TensorRT-LLM: My submission for NVIDIA's Generative AI on RTX PCs Developer Contest
    </h1> <div class="flex flex-wrap -ml-1 py-2" data-v-21780fb6 data-v-142b09b6><a href="/zh/blog/tags/nvidia" data-v-d8ade784 data-v-21780fb6><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-d8ade784>
    nvidia 🏷️
    <!----></div></a><a href="/zh/blog/tags/rtx" data-v-d8ade784 data-v-21780fb6><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-d8ade784>
    rtx 🏷️
    <!----></div></a><a href="/zh/blog/tags/gpu" data-v-d8ade784 data-v-21780fb6><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-d8ade784>
    gpu 🏷️
    <!----></div></a><a href="/zh/blog/tags/tensorrt-llm" data-v-d8ade784 data-v-21780fb6><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-d8ade784>
    tensorrt-llm 🏷️
    <!----></div></a><a href="/zh/blog/tags/ai" data-v-d8ade784 data-v-21780fb6><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-d8ade784>
    ai 🏷️
    <!----></div></a><a href="/zh/blog/tags/llm" data-v-d8ade784 data-v-21780fb6><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-d8ade784>
    llm 🏷️
    <!----></div></a><a href="/zh/blog/tags/llama" data-v-d8ade784 data-v-21780fb6><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-d8ade784>
    llama 🏷️
    <!----></div></a><a href="/zh/blog/tags/rocket-league" data-v-d8ade784 data-v-21780fb6><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-d8ade784>
    rocket-league 🏷️
    <!----></div></a><a href="/zh/blog/tags/gaming" data-v-d8ade784 data-v-21780fb6><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-d8ade784>
    gaming 🏷️
    <!----></div></a><a href="/zh/blog/tags/windows" data-v-d8ade784 data-v-21780fb6><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-d8ade784>
    windows 🏷️
    <!----></div></a></div> <div class="flex py-2" data-v-23cbc744 data-v-142b09b6><div class="pr-4 rounded" data-v-86c576ca data-v-23cbc744><a href="https://twitter.com/briancaffey/status/1759265152275292644" data-v-86c576ca><img src="/icons/x.png" alt="https://twitter.com/briancaffey/status/1759265152275292644" width="25" class="rounded" data-v-86c576ca></a></div><div class="pr-4 rounded" data-v-86c576ca data-v-23cbc744><a href="https://www.reddit.com/r/RocketLeague/comments/1au0po3/rocket_league_botchat_an_llmpowered_bakkesmod/" data-v-86c576ca><img src="/icons/reddit.png" alt="https://www.reddit.com/r/RocketLeague/comments/1au0po3/rocket_league_botchat_an_llmpowered_bakkesmod/" width="25" class="rounded" data-v-86c576ca></a></div></div> <p class="blog-date text-gray-500 mb-4" data-v-142b09b6>
      更新日期
      2024年2月17日
    </p> <!----> <div class="markdown nuxt-content" data-v-142b09b6 data-v-142b09b6><h2 id="tldr" data-v-142b09b6 data-v-142b09b6><a href="#tldr" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>tl;dr</h2>
<p data-v-142b09b6 data-v-142b09b6>This article is about my submission to NVIDIA's Generative AI on RTX PCs Developer Contest: Rocket League BotChat. Rocket League BotChat is a BakkesMod plugin for Rocket League that allows bots to send chat messages based on in-game events. It is designed to be used with a local LLM service optimized and accelerated with NVIDIA's TensorRT-LLM library.</p>
<p data-v-142b09b6 data-v-142b09b6>Here's my project submission post on 𝕏:</p>
<blockquote class="twitter-tweet tw-align-center" data-theme="dark" data-v-142b09b6 data-v-142b09b6><p lang="en" dir="ltr" data-v-142b09b6 data-v-142b09b6>Rocket League BotChat - powered by TensorRT-LLM<br data-v-142b09b6 data-v-142b09b6>⚽️🚗⚡️🤖💬<br data-v-142b09b6 data-v-142b09b6>My submission for NVIDIA's Gen AI on RTX PCs Developer Contest<a href="https://twitter.com/NVIDIAAIDev?ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>@NVIDIAAIDev</a> <a href="https://twitter.com/hashtag/RocketLeague?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#RocketLeague</a> <a href="https://twitter.com/hashtag/GTC24?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#GTC24</a> <a href="https://twitter.com/hashtag/NVIDIA?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#NVIDIA</a> <a href="https://twitter.com/hashtag/LLM?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#LLM</a> <a href="https://twitter.com/hashtag/Llama?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#Llama</a> <a href="https://twitter.com/hashtag/AI?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#AI</a> <a href="https://twitter.com/hashtag/Windows11?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#Windows11</a> <a href="https://t.co/A7ON3lyTC6" data-v-142b09b6 data-v-142b09b6>pic.twitter.com/A7ON3lyTC6</a></p>— Brian Caffey (@briancaffey) <a href="https://twitter.com/briancaffey/status/1759265152275292644?ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>February 18, 2024</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8" data-v-142b09b6 data-v-142b09b6></script>
<p data-v-142b09b6 data-v-142b09b6>Here's a link to the <a href="https://github.com/briancaffey/RocketLeagueBotChat" rel="nofollow noopener noreferrer" target="_blank" data-v-142b09b6 data-v-142b09b6>Rocket League BotChat GitHub repository</a>.</p>
<h2 id="nvidias-gen-ai-developer-contest" data-v-142b09b6 data-v-142b09b6><a href="#nvidias-gen-ai-developer-contest" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>NVIDIA's Gen AI Developer Contest</h2>
<p data-v-142b09b6 data-v-142b09b6>The following email caught my attention last month:</p>
<blockquote data-v-142b09b6 data-v-142b09b6>
<p data-v-142b09b6 data-v-142b09b6>Generative AI on RTX PCs Developer Contest: Build your next innovative Gen AI project using NVIDIA TensorRT or TensorRT-LLM on Windows PC with NVIDIA RTX systems</p>
</blockquote>
<p data-v-142b09b6 data-v-142b09b6>The part about “on Windows PC” made me think: why would a developer contest focus on a particular operating system? I use all three of the major operating systems: macOS, Ubuntu and Windows 11, but most of the development work I do is on macOS and Ubuntu. I discovered WSL (Windows Subsystem for Linux) a few years ago and really enjoy using that for development as well, but I had never considered doing development work on Windows outside of WSL. I had also never used any of the Windows-specific development frameworks like .NET or Visual Studio.</p>
<p data-v-142b09b6 data-v-142b09b6>My experience with Windows goes back to 2016 when I built my fist PC with an NVIDIA GeForce GTX 1080 graphics card. When I built another personal computer last year in 2023, getting the NVIDIA GeForce RTX 4090 graphics card was a big step up. I bought two NVMe drives in order to dual boot into both Windows and Ubuntu operating systems. Switching between the operating systems requires turning off the computer, going into the BIOS settings and changing the boot order and restarting the computer.</p>
<p data-v-142b09b6 data-v-142b09b6>Last year I started learning more about AI image generation using Stable Diffusion with programs like Automatic1111, InvokeAI and ComfyUI. I set up everything on my PC's Ubuntu operating system, and frequently had to switch between using Ubuntu for working with stable diffusion and Windows for gaming and other Windows-specific software. The friction of having to constantly switch operating systems pushed me to move my stable diffusion software workflows to Windows. All of my models and images are stored to external drives, so moving things over to Windows was pretty easy.</p>
<p data-v-142b09b6 data-v-142b09b6>I learned PowerShell and got more familiar with how Windows works as a development machine. Environment variables and system variables are one example of how Windows does things differently compared ot Linux-based operating systems. And just like that, I became a Windows developer! This experience got me interested in coming up with an idea for the NVIDIA Generative AI on NVIDIA RTX PCs Developer Contest.</p>
<p data-v-142b09b6 data-v-142b09b6><img alt="Windows winfetch screenshot" src="/img/rlbc/winfetch.png" data-v-142b09b6 data-v-142b09b6></p>
<h2 id="coming-up-with-an-idea" data-v-142b09b6 data-v-142b09b6><a href="#coming-up-with-an-idea" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Coming up with an Idea</h2>
<p data-v-142b09b6 data-v-142b09b6>The contest description and some related NVIDIA articles about the contest helped me with brainstorming:</p>
<blockquote data-v-142b09b6 data-v-142b09b6>
<p data-v-142b09b6 data-v-142b09b6>Whether it’s a RAG-based chatbot, a plug-in for an existing application, or a code generation tool, the possibilities are endless.</p>
</blockquote>
<blockquote data-v-142b09b6 data-v-142b09b6>
<p data-v-142b09b6 data-v-142b09b6>Many use cases would benefit from running LLMs locally on Windows PCs, including gaming, creativity, productivity, and developer experiences.</p>
</blockquote>
<p data-v-142b09b6 data-v-142b09b6>This contest is focused on NVIDIA's consumer hardware line: GeForce RTX. It has a diverse set of use cases including gaming, crypto mining, VR, simulation software, creative tools and new AI techniques including image generation and LLM (Large Language Model) inference.</p>
<p data-v-142b09b6 data-v-142b09b6><img alt="A stacked bar chart showing the composition of Nvidia's revenue each quarter going back to fiscal 2019." src="https://g.foolcdn.com/image/?url=https%3A%2F%2Fg.foolcdn.com%2Feditorial%2Fimages%2F764886%2Fnvda_revenue_bar.png&op=resize&w=700" data-v-142b09b6 data-v-142b09b6></p>
<p data-v-142b09b6 data-v-142b09b6>Gaming seemed like an interesting avenue for me to explore. PC gaming is still an industry that is developed primarily for Windows operating systems, and the gaming industry has been the largest revenue driver of NVIDIA in recent years, only recently surpassed by the data center segment. GPUs are needed to render graphics of enormous open-world environments. Some story-driven games include huge amounts of dialogue that can be considered as huge literary works in their own right. Red Dead Redemption and Genshin Impact are two massively popular games of this type. There might be an interesting project idea that could use LLMs and RAG (retrieval augmented generation), but I don't play these types of games and it didn't seem practical for a project that would be built in just over a month. I thought about trying to build something for a simpler game that I already know.</p>
<p data-v-142b09b6 data-v-142b09b6>Rocket League is a vehicular soccer game that is played on both game consoles and on PCs. It is an eSports with a very high skill ceiling and a massive player base (85 million active players in the last 30 days). I started playing it during the pandemic with some of my friends and all got hooked. We also came to learn that Rocket League's in-game is varies from entertaining, annoying, toxic and in some cases, sportsmanlike.</p>
<p data-v-142b09b6 data-v-142b09b6>One other thing I learned about Rocket League is that it has an active modding community. Developers create plugins for the game for all different purposes, such as coaching, practice drills, capturing replays, tracking player statistics, etc. Most Rocket League Mods are written in a popular framework called Bakkesmod (developed Andreas "bakkes" Bakke, a Norwegian software engineer). Rocket League's in-game chat inspired the idea for my submission to NVIDIA's Generative AI Developer Contest: Rocket League BotChat. The idea for my project is to build a plugin with Bakkesmod that allows Rocket League bots to send chat messages based on game events using an LLM accelerated and optimized by TensorRT-LLM (more on TensorRT-LLM soon!)</p>
<p data-v-142b09b6 data-v-142b09b6>Bots are built into the Rocket League game and you can play with or against them in offline matches. However, the built-in bots are not very good. Another 3rd-party project called RLBot allows players to play against community-developed AI bots that are developed with machine learning frameworks like TensorFlow and PyTorch. These bots are very good, but they are not infallible. My contest project idea was now clear: develop a plugin for Rocket League capable of sending messages from bot players. This idea seemed to check the boxes for the large language model category of NVIDIA's developer contest: develop a project in a Windows environment for a Windows-specific program, and use an LLM powered by TensorRT-LLM.</p>
<p data-v-142b09b6 data-v-142b09b6><img alt="RLBot Ascii Art" src="/img/rlbc/bot.png" data-v-142b09b6 data-v-142b09b6></p>
<h2 id="putting-together-the-puzzle-pieces" data-v-142b09b6 data-v-142b09b6><a href="#putting-together-the-puzzle-pieces" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Putting together the puzzle pieces</h2>
<p data-v-142b09b6 data-v-142b09b6>With this idea in mind, I looked into the project's feasibility. I really had no idea if this would work. I looked through the Bakkesmod documentation and found some helpful resources that gave me confidence that I could pull something together for at least a proof-of-concept.</p>
<ul data-v-142b09b6 data-v-142b09b6>
<li data-v-142b09b6 data-v-142b09b6>The Bakkesmod Plugin Wiki <a href="https://wiki.bakkesplugins.com/" rel="nofollow noopener noreferrer" target="_blank" data-v-142b09b6 data-v-142b09b6>https://wiki.bakkesplugins.com/</a>
<ul data-v-142b09b6 data-v-142b09b6>
<li data-v-142b09b6 data-v-142b09b6><a href="https://wiki.bakkesplugins.com/code_snippets/using_http_wrapper/" rel="nofollow noopener noreferrer" target="_blank" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6>HttpWrapper</code></a> for sending HTTP requests from Bakkesmod</li>
<li data-v-142b09b6 data-v-142b09b6><a href="https://wiki.bakkesplugins.com/functions/stat_events/" rel="nofollow noopener noreferrer" target="_blank" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6>StatEvents</code></a> that allow for running custom code when specific event functions are triggered in the game (such as scoring a goal, or making a save).</li>
</ul>
</li>
<li data-v-142b09b6 data-v-142b09b6>The Bakkesmod plugin template: <a href="https://github.com/Martinii89/BakkesmodPluginTemplate" rel="nofollow noopener noreferrer" target="_blank" data-v-142b09b6 data-v-142b09b6>https://github.com/Martinii89/BakkesmodPluginTemplate</a>
<ul data-v-142b09b6 data-v-142b09b6>
<li data-v-142b09b6 data-v-142b09b6>This provides a great starting-off point for developing Bakkesmod plugins. Plugins for Bakkesmod are written in C++ and this repo provides an organized file structure that allows your to get started quickly</li>
</ul>
</li>
<li data-v-142b09b6 data-v-142b09b6>Plugin Tutorial: <a href="https://wiki.bakkesplugins.com/plugin_tutorial/getting_started/" rel="nofollow noopener noreferrer" target="_blank" data-v-142b09b6 data-v-142b09b6>https://wiki.bakkesplugins.com/plugin_tutorial/getting_started/</a></li>
<li data-v-142b09b6 data-v-142b09b6>Open-source chat-related Bakkesmod plugins on GitHub
<ul data-v-142b09b6 data-v-142b09b6>
<li data-v-142b09b6 data-v-142b09b6>BetterChat: <a href="https://github.com/JulienML/BetterChat" rel="nofollow noopener noreferrer" target="_blank" data-v-142b09b6 data-v-142b09b6>https://github.com/JulienML/BetterChat</a></li>
<li data-v-142b09b6 data-v-142b09b6>Translate: <a href="https://github.com/0xleft/trnslt" rel="nofollow noopener noreferrer" target="_blank" data-v-142b09b6 data-v-142b09b6>https://github.com/0xleft/trnslt</a></li>
</ul>
</li>
</ul>
<p data-v-142b09b6 data-v-142b09b6>Starting with the Plugin Template, I wrote a simple console command that when triggered sends an HTTP request to <code data-v-142b09b6 data-v-142b09b6>localhost:8000/hello</code>. I set up a Hello World Flask app running on <code data-v-142b09b6 data-v-142b09b6>localhost:8000</code> and I was able to get a response from my Hello World server! There didn't seem to be any network or permission errors that would prevent my game code from communicating with other applications on my PC.</p>
<p data-v-142b09b6 data-v-142b09b6>Next I started looking into how to build and run optimized LLMs with NVIDIA's TensorRT-LLM library, the software that this contest is promoting. The contest announcement included an interesting building block that I thought could be very useful: an example repo showing how to run <code data-v-142b09b6 data-v-142b09b6>CodeLlama-13b-instruct-hf</code> optimized by TensorRT-LLM to provide inference for a VSCode extension called Continue (Continue.dev).</p>
<ul data-v-142b09b6 data-v-142b09b6>
<li data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6>CodeLlama-13b-instruct-hf</code> is an open source model from Meta that is trained on code and can help with code generation tasks</li>
<li data-v-142b09b6 data-v-142b09b6>TensorRT-LLM is a Python library that accelerates and optimizes inference performance of large language models. It takes a Large Language Model like <code data-v-142b09b6 data-v-142b09b6>CodeLlama-13b-instruct-hf</code> and generates an engine that can be used for doing inference</li>
<li data-v-142b09b6 data-v-142b09b6>VSCode is an open source code editor developed by Microsoft with an large number of community plugins</li>
<li data-v-142b09b6 data-v-142b09b6>Continue.dev is a startup backed by Y Combinator that is developing an open-source autopilot (code assistant) for VSCode and JetBrains that works with local LLMs or paid services like ChatGPT</li>
</ul>
<p data-v-142b09b6 data-v-142b09b6>To get the coding assistant project working I needed to build the TensorRT-LLM engine. Building TensorRT-LLM engines on Windows can be done in one of two ways:</p>
<ul data-v-142b09b6 data-v-142b09b6>
<li data-v-142b09b6 data-v-142b09b6>using a "bare-metal" virtual environment on Windows (with PowerShell)</li>
<li data-v-142b09b6 data-v-142b09b6>using WSL</li>
</ul>
<p data-v-142b09b6 data-v-142b09b6>At the time of writing, building a TensorRT-LLM engine on Windows can only be done with version <code data-v-142b09b6 data-v-142b09b6>v0.6.1</code> of the TensorRT-LLM repo and version <code data-v-142b09b6 data-v-142b09b6>v0.7.1</code> of the <code data-v-142b09b6 data-v-142b09b6>tensorrt_llm</code> Python package.</p>
<p data-v-142b09b6 data-v-142b09b6>With WSL you can use the up-to-date versions of the TensorRT-LLM repo (main branch). The engines produced by Windows and WSL (Ubuntu) are not interchangeable and you will get errors if you try to use an engine created with one operating system on another operating system.</p>
<p data-v-142b09b6 data-v-142b09b6>Once the engines are built you can use them to run the example from the <code data-v-142b09b6 data-v-142b09b6>trt-llm-as-openai-windows</code> repo.</p>
<p data-v-142b09b6 data-v-142b09b6>The example repo exposes an OpenAI-compatible API locally that can do chat completions. You then need to configure the Continue.dev extension to use the local LLM service:</p>
<div class="nuxt-content-highlight" data-v-142b09b6 data-v-142b09b6><pre class="line-numbers language-json" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>{</span>
  <span class="token property" data-v-142b09b6 data-v-142b09b6>"title"</span><span class="token operator" data-v-142b09b6 data-v-142b09b6>:</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"CodeLlama-13b-instruct-hf"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span>
  <span class="token property" data-v-142b09b6 data-v-142b09b6>"apiBase"</span><span class="token operator" data-v-142b09b6 data-v-142b09b6>:</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"http://192.168.5.96:5000/"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span>
  <span class="token property" data-v-142b09b6 data-v-142b09b6>"provider"</span><span class="token operator" data-v-142b09b6 data-v-142b09b6>:</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"openai"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span>
  <span class="token property" data-v-142b09b6 data-v-142b09b6>"apiKey"</span><span class="token operator" data-v-142b09b6 data-v-142b09b6>:</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"None"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span>
  <span class="token property" data-v-142b09b6 data-v-142b09b6>"model"</span><span class="token operator" data-v-142b09b6 data-v-142b09b6>:</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"gpt-4"</span>
<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>}</span>
</code></pre></div>
<p data-v-142b09b6 data-v-142b09b6>The Continue.dev extension using <code data-v-142b09b6 data-v-142b09b6>CodeLlama-13b-instruct-hf</code> accelerated and optimized by TensorRT-LLM is very fast. According to <a href="https://blog.continue.dev/programming-languages/" rel="nofollow noopener noreferrer" target="_blank" data-v-142b09b6 data-v-142b09b6>this post on Continue.dev's blog</a>, C++ is a "first tier" language:</p>
<blockquote data-v-142b09b6 data-v-142b09b6>
<p data-v-142b09b6 data-v-142b09b6>C++ has one of the largest presences on GitHub and Stack Overflow. This shows up in its representation in public LLM datasets, where it is one of the languages with the most data. Its performance is near the top of the MultiPL-E, BabelCode / TP3, MBXP / Multilingual HumanEval, and HumanEval-X benchmarks. However, given that C++ is often used when code performance and exact algorithm implementation is very important, many developers don’t believe that LLMs are as helpful for C++ as some of the other languages in this tier.</p>
</blockquote>
<p data-v-142b09b6 data-v-142b09b6>Most of the time I'm working with either Python and TypeScript. I've read about C++ but haven't used it for anything before doing this project. I primarily used Microsoft Visual Studio to build the plugin, but VSCode with the Continue.dev autopilot extension was helpful for tackling smaller problems in a REPL-like environment. For example, I used Continue.dev in VSCode to figure out how to handle JSON. Coming from Python and JavaScript languages, I found the <code data-v-142b09b6 data-v-142b09b6>nlohmann/json</code> JSON library syntax to be somewhat different. For example, here is how to add a message to <code data-v-142b09b6 data-v-142b09b6>messages</code> in the body of an OpenAI API request:</p>
<div class="nuxt-content-highlight" data-v-142b09b6 data-v-142b09b6><pre class="line-numbers language-cpp" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6>messages<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span><span class="token function" data-v-142b09b6 data-v-142b09b6>push_back</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>{</span> <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>{</span><span class="token string" data-v-142b09b6 data-v-142b09b6>"role"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span> role<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>}</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span> <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>{</span><span class="token string" data-v-142b09b6 data-v-142b09b6>"content"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span> content <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>}</span> <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>}</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>;</span>
</code></pre></div>
<p data-v-142b09b6 data-v-142b09b6>In Python the code for appending a message to a list of messages would be written differently:</p>
<div class="nuxt-content-highlight" data-v-142b09b6 data-v-142b09b6><pre class="line-numbers language-python" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6>messages<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>append<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>{</span><span class="token string" data-v-142b09b6 data-v-142b09b6>"role"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>:</span> role<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"content"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>:</span> content<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>}</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span>
</code></pre></div>
<h2 id="development-environment" data-v-142b09b6 data-v-142b09b6><a href="#development-environment" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Development environment</h2>
<p data-v-142b09b6 data-v-142b09b6>While working on different projects using web technologies and frameworks in the Python and JavaScript ecosystems, I developed an appreciation for well-structured development environments that are easy to use. Development environment refers to the tools and processes by which a developer can make a change to source code and see these changes reflected in some version of the application running on a local environment. The local environment (the developer's computer) should be a close proxy for the production environment where the code will ultimately deployed to for end users. For this project the local development environment is our PC itself, which simplifies things. A development environment should support hot-reloading so incremental changes can be run to test functionality, offering a tight feedback loop. I really like the development environment for this project. Here's a screenshot that shows the different parts of the development environment I used for working on Rocket League BotChat:</p>
<p data-v-142b09b6 data-v-142b09b6><img alt="Screenshot of Rocket League BotChat development environment" src="/img/rlbc/devenv2.png" data-v-142b09b6 data-v-142b09b6></p>
<ul data-v-142b09b6 data-v-142b09b6>
<li data-v-142b09b6 data-v-142b09b6>Rocket League (running with the <code data-v-142b09b6 data-v-142b09b6>-dev</code> flag turned on). The console is helpful for viewing log messages and the plugin settings panel can be used to view and change plugin configuration values. The BakkesMod plugin also needs to be running in order to inject plugin code into the game engine</li>
<li data-v-142b09b6 data-v-142b09b6>Visual Studio for working on the plugin code. <code data-v-142b09b6 data-v-142b09b6>Control</code>+<code data-v-142b09b6 data-v-142b09b6>Shift</code>+<code data-v-142b09b6 data-v-142b09b6>B</code> rebuilds the code and automatically reloads the plugin in the game</li>
<li data-v-142b09b6 data-v-142b09b6>OpenAI-compatible LLM server powered by TensorRT-LLM (using <code data-v-142b09b6 data-v-142b09b6>Llama-2-13b-chat-hf</code> with AWQ INT4 quantization) running in a docker container on Ubuntu in WSL</li>
<li data-v-142b09b6 data-v-142b09b6>VSCode for debugging C++ code with Continue.dev extension powered by TensorRT-LLM (using <code data-v-142b09b6 data-v-142b09b6>CodeLlama-13b-instruct-hf</code> with AWQ INT4 quantization) running in a virtual environment on Windows</li>
</ul>
<h3 id="building-the-tensorrt-llm-engines" data-v-142b09b6 data-v-142b09b6><a href="#building-the-tensorrt-llm-engines" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Building the TensorRT-LLM engines</h3>
<p data-v-142b09b6 data-v-142b09b6>I was able to build and run the TensorRT LLM engines for my game plugin's inference and the Continue.dev extension's inference both in Python virtual environments on Windows and on Ubuntu in WSL. For building the <code data-v-142b09b6 data-v-142b09b6>Llama-2-13b-chat-hf</code> model with INT4 AWQ quantization on Windows 11 I used this command:</p>
<div class="nuxt-content-highlight" data-v-142b09b6 data-v-142b09b6><pre class="line-numbers language-powershell" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>venv<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span> <span class="token function" data-v-142b09b6 data-v-142b09b6>PS</span> C:\Users\My PC\GitHub\TensorRT<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>LLM\examples\llama> python build<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>py <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>model_dir D:\llama\Llama<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>2<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>13b<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>chat<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>hf\ <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>quant_ckpt_path D:\llama\Llama<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>2<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>13b<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>chat<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>hf\llama_tp1_rank0<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>npz <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>dtype float16 <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>use_gpt_attention_plugin float16 <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>use_gemm_plugin float16 <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>use_weight_only <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>weight_only_precision int4_awq <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>per_group <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>enable_context_fmha <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>max_batch_size 1 <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>max_input_len 3500 <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>max_output_len 1024 <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>output_dir D:\llama\Llama<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>2<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>13b<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>chat<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>hf\single<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>gpu\ <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>vocab_size 32064
</code></pre></div>
<h3 id="running-the-tensorrt-llm-engines" data-v-142b09b6 data-v-142b09b6><a href="#running-the-tensorrt-llm-engines" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Running the TensorRT-LLM engines</h3>
<p data-v-142b09b6 data-v-142b09b6>Using Windows PowerShell to start the CodeLlama server for Continue.dev:</p>
<div class="nuxt-content-highlight" data-v-142b09b6 data-v-142b09b6><pre class="line-numbers language-powershell" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>venv<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span> <span class="token function" data-v-142b09b6 data-v-142b09b6>PS</span> C:\Users\My PC\GitHub\trt<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>llm<span class="token operator" data-v-142b09b6 data-v-142b09b6>-as</span><span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>openai<span class="token operator" data-v-142b09b6 data-v-142b09b6>-</span>windows> python <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>\app<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>py <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>trt_engine_path <span class="token string" data-v-142b09b6 data-v-142b09b6>"D:\llama\CodeLlama-13b-Instruct-hf\trt_engines\1-gpu\"</span> <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>trt_engine_name llama_float16_tp1_rank0<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>engine <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>tokenizer_dir_path <span class="token string" data-v-142b09b6 data-v-142b09b6>"D:\llama\CodeLlama-13b-Instruct-hf\"</span> <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>port 5000 <span class="token operator" data-v-142b09b6 data-v-142b09b6>--</span>host 0<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>0<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>0<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>0
</code></pre></div>
<p data-v-142b09b6 data-v-142b09b6>Tip: Adding <code data-v-142b09b6 data-v-142b09b6>--host 0.0.0.0</code> isn't required here, but it allows me to use the CodeLlama/TensorRT-LLM server with VSCode any computer on my local network using my PC's local IP address in the Continue.dev configuration.</p>
<p data-v-142b09b6 data-v-142b09b6>Using docker in WSL to start the Llama-2-13b-chat-hf LLM server:</p>
<div class="nuxt-content-highlight" data-v-142b09b6 data-v-142b09b6><pre class="line-numbers language-text" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6>root@0a5b5b75f079:/code/git/TensorRT-LLM/examples/server/flask# python3 app.py --trt_engine_path /llama/Llama-2-13b-chat-hf/trt_engines/1-gpu/ --trt_engine_name  llama_float16_t_rank0.engine --tokenizer_dir_path /llama/Llama-2-13b-chat-hf/ --port 5001 --host 0.0.0.0
</code></pre></div>
<p data-v-142b09b6 data-v-142b09b6>Note: Here I also add <code data-v-142b09b6 data-v-142b09b6>--host 0.0.0.0</code>, but this is required in order for the service in the docker container to be reached from WSL by the game running on Windows.</p>
<p data-v-142b09b6 data-v-142b09b6>BakkesMod includes a console window that came in handy for debugging errors during development.</p>
<p data-v-142b09b6 data-v-142b09b6>At the beginning of this developer contest on January 9, NVIDIA announced Chat with RTX. This is a demo program for Windows that automates a lots of the processes needed to set up a TensorRT-LLM-powered LLM running on your PC. Keep an eye on this project as it may become the best way to install and manage large language models on Windows PCs.</p>
<p data-v-142b09b6 data-v-142b09b6><img alt="Chat with RTX image" src="/img/rlbc/chat_with_rtx.jpeg" data-v-142b09b6 data-v-142b09b6></p>
<h2 id="how-it-works" data-v-142b09b6 data-v-142b09b6><a href="#how-it-works" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>How it works</h2>
<p data-v-142b09b6 data-v-142b09b6>Here's a quick look at key parts of the plugin source code (<a href="https://github.com/briancaffey/RocketLeagueBotChat" rel="nofollow noopener noreferrer" target="_blank" data-v-142b09b6 data-v-142b09b6>https://github.com/briancaffey/RocketLeagueBotChat</a>).</p>
<h3 id="hooking-events" data-v-142b09b6 data-v-142b09b6><a href="#hooking-events" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Hooking events</h3>
<p data-v-142b09b6 data-v-142b09b6>Hooking events is the core of how this plugin works. <code data-v-142b09b6 data-v-142b09b6>StatTickerMessage</code> events cover most of the events that are triggered in Rocket League, such as scoring a goal, making a save or demolishing a car.</p>
<div class="nuxt-content-highlight" data-v-142b09b6 data-v-142b09b6><pre class="line-numbers language-cpp" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6>    <span class="token comment" data-v-142b09b6 data-v-142b09b6>// Hooks different types of events that are handled in onStatTickerMessage</span>
    <span class="token comment" data-v-142b09b6 data-v-142b09b6>// See https://wiki.bakkesplugins.com/functions/stat_events/</span>
    gameWrapper<span class="token operator" data-v-142b09b6 data-v-142b09b6>-></span><span class="token generic-function" data-v-142b09b6 data-v-142b09b6><span class="token function" data-v-142b09b6 data-v-142b09b6>HookEventWithCallerPost</span><span class="token generic class-name" data-v-142b09b6 data-v-142b09b6><span class="token operator" data-v-142b09b6 data-v-142b09b6>&lt;</span>ServerWrapper<span class="token operator" data-v-142b09b6 data-v-142b09b6>></span></span></span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span><span class="token string" data-v-142b09b6 data-v-142b09b6>"Function TAGame.GFxHUD_TA.HandleStatTickerMessage"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span>
        <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>[</span><span class="token keyword" data-v-142b09b6 data-v-142b09b6>this</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>]</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span>ServerWrapper caller<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span> <span class="token keyword" data-v-142b09b6 data-v-142b09b6>void</span><span class="token operator" data-v-142b09b6 data-v-142b09b6>*</span> params<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span> std<span class="token double-colon punctuation" data-v-142b09b6 data-v-142b09b6>::</span>string eventname<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span> <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>{</span>
            <span class="token function" data-v-142b09b6 data-v-142b09b6>onStatTickerMessage</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span>params<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>;</span>
        <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>}</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>;</span>
</code></pre></div>
<h3 id="handling-events-and-building-the-prompt" data-v-142b09b6 data-v-142b09b6><a href="#handling-events-and-building-the-prompt" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Handling events and building the prompt</h3>
<p data-v-142b09b6 data-v-142b09b6>We can unpack values from the event to determine the player to which the event should be attributed. The code then translates the game event and related data into an English sentence. This is appended to a vector of message objects with the <code data-v-142b09b6 data-v-142b09b6>appendToPrompt</code> method.</p>
<div class="nuxt-content-highlight" data-v-142b09b6 data-v-142b09b6><pre class="line-numbers language-cpp" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6>    <span class="token comment" data-v-142b09b6 data-v-142b09b6>// handle different events like scoring a goal or making a save</span>
    <span class="token keyword" data-v-142b09b6 data-v-142b09b6>if</span> <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span>statEvent<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span><span class="token function" data-v-142b09b6 data-v-142b09b6>GetEventName</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span> <span class="token operator" data-v-142b09b6 data-v-142b09b6>==</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"Goal"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span> <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>{</span>

        <span class="token comment" data-v-142b09b6 data-v-142b09b6>// was the goal scored by the human player or the bot?</span>
        <span class="token keyword" data-v-142b09b6 data-v-142b09b6>if</span> <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span>playerPRI<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>memory_address <span class="token operator" data-v-142b09b6 data-v-142b09b6>==</span> receiver<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>.</span>memory_address<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span> <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>{</span>
            <span class="token function" data-v-142b09b6 data-v-142b09b6>appendToPrompt</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span><span class="token string" data-v-142b09b6 data-v-142b09b6>"Your human opponent just scored a goal against you! "</span> <span class="token operator" data-v-142b09b6 data-v-142b09b6>+</span> score_sentence<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"user"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>;</span>
        <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>}</span>
        <span class="token keyword" data-v-142b09b6 data-v-142b09b6>else</span> <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>{</span>
            <span class="token function" data-v-142b09b6 data-v-142b09b6>appendToPrompt</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span><span class="token string" data-v-142b09b6 data-v-142b09b6>"You just scored a goal against the human player! "</span> <span class="token operator" data-v-142b09b6 data-v-142b09b6>+</span> score_sentence<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"user"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>;</span>
        <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>}</span>
    <span class="token punctuation" data-v-142b09b6 data-v-142b09b6>}</span>
</code></pre></div>
<h3 id="making-requests-and-handling-responses" data-v-142b09b6 data-v-142b09b6><a href="#making-requests-and-handling-responses" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Making requests and handling responses</h3>
<p data-v-142b09b6 data-v-142b09b6>The last main part of the code is making a request to the LLM server with the prompt that we have formed above based on game messages. This code should look familiar to anyone who has worked with OpenAI's API.</p>
<div class="nuxt-content-highlight" data-v-142b09b6 data-v-142b09b6><pre class="line-numbers language-cpp" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6>std<span class="token double-colon punctuation" data-v-142b09b6 data-v-142b09b6>::</span>string message <span class="token operator" data-v-142b09b6 data-v-142b09b6>=</span> response_json<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>[</span><span class="token string" data-v-142b09b6 data-v-142b09b6>"choices"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>]</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>[</span><span class="token number" data-v-142b09b6 data-v-142b09b6>0</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>]</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>[</span><span class="token string" data-v-142b09b6 data-v-142b09b6>"message"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>]</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>[</span><span class="token string" data-v-142b09b6 data-v-142b09b6>"content"</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>]</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>;</span>
</code></pre></div>
<p data-v-142b09b6 data-v-142b09b6>The <code data-v-142b09b6 data-v-142b09b6>LogToChatbox</code> method is used to send a message to the in-game chat box with the name of the bot that is sending the message. Since messages could possibly be longer than the limit of 120 characters, I send messages to the chatbox in chunks of 120 characters at a time.</p>
<div class="nuxt-content-highlight" data-v-142b09b6 data-v-142b09b6><pre class="line-numbers language-cpp" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6>gameWrapper<span class="token operator" data-v-142b09b6 data-v-142b09b6>-></span><span class="token function" data-v-142b09b6 data-v-142b09b6>LogToChatbox</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>(</span>messages<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>[</span>i<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>]</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>,</span> <span class="token keyword" data-v-142b09b6 data-v-142b09b6>this</span><span class="token operator" data-v-142b09b6 data-v-142b09b6>-></span>bot_name<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>)</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>;</span>
</code></pre></div>
<p data-v-142b09b6 data-v-142b09b6>That's it! The code isn't that complicated. I had to sanitize the message so that it would not include emoji or the stop character that the LLM server would include in messages (<code data-v-142b09b6 data-v-142b09b6>&lt;/s></code>). Oddly, I had a hard time getting the LLM to not use emoji even when I instructed it to not use emoji in the system prompt.</p>
<h2 id="rocket-league-botchat-ui" data-v-142b09b6 data-v-142b09b6><a href="#rocket-league-botchat-ui" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Rocket League BotChat UI</h2>
<p data-v-142b09b6 data-v-142b09b6>Most BakkesMod plugins for RocketLeague UIs that allow for controlling settings. Here's what the UI for Rocket League BotChat looks like:</p>
<p data-v-142b09b6 data-v-142b09b6><img alt="Rocket League BotChat Plugin UI" src="/img/rlbc/rlbcui.png" data-v-142b09b6 data-v-142b09b6></p>
<h3 id="system-prompt" data-v-142b09b6 data-v-142b09b6><a href="#system-prompt" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>System prompt</h3>
<p data-v-142b09b6 data-v-142b09b6>The system prompt instructs the bot on how it shoud reply. This is an important part of the prompt engineering for this project, and I used Postman to experiment with lots of different types of instructions. Here's the default prompt that I used:</p>
<div class="nuxt-content-highlight" data-v-142b09b6 data-v-142b09b6><pre class="line-numbers language-cpp" data-v-142b09b6 data-v-142b09b6><code data-v-142b09b6 data-v-142b09b6>    std<span class="token double-colon punctuation" data-v-142b09b6 data-v-142b09b6>::</span>string ai_player <span class="token operator" data-v-142b09b6 data-v-142b09b6>=</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"You are an elite AI player in the car soccer game Rocket League. "</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>;</span>
    std<span class="token double-colon punctuation" data-v-142b09b6 data-v-142b09b6>::</span>string one_v_one <span class="token operator" data-v-142b09b6 data-v-142b09b6>=</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"You are playing a 1v1 match against a human player. "</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>;</span>
    std<span class="token double-colon punctuation" data-v-142b09b6 data-v-142b09b6>::</span>string instructions <span class="token operator" data-v-142b09b6 data-v-142b09b6>=</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"You will send short chat messages to your human opponent in response to what happens in the game. "</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>;</span>
    std<span class="token double-colon punctuation" data-v-142b09b6 data-v-142b09b6>::</span>string details <span class="token operator" data-v-142b09b6 data-v-142b09b6>=</span> <span class="token string" data-v-142b09b6 data-v-142b09b6>"Respond to the human player with brief messages no more than 12 words long."</span><span class="token punctuation" data-v-142b09b6 data-v-142b09b6>;</span>
    <span class="token comment" data-v-142b09b6 data-v-142b09b6>// initial system prompt</span>
    std<span class="token double-colon punctuation" data-v-142b09b6 data-v-142b09b6>::</span>string initial_system_prompt <span class="token operator" data-v-142b09b6 data-v-142b09b6>=</span> ai_player <span class="token operator" data-v-142b09b6 data-v-142b09b6>+</span> one_v_one <span class="token operator" data-v-142b09b6 data-v-142b09b6>+</span> instructions <span class="token operator" data-v-142b09b6 data-v-142b09b6>+</span> details<span class="token punctuation" data-v-142b09b6 data-v-142b09b6>;</span>
</code></pre></div>
<p data-v-142b09b6 data-v-142b09b6>The last part about <code data-v-142b09b6 data-v-142b09b6>no more than 12 words long</code> was the most effective way of controlling the length responses from the LLM. I tried changing the <code data-v-142b09b6 data-v-142b09b6>max_output_len</code> when building the TensorRT engine, but this degraded the quality of the responses. The system prompt can be changed by the user. Changing the system prompt was a lot of fun to expirment with!</p>
<h3 id="temperature-and-seed" data-v-142b09b6 data-v-142b09b6><a href="#temperature-and-seed" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Temperature and Seed</h3>
<p data-v-142b09b6 data-v-142b09b6>These values are included in the body of the request to the LLM, but I didn't have much luck with these. Early on I had issues with getting sufficient variation in the responses from the LLM, so I tried using random values for seed and temperature, but this didn't really work.</p>
<h3 id="messages" data-v-142b09b6 data-v-142b09b6><a href="#messages" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Messages</h3>
<p data-v-142b09b6 data-v-142b09b6>This section of the UI displays the messages that are used in requests to the LLM. In order keep the prompt within the context window limit, I only used the most recent six messages sent from the "user" (which are messages about game events) and the "assistant" (which are LLM responses from the bot). Whenever the user changes the system prompt, the messages vector is reset to only include the new system prompt.</p>
<h2 id="demo-video-for-contest-submission" data-v-142b09b6 data-v-142b09b6><a href="#demo-video-for-contest-submission" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Demo Video for Contest Submission</h2>
<blockquote class="twitter-tweet tw-align-center" data-media-max-width="560" data-v-142b09b6 data-v-142b09b6><p lang="en" dir="ltr" data-v-142b09b6 data-v-142b09b6>Rocket League BotChat - powered by TensorRT-LLM<br data-v-142b09b6 data-v-142b09b6>⚽️🚗⚡️🤖💬<br data-v-142b09b6 data-v-142b09b6>My submission for NVIDIA's Gen AI on RTX PCs Developer Contest<a href="https://twitter.com/NVIDIAAIDev?ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>@NVIDIAAIDev</a> <a href="https://twitter.com/hashtag/RocketLeague?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#RocketLeague</a> <a href="https://twitter.com/hashtag/GTC24?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#GTC24</a> <a href="https://twitter.com/hashtag/NVIDIA?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#NVIDIA</a> <a href="https://twitter.com/hashtag/LLM?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#LLM</a> <a href="https://twitter.com/hashtag/Llama?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#Llama</a> <a href="https://twitter.com/hashtag/AI?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#AI</a> <a href="https://twitter.com/hashtag/Windows11?src=hash&ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>#Windows11</a> <a href="https://t.co/A7ON3lyTC6" data-v-142b09b6 data-v-142b09b6>pic.twitter.com/A7ON3lyTC6</a></p>— Brian Caffey (@briancaffey) <a href="https://twitter.com/briancaffey/status/1759265152275292644?ref_src=twsrc%5Etfw" data-v-142b09b6 data-v-142b09b6>February 18, 2024</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8" data-v-142b09b6 data-v-142b09b6></script>
<p data-v-142b09b6 data-v-142b09b6>I used Blender's sequence editor to create a demo video for my contest submission. I don't edit a lot of videos, but it is a fun process and I learned a lot about Blender and non-linear video editing in the process. Here's how I approached creating the demo video for my project.</p>
<p data-v-142b09b6 data-v-142b09b6><img alt="Blender video sequence editor UI used to create my project video" src="/img/rlbc/blender.png" data-v-142b09b6 data-v-142b09b6></p>
<ul data-v-142b09b6 data-v-142b09b6>
<li data-v-142b09b6 data-v-142b09b6>Structure the video in three main parts: introduction to my project and the contest, description of how it works, demo of my project in action</li>
<li data-v-142b09b6 data-v-142b09b6>Find an upbeat song from playlists included in Rocket League with no vocals to use as background music. I used <a href="https://open.spotify.com/track/68ahXxPJrxcEvQFjRmC2ja?si=2147d6d652064d51" rel="nofollow noopener noreferrer" target="_blank" data-v-142b09b6 data-v-142b09b6>"Dads in Space" by Steven Walking</a></li>
<li data-v-142b09b6 data-v-142b09b6>Get stock Rocket League footage from YouTube with <code data-v-142b09b6 data-v-142b09b6>youtube-dl</code> (this is an amazing tool!). I mostly used footage from the <a href="https://www.youtube.com/watch?v=e1tqWldCYOI&pp=ygUQcmxjcyB3aW50ZXIgMjAyMw%3D%3D" rel="nofollow noopener noreferrer" target="_blank" data-v-142b09b6 data-v-142b09b6>RLCS 2023 Winter Major Trailer</a>. This video was uploaded at 24 fps, and my Blender Video project frame rate was set to 29.97, so I used ffmpeg to convert this video from 24 fps to 29.97 fps.</li>
<li data-v-142b09b6 data-v-142b09b6>Record myself playing Rocket League with my plugin enabled using NVIDIA Share. Miraculously, I was able to score against the Nexto bot!</li>
<li data-v-142b09b6 data-v-142b09b6>Use ComfyUI to animate some of the images used in the contest description and use these in my video</li>
</ul>
<p data-v-142b09b6 data-v-142b09b6><img alt="ComfyUI workflow for animating images using img2vid model" src="/img/rlbc/comfyui.png" data-v-142b09b6 data-v-142b09b6></p>
<ul data-v-142b09b6 data-v-142b09b6>
<li data-v-142b09b6 data-v-142b09b6>Use ElevenLabs to narrate a simple voice over script that describes the video content. This tuned out a lot better than I expected. I paid $1 for the ElevenLabs creator plan and got lots of tokens to experiment with different settings for voice generation using a clone of my voice.</li>
</ul>
<p data-v-142b09b6 data-v-142b09b6><img alt="Eleven Labs Voice Generation Web UI" src="/img/rlbc/elevenlabs.png" data-v-142b09b6 data-v-142b09b6></p>
<p data-v-142b09b6 data-v-142b09b6><a href="#" data-v-142b09b6 data-v-142b09b6>Embed twitter video here</a></p>
<h2 id="shortcomings-of-my-project" data-v-142b09b6 data-v-142b09b6><a href="#shortcomings-of-my-project" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>Shortcomings of my project</h2>
<p data-v-142b09b6 data-v-142b09b6>This plugin is a proof of concept and it has some shortcomings. One issue is that some events that my plugin listens to can happen in rapid succession. This results in "user" and "assistant" prompts getting out of order which breaks assertions on the <code data-v-142b09b6 data-v-142b09b6>trt-llm-as-openai-windows</code> repo. It would make more sense to have the bot send messages not immediately after the events are triggered, but on a different type of schedule that allows for multiple events to happen before sending the prompt to the LLM.</p>
<p data-v-142b09b6 data-v-142b09b6>There are lots of events that are triggered that would be interesting things for the bot to react to, but I decided not to prompt on every event since the above situation would be triggered frequently. For example, suppose I listen for events like taking a shot on goal and scoring a goal. If the goal is scored immediately after the shot is taken, then the second prompt is sent before the response for the first prompt comes back. For this reason I decided to simply not listen to events like "shot on goal" to avoid prompt messages getting out of order. This could also be addressed with more code logic.</p>
<p data-v-142b09b6 data-v-142b09b6>Prompt engineering is something that can always be improved. It is hard to measure and testing it is subjective. I am pleased with the results I was able to capture for the demo video, but the quality of the LLM responses can very depending on what happens during gameplay. One idea I had to address this would be to provide multiple English translations for any given event, and then select one at random. This might help improve the variety of responses, for example.</p>
<p data-v-142b09b6 data-v-142b09b6>I faced some limitations that are built in to the game iteself. For example, it is not possible for a player to send messages to the in-game chat in offline matches, which makes sense! I built a backdoor for doing this through the BakkesMod developer console, so you can send messages to the bot by typing something like <code data-v-142b09b6 data-v-142b09b6>SendMessage Good shot, bot!</code>, for example.</p>
<h2 id="whats-next" data-v-142b09b6 data-v-142b09b6><a href="#whats-next" aria-hidden="true" tabindex="-1" data-v-142b09b6 data-v-142b09b6><span class="icon icon-link" data-v-142b09b6 data-v-142b09b6></span></a>What's next?</h2>
<p data-v-142b09b6 data-v-142b09b6>Participating in this contest was a great opportunity to learn more about LLMs and how to use them to extend programs in a Windows environment. It was also a lot of fun to build something by putting together new tools like TensorRT-LLM. Seeing the bot send me chat messages was very satisfying when I first got it to work! Overall it is a pretty simple implementation, but this idea could be extended to produce useful application. I could imagine a "Rocket League Coach" plugin that expands on this idea to give helpful feedback based on higher-level data, statistical trends, training goals, etc.</p>
<p data-v-142b09b6 data-v-142b09b6>I think the gaming industry's adoption of LLMs for new games will be BIG, and it will present a huge opportunity for LLM optimization and acceleration software like TensorRT-LLM that I was able to use in my Rocket League BotChat. This is not to discredit the work of writers which play an important role in game development. I'm excited to see what other developers have built for this contest, especially submissions that are building mods for games using TensorRT-LLM.</p>
<p data-v-142b09b6 data-v-142b09b6>Thanks NVIDIA and the TensorRT and TensorRT-LLM teams for organizing this contest! Keep on building!!</p></div> <div class="text-center pb-4 pt-8" data-v-142b09b6><button class="mc-btn rounded py-1 px-2" data-v-142b09b6>
        Show Disqus Comments 💬
      </button></div> <!----> <h1 data-v-142b09b6></h1></div></article> <div class="mx-auto max-w-6xl p-4 lg:px-16 text-center" data-v-7718c60c><hr class="mt-4" data-v-7718c60c> <div class="align-center py-4" data-v-7718c60c><div class="pb-4" data-v-7718c60c>
      加入我的通讯名单
    </div> <div class="flex align-center justify-center" data-v-5690d13b data-v-7718c60c><div id="mc_embed_signup" class="w-full md:w-1/2 flex-shrink justify-center" data-v-5690d13b><form id="mc-embedded-subscribe-form" action="https://github.us2.list-manage.com/subscribe/post?u=43a795784ca963e25903a0da6&id=9937fe4fc5" method="post" name="mc-embedded-subscribe-form" target="_blank" novalidate class="validate" data-v-5690d13b><div id="mc_embed_signup_scroll" class="grid grid-cols-1 sm:grid-cols-2 gap-4" data-v-5690d13b><input id="mce-EMAIL" type="email" name="EMAIL" placeholder="输入您的电子邮箱" class="rounded mc text-center" data-v-5690d13b> <div aria-hidden="true" style="position:absolute;left:-5000px" data-v-5690d13b><input name="b_43a795784ca963e25903a0da6_9937fe4fc5" tabindex="-1" data-v-5690d13b></div> <div class="text-right" style="width:100%" data-v-5690d13b><input id="mc-embedded-subscribe" type="submit" name="subscribe" value="订阅" class="mc-btn rounded px-2 py-1 w-full" data-v-5690d13b></div></div></form></div></div></div> <hr data-v-7718c60c> <div class="py-4" data-v-7718c60c>
    感谢您访问我的网站！
  </div> <div class="pb-4" data-v-7718c60c>
    © 2024 Brian Caffey
  </div></div></div></div></div><script defer src="/_nuxt/static/1708308010/zh/2024/02/17/rocket-league-botchat-nvidia-generative-ai-on-rtx-pcs-developer-contest/state.js"></script><script src="/_nuxt/8369139.js" defer></script><script src="/_nuxt/c259e4a.js" defer></script><script src="/_nuxt/8bfa011.js" defer></script><script src="/_nuxt/b575c49.js" defer></script><script src="/_nuxt/691d3dd.js" defer></script>
  </body>
</html>
