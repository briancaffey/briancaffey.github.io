__NUXT_JSONP__("/2017/11/19/tensorflow-gpu-setup-with-docker-on-arch-linux.html", (function(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,A,B,C,D,E,F,G,H,I,J,K,L,M,N,O,P,Q,R,S,T,U,V){return {data:[{article:{slug:"tensorflow-gpu-setup-with-docker-on-arch-linux.html",layout:"post",title:"Installing the GPU version of Tensorflow with Docker on Arch Linux",date:"2017-11-19T00:00:00.000Z",comments:true,image:E,tags:["arch-linux","tensorflow",F,"nvidia","python"],toc:[{id:G,depth:H,text:I},{id:J,depth:H,text:K},{id:L,depth:3,text:M}],body:{type:"root",children:[{type:b,tag:d,props:{},children:[{type:a,value:"I've tried installing the GPU version of Tensorflow a few times before and failed. There seems to be lots of confusion about the build process, of which there are many. Also, over the last few years there have been many new versions of the software needed to support the GPU version of Tensorflow as well as the first official release of Tensorflow itself (which is now on version 1.4), such as CUDA and cudnn, and different version of python. This is one more attempt at installing the GPU version of Tensor Flow on my Desktop PC that is currently dual booting with Arch Linux and Windows 10. I've decided to try going the docker route because it should eliminate some of the headache of missing depedencies. Here are the specs for my computer:"}]},{type:a,value:c},{type:b,tag:"ul",props:{},children:[{type:a,value:c},{type:b,tag:x,props:{},children:[{type:a,value:"i7-6700K"}]},{type:a,value:c},{type:b,tag:x,props:{},children:[{type:a,value:"NVIDIA GTX 1080"}]},{type:a,value:c},{type:b,tag:x,props:{},children:[{type:a,value:"Asus Hero VIII motherboard"}]},{type:a,value:c},{type:b,tag:x,props:{},children:[{type:a,value:"Arch Linux on a 128 GB SSD (Windows 10 is installed on a separate SSD)"}]},{type:a,value:c}]},{type:a,value:c},{type:b,tag:N,props:{id:G},children:[{type:b,tag:n,props:{href:"#installing-cuda-and-cudnn",ariaHidden:y,tabIndex:z},children:[{type:b,tag:e,props:{className:[A,B]},children:[]}]},{type:a,value:I}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"We don't need to install these when installing Tensorflow with Docker. Read to the bottom for more info."}]},{type:a,value:c},{type:b,tag:N,props:{id:J},children:[{type:b,tag:n,props:{href:"#installing-docker",ariaHidden:y,tabIndex:z},children:[{type:b,tag:e,props:{className:[A,B]},children:[]}]},{type:a,value:K}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"To install docker on our machine, let's start with the "},{type:b,tag:n,props:{href:"https:\u002F\u002Fwiki.archlinux.org\u002Findex.php\u002FDocker",rel:[r,s,t],target:u},children:[{type:a,value:"Arch Wiki article on docker"}]},{type:a,value:o}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"We need to add the Loopback module to the Linux Kernel, so we run:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"# tee \u002Fetc\u002Fmodules-load.d\u002Floop.conf \u003C\u003C\u003C \"loop\"\n# modprobe loop\n$ reboot\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Ater rebooting we can install docker:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"yaourt -S docker\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Now we want to add ourself to the docker group with the following command:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"$ sudo gpasswd -a brian docker\n[sudo] password for brian:\nAdding user brian to group docker\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"If you run "},{type:b,tag:f,props:{},children:[{type:a,value:"groups"}]},{type:a,value:", you won't see docker listed in the groups you (brian) belong to. Run "},{type:b,tag:f,props:{},children:[{type:a,value:"newgrp docker"}]},{type:a,value:" and then re-run docker and you should see "},{type:b,tag:f,props:{},children:[{type:a,value:F}]},{type:a,value:" listed with any other groups you belong to:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"[brian@a1arch ~]$ groups\nwheel storage power users\n[brian@a1arch ~]$ newgrp docker\n                   -`                    brian@a1arch\n                  .o+`                   ------------\n                 `ooo\u002F                   OS: Arch Linux x86_64\n                `+oooo:                  Kernel: 4.12.8-2-ARCH\n               `+oooooo:                 Uptime: 6 mins\n               -+oooooo+:                Packages: 1127\n             `\u002F:-:++oooo+:               Shell: bash 4.4.12\n            `\u002F++++\u002F+++++++:              Resolution: 1920x1080\n           `\u002F++++++++++++++:             WM: i3\n          `\u002F+++ooooooooooooo\u002F`           Theme: Adwaita [GTK2]\n         .\u002Fooosssso++osssssso+`          Icons: Adwaita [GTK2]\n        .oossssso-````\u002Fossssss+`         Terminal: urxvt\n       -osssssso.      :ssssssso.        Terminal Font: Inconsolata-12\n      :osssssss\u002F        osssso+++.       CPU: Intel i7-6700K (8) @ 4.200GHz\n     \u002Fossssssss\u002F        +ssssooo\u002F-       GPU: NVIDIA GeForce GTX 1080\n   `\u002Fossssso+\u002F:-        -:\u002F+osssso+-     Memory: 3289MiB \u002F 15975MiB\n  `+sso+:-`                 `.-\u002F+oso:\n `++:.                           `-\u002F+\u002F\n .`                                 `\u002F\n\n[brian@a1arch ~]$ groups\ndocker wheel storage power users\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Doing this prevents us from having to write sudo each time we run docker."}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Next we need to start the docker daemon."}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"$ systemctl start docker\n==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-units ====\nAuthentication is required to start 'docker.service'.\nAuthenticating as: brian\nPassword:\n==== AUTHENTICATION COMPLETE ====\n$\n"}]}]}]},{type:a,value:c},{type:b,tag:"h3",props:{id:L},children:[{type:b,tag:n,props:{href:"#side-note",ariaHidden:y,tabIndex:z},children:[{type:b,tag:e,props:{className:[A,B]},children:[]}]},{type:a,value:M}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"There seems to be an "},{type:b,tag:n,props:{href:"https:\u002F\u002Fgithub.com\u002Fmoby\u002Fmoby\u002Fissues\u002F23289",rel:[r,s,t],target:u},children:[{type:a,value:"Arch Linux-specific bug"}]},{type:a,value:" which prevents us from enabling docker (and nvidia-docker which we will get next). There is a solution to downgrade to an older version of docker, or you can just start the docker service and the nvidia-docker service when you want to use them. I have found it faster to first start nvidia-docker and then start docker services."}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"So far so good. Next let's look at the Tensorflow documentation for installing Tensorflow with docker."}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"We need to install "},{type:b,tag:f,props:{},children:[{type:a,value:O}]},{type:a,value:P}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"$ yaourt -S nvidia-docker\n[...]\n[sudo] password for brian:\nloading packages...\nresolving dependencies...\nlooking for conflicting packages...\n\nPackages (1) nvidia-docker-1.0.1-1\n\nTotal Installed Size:  13.34 MiB\n\n:: Proceed with installation? [Y\u002Fn]\n(1\u002F1) checking keys in keyring                                 [##################################] 100%\n(1\u002F1) checking package integrity                               [##################################] 100%\n(1\u002F1) loading package files                                    [##################################] 100%\n(1\u002F1) checking for file conflicts                              [##################################] 100%\n(1\u002F1) checking available disk space                            [##################################] 100%\n:: Processing package changes...\n(1\u002F1) installing nvidia-docker                                 [##################################] 100%\n=\u003E Prior to running 'CUDA'-containers, ensure that the nvidia-docker-plugin\n   is loaded. -\u003E https:\u002F\u002Fgithub.com\u002FNVIDIA\u002Fnvidia-docker#other-distributions\n\n*) manually; sudo -b nohup nvidia-docker-plugin \u003E \u002Ftmp\u002Fnvidia-docker.log\n\n*) automatically at startup; systemctl enable nvidia-docker.service\nOptional dependencies for nvidia-docker\n    cuda [installed]\n    nvidia [installed]\n    opencl-nvidia [installed]\n:: Running post-transaction hooks...\n(1\u002F1) Arming ConditionNeedsUpdate...\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Next it says: Launch a Docker container that contains one of the TensorFlow binary images. Those images are available "},{type:b,tag:n,props:{href:"https:\u002F\u002Fhub.docker.com\u002Fr\u002Ftensorflow\u002Ftensorflow\u002Ftags\u002F",rel:[r,s,t],target:u},children:[{type:a,value:"here"}]},{type:a,value:o}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Next I pulled the container with the "},{type:b,tag:f,props:{},children:[{type:a,value:"gpu-latest"}]},{type:a,value:" tag and it started to download the container:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"$ docker pull tensorflow\u002Ftensorflow:gpu-latest\n[sudo] password for brian:\nlatest-gpu: Pulling from tensorflow\u002Ftensorflow\nae79f2514705: Pull complete\nc59d01a7e4ca: Pull complete\n41ba73a9054d: Pull complete\nf1bbfd495cc1: Pull complete\n0c346f7223e2: Pull complete\n5dcd01667896: Pull complete\nca677f607487: Downloading  180.7MB\u002F453MB\nb4637619a887: Download complete\n8c644ff287da: Downloading    224MB\u002F465.6MB\n119c5f576e79: Download complete\n009f82e71a7c: Download complete\ndbc0fb5872c7: Downloading  17.83MB\u002F66.54MB\n5ef01389c5b2: Waiting\n04f824004b76: Waiting\n5861b82f52e5: Waiting\na495a3b4e6e1: Waiting\n3a0a25b1bbaf: Pulling fs layer\nb76a0afeb1e1: Waiting\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"It finished after several minutes:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"ca677f607487: Pull complete\nb4637619a887: Pull complete\n8c644ff287da: Pull complete\n119c5f576e79: Pull complete\n009f82e71a7c: Pull complete\ndbc0fb5872c7: Pull complete\n5ef01389c5b2: Pull complete\n04f824004b76: Pull complete\n5861b82f52e5: Pull complete\na495a3b4e6e1: Pull complete\n3a0a25b1bbaf: Pull complete\nb76a0afeb1e1: Pull complete\nDigest: sha256:90e27448121b321c5ec66069fb2c718301df2ddaf25ba916b6f53719141572b0\nStatus: Downloaded newer image for tensorflow\u002Ftensorflow:latest-gpu\n$\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Let's verify that it has the image:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"$ docker images\nREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\ntensorflow\u002Ftensorflow   latest-gpu          2f243a16ff63        13 days ago         3.36GB\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Next let's start the "},{type:b,tag:f,props:{},children:[{type:a,value:O}]},{type:a,value:" service:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"$ systemctl start nvidia-docker\n==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-units ====\nAuthentication is required to start 'nvidia-docker.service'.\nAuthenticating as: brian\nPassword:\n==== AUTHENTICATION COMPLETE ====\n$\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"OK, we should be ready to launch the image:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"$ nvidia-docker run -it tensorflow\u002Ftensorflow:latest-gpu bash\nroot@761a62c1cff1:\u002Fnotebooks#\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"This is looking good. Let's try to start python:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"root@761a62c1cff1:\u002Fnotebooks# python\nPython 2.7.12 (default, Nov 19 2016, 06:48:10)\n[GCC 5.4.0 20160609] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\u003E\u003E\u003E import tensorflow as tf\n\u003E\u003E\u003E\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"That works! Let's try out the classic MNIST hand-written digit classification problem that comes packaged as a notebook with the container image:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"$ nvidia-docker run -it -p 8888:8888 tensorflow\u002Ftensorflow:latest-gpu\n[sudo] password for brian:\n[I 21:54:26.671 NotebookApp] Writing notebook server cookie secret to \u002Froot\u002F.local\u002Fshare\u002Fjupyter\u002Fruntime\u002Fnotebook_cookie_secret\n[W 21:54:26.689 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.\n[I 21:54:26.693 NotebookApp] Serving notebooks from local directory: \u002Fnotebooks\n[I 21:54:26.693 NotebookApp] 0 active kernels\n[I 21:54:26.693 NotebookApp] The Jupyter Notebook is running at:\n[I 21:54:26.693 NotebookApp] http:\u002F\u002F[all ip addresses on your system]:8888\u002F?token=cda89aff96a3d4a9741cc755aac07f65f3aa372f60a198bd\n[I 21:54:26.693 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n[C 21:54:26.693 NotebookApp]\n\n    Copy\u002Fpaste this URL into your browser when you connect for the first time,\n    to login with a token:\n        http:\u002F\u002Flocalhost:8888\u002F?token=cda89aff96a3d4a9741cc755aac07f65f3aa372f60a198bd\n[I 21:54:34.489 NotebookApp] 302 GET \u002F?token=cda89aff96a3d4a9741cc755aac07f65f3aa372f60a198bd (172.17.0.1) 0.32ms\n[I 21:54:59.019 NotebookApp] Writing notebook-signing key to \u002Froot\u002F.local\u002Fshare\u002Fjupyter\u002Fnotebook_secret\n[W 21:54:59.023 NotebookApp] Notebook 3_mnist_from_scratch.ipynb is not trusted\n[W 21:54:59.049 NotebookApp] 404 GET \u002Fnbextensions\u002Fwidgets\u002Fnotebook\u002Fjs\u002Fextension.js?v=20171119215426 (172.17.0.1) 4.38ms referer=http:\u002F\u002Flocalhost:8888\u002Fnotebooks\u002F3_mnist_from_scratch.ipynb\n[I 21:54:59.813 NotebookApp] Kernel started: 00027a3e-59ae-47ce-90a5-752a9d1fe075\n[I 21:55:00.199 NotebookApp] Adapting to protocol v5.1 for kernel 00027a3e-59ae-47ce-90a5-752a9d1fe075\n[I 21:56:59.815 NotebookApp] Saving file at \u002F3_mnist_from_scratch.ipynb\n[W 21:56:59.816 NotebookApp] Notebook 3_mnist_from_scratch.ipynb is not trusted\n2017-11-19 21:57:03.988627: I tensorflow\u002Fcore\u002Fplatform\u002Fcpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2017-11-19 21:57:04.070873: I tensorflow\u002Fstream_executor\u002Fcuda\u002Fcuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-11-19 21:57:04.071129: I tensorflow\u002Fcore\u002Fcommon_runtime\u002Fgpu\u002Fgpu_device.cc:1030] Found device 0 with properties:\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\npciBusID: 0000:01:00.0\ntotalMemory: 7.92GiB freeMemory: 7.44GiB\n2017-11-19 21:57:04.071143: I tensorflow\u002Fcore\u002Fcommon_runtime\u002Fgpu\u002Fgpu_device.cc:1120] Creating TensorFlow device (\u002Fdevice:GPU:0) -\u003E (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"I was only able to get the entire notebook to run after making a few small configuration tweaks to the tensorflow Interactive Session to fix some memory issues:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,"language-python"]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"gpu_options "},{type:b,tag:e,props:{className:[g,v]},children:[{type:a,value:w}]},{type:a,value:Q},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:o}]},{type:a,value:"GPUOptions"},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:p}]},{type:a,value:"per_process_gpu_memory_fraction"},{type:b,tag:e,props:{className:[g,v]},children:[{type:a,value:w}]},{type:b,tag:e,props:{className:[g,"number"]},children:[{type:a,value:R}]},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:q}]},{type:a,value:"\n\ns "},{type:b,tag:e,props:{className:[g,v]},children:[{type:a,value:w}]},{type:a,value:Q},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:o}]},{type:a,value:"InteractiveSession"},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:p}]},{type:a,value:"config"},{type:b,tag:e,props:{className:[g,v]},children:[{type:a,value:w}]},{type:a,value:"tf"},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:o}]},{type:a,value:"ConfigProto"},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:p}]},{type:a,value:C},{type:b,tag:e,props:{className:[g,v]},children:[{type:a,value:w}]},{type:a,value:C},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:q}]},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:q}]},{type:a,value:S},{type:b,tag:e,props:{className:[g,D]},children:[{type:a,value:"# Use our newly created session as the default for"}]},{type:a,value:c},{type:b,tag:e,props:{className:[g,D]},children:[{type:a,value:"# subsequent operations."}]},{type:a,value:"\ns"},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:o}]},{type:a,value:"as_default"},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:p}]},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:q}]},{type:a,value:S},{type:b,tag:e,props:{className:[g,D]},children:[{type:a,value:"# Initialize all the variables we defined above."}]},{type:a,value:"\ntf"},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:o}]},{type:a,value:"global_variables_initializer"},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:p}]},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:q}]},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:o}]},{type:a,value:"run"},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:p}]},{type:b,tag:e,props:{className:[g,l]},children:[{type:a,value:q}]},{type:a,value:c}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Without setting "},{type:b,tag:f,props:{},children:[{type:a,value:C}]},{type:a,value:", Tensorflow allocates 95% of available GPU memory (according to "},{type:b,tag:n,props:{href:"https:\u002F\u002Fstackoverflow.com\u002Fquestions\u002F34514324\u002Ferror-using-tensorflow-with-gpu",rel:[r,s,t],target:u},children:[{type:a,value:"this SO question"}]},{type:a,value:")."}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Setting it to "},{type:b,tag:f,props:{},children:[{type:a,value:"0.333"}]},{type:a,value:" was too low and didn't allow for training to complete, but setting it to "},{type:b,tag:f,props:{},children:[{type:a,value:R}]},{type:a,value:" seemed to work just fine."}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"You can monitor GPU memory usage on NVIDIA cards with the following command:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"$ nvidia-smi\nSun Nov 19 17:03:03 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage\u002FCap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N\u002FA |\n| 27%   32C    P8    10W \u002F 180W |   6707MiB \u002F  8105MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0       350    C   \u002Fusr\u002Fbin\u002Fpython                               6365MiB |\n|    0       554    G   \u002Fusr\u002Flib\u002Fxorg-server\u002FXorg                       19MiB |\n|    0       588    G   \u002Fusr\u002Fbin\u002Fgnome-shell                            28MiB |\n|    0       853    G   \u002Fusr\u002Flib\u002Fxorg-server\u002FXorg                      186MiB |\n|    0       873    G   compton                                          2MiB |\n|    0      1114    G   ...el-token=A50C2F183DB4F79482A2D8768ED1B285    64MiB |\n|    0      2190    G   ...el-token=1AC796A35DBDCDBE07AEC2FC1E8026C4    35MiB |\n+-----------------------------------------------------------------------------+\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"I think this was a success! I'm fairly certain that we were leveraging the GPU to run the MNIST hand-written digit notebook. I didn't see messages that CUDNN loaded, but I can find versions of both CUDNN and CUDA in the docker image:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"root@80f65a971e9a:\u002F# ls \u002Fusr\u002Finclude\u002Fx86_64-linux-gnu\u002F\na.out.h  bits  cudnn_v6.h      fpu_control.h  gnu        python2.7\nasm      c++   expat_config.h  freetype2      ieee754.h  sys\n"}]}]}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"root@80f65a971e9a:\u002F# nvcc --version\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2016 NVIDIA Corporation\nBuilt on Tue_Jan_10_13:22:03_CST_2017\nCuda compilation tools, release 8.0, V8.0.61\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"In previous attempts I had to register for an NVIDIA developer account and install these packages, but they seem to be packaged with the container."}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Finally, we can check the installed python packages:"}]},{type:a,value:c},{type:b,tag:h,props:{className:[i]},children:[{type:b,tag:j,props:{className:[k,m]},children:[{type:b,tag:f,props:{},children:[{type:a,value:"root@80f65a971e9a:~# pip freeze | grep tensorflow\ntensorflow-gpu==1.4.0\ntensorflow-tensorboard==0.4.0rc2\nroot@80f65a971e9a:~#\n"}]}]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"This looks good, but I'm still not 100% sure that everything was done properly. I would like to learn more about Tensorflow and also play around with some examples using Tensorboard. Let me know if you have any questions or comments about this setup, I'm still learning! Thanks for reading."}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"Just for fun, here's a DeepDream rendering of a famous Donald Trump picture using Google's pre-trained "},{type:b,tag:n,props:{href:"https:\u002F\u002Fgithub.com\u002Fgoogle\u002Finception",rel:[r,s,t],target:u},children:[{type:a,value:"Inception model"}]},{type:a,value:P}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:b,tag:T,props:{alt:U,src:E},children:[]}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:a,value:"For comparison, here is the original image:"}]},{type:a,value:c},{type:b,tag:d,props:{},children:[{type:b,tag:T,props:{alt:U,src:"\u002Fstatic\u002Ftrump_original.jpg"},children:[]}]}]},dir:"\u002F2017\u002F11\u002F19",path:"\u002F2017\u002F11\u002F19\u002Ftensorflow-gpu-setup-with-docker-on-arch-linux.html",extension:".md",createdAt:V,updatedAt:V,raw:"\nI've tried installing the GPU version of Tensorflow a few times before and failed. There seems to be lots of confusion about the build process, of which there are many. Also, over the last few years there have been many new versions of the software needed to support the GPU version of Tensorflow as well as the first official release of Tensorflow itself (which is now on version 1.4), such as CUDA and cudnn, and different version of python. This is one more attempt at installing the GPU version of Tensor Flow on my Desktop PC that is currently dual booting with Arch Linux and Windows 10. I've decided to try going the docker route because it should eliminate some of the headache of missing depedencies. Here are the specs for my computer:\n\n- i7-6700K\n- NVIDIA GTX 1080\n- Asus Hero VIII motherboard\n- Arch Linux on a 128 GB SSD (Windows 10 is installed on a separate SSD)\n\n## Installing CUDA and cudnn\n\nWe don't need to install these when installing Tensorflow with Docker. Read to the bottom for more info.\n\n## Installing Docker\n\nTo install docker on our machine, let's start with the [Arch Wiki article on docker](https:\u002F\u002Fwiki.archlinux.org\u002Findex.php\u002FDocker).\n\nWe need to add the Loopback module to the Linux Kernel, so we run:\n\n```terminal\n# tee \u002Fetc\u002Fmodules-load.d\u002Floop.conf \u003C\u003C\u003C \"loop\"\n# modprobe loop\n$ reboot\n```\n\nAter rebooting we can install docker:\n\n```terminal\nyaourt -S docker\n```\n\nNow we want to add ourself to the docker group with the following command:\n\n```terminal\n$ sudo gpasswd -a brian docker\n[sudo] password for brian:\nAdding user brian to group docker\n```\n\nIf you run `groups`, you won't see docker listed in the groups you (brian) belong to. Run `newgrp docker` and then re-run docker and you should see `docker` listed with any other groups you belong to:\n\n`````terminal\n[brian@a1arch ~]$ groups\nwheel storage power users\n[brian@a1arch ~]$ newgrp docker\n                   -`                    brian@a1arch\n                  .o+`                   ------------\n                 `ooo\u002F                   OS: Arch Linux x86_64\n                `+oooo:                  Kernel: 4.12.8-2-ARCH\n               `+oooooo:                 Uptime: 6 mins\n               -+oooooo+:                Packages: 1127\n             `\u002F:-:++oooo+:               Shell: bash 4.4.12\n            `\u002F++++\u002F+++++++:              Resolution: 1920x1080\n           `\u002F++++++++++++++:             WM: i3\n          `\u002F+++ooooooooooooo\u002F`           Theme: Adwaita [GTK2]\n         .\u002Fooosssso++osssssso+`          Icons: Adwaita [GTK2]\n        .oossssso-````\u002Fossssss+`         Terminal: urxvt\n       -osssssso.      :ssssssso.        Terminal Font: Inconsolata-12\n      :osssssss\u002F        osssso+++.       CPU: Intel i7-6700K (8) @ 4.200GHz\n     \u002Fossssssss\u002F        +ssssooo\u002F-       GPU: NVIDIA GeForce GTX 1080\n   `\u002Fossssso+\u002F:-        -:\u002F+osssso+-     Memory: 3289MiB \u002F 15975MiB\n  `+sso+:-`                 `.-\u002F+oso:\n `++:.                           `-\u002F+\u002F\n .`                                 `\u002F\n\n[brian@a1arch ~]$ groups\ndocker wheel storage power users\n`````\n\nDoing this prevents us from having to write sudo each time we run docker.\n\nNext we need to start the docker daemon.\n\n```\n$ systemctl start docker\n==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-units ====\nAuthentication is required to start 'docker.service'.\nAuthenticating as: brian\nPassword:\n==== AUTHENTICATION COMPLETE ====\n$\n```\n\n### Side note\n\nThere seems to be an [Arch Linux-specific bug](https:\u002F\u002Fgithub.com\u002Fmoby\u002Fmoby\u002Fissues\u002F23289) which prevents us from enabling docker (and nvidia-docker which we will get next). There is a solution to downgrade to an older version of docker, or you can just start the docker service and the nvidia-docker service when you want to use them. I have found it faster to first start nvidia-docker and then start docker services.\n\nSo far so good. Next let's look at the Tensorflow documentation for installing Tensorflow with docker.\n\nWe need to install `nvidia-docker`:\n\n```terminal\n$ yaourt -S nvidia-docker\n[...]\n[sudo] password for brian:\nloading packages...\nresolving dependencies...\nlooking for conflicting packages...\n\nPackages (1) nvidia-docker-1.0.1-1\n\nTotal Installed Size:  13.34 MiB\n\n:: Proceed with installation? [Y\u002Fn]\n(1\u002F1) checking keys in keyring                                 [##################################] 100%\n(1\u002F1) checking package integrity                               [##################################] 100%\n(1\u002F1) loading package files                                    [##################################] 100%\n(1\u002F1) checking for file conflicts                              [##################################] 100%\n(1\u002F1) checking available disk space                            [##################################] 100%\n:: Processing package changes...\n(1\u002F1) installing nvidia-docker                                 [##################################] 100%\n=\u003E Prior to running 'CUDA'-containers, ensure that the nvidia-docker-plugin\n   is loaded. -\u003E https:\u002F\u002Fgithub.com\u002FNVIDIA\u002Fnvidia-docker#other-distributions\n\n*) manually; sudo -b nohup nvidia-docker-plugin \u003E \u002Ftmp\u002Fnvidia-docker.log\n\n*) automatically at startup; systemctl enable nvidia-docker.service\nOptional dependencies for nvidia-docker\n    cuda [installed]\n    nvidia [installed]\n    opencl-nvidia [installed]\n:: Running post-transaction hooks...\n(1\u002F1) Arming ConditionNeedsUpdate...\n```\n\nNext it says: Launch a Docker container that contains one of the TensorFlow binary images. Those images are available [here](https:\u002F\u002Fhub.docker.com\u002Fr\u002Ftensorflow\u002Ftensorflow\u002Ftags\u002F).\n\nNext I pulled the container with the `gpu-latest` tag and it started to download the container:\n\n```terminal\n$ docker pull tensorflow\u002Ftensorflow:gpu-latest\n[sudo] password for brian:\nlatest-gpu: Pulling from tensorflow\u002Ftensorflow\nae79f2514705: Pull complete\nc59d01a7e4ca: Pull complete\n41ba73a9054d: Pull complete\nf1bbfd495cc1: Pull complete\n0c346f7223e2: Pull complete\n5dcd01667896: Pull complete\nca677f607487: Downloading  180.7MB\u002F453MB\nb4637619a887: Download complete\n8c644ff287da: Downloading    224MB\u002F465.6MB\n119c5f576e79: Download complete\n009f82e71a7c: Download complete\ndbc0fb5872c7: Downloading  17.83MB\u002F66.54MB\n5ef01389c5b2: Waiting\n04f824004b76: Waiting\n5861b82f52e5: Waiting\na495a3b4e6e1: Waiting\n3a0a25b1bbaf: Pulling fs layer\nb76a0afeb1e1: Waiting\n```\n\nIt finished after several minutes:\n\n```terminal\nca677f607487: Pull complete\nb4637619a887: Pull complete\n8c644ff287da: Pull complete\n119c5f576e79: Pull complete\n009f82e71a7c: Pull complete\ndbc0fb5872c7: Pull complete\n5ef01389c5b2: Pull complete\n04f824004b76: Pull complete\n5861b82f52e5: Pull complete\na495a3b4e6e1: Pull complete\n3a0a25b1bbaf: Pull complete\nb76a0afeb1e1: Pull complete\nDigest: sha256:90e27448121b321c5ec66069fb2c718301df2ddaf25ba916b6f53719141572b0\nStatus: Downloaded newer image for tensorflow\u002Ftensorflow:latest-gpu\n$\n```\n\nLet's verify that it has the image:\n\n```terminal\n$ docker images\nREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\ntensorflow\u002Ftensorflow   latest-gpu          2f243a16ff63        13 days ago         3.36GB\n```\n\nNext let's start the `nvidia-docker` service:\n\n```terminal\n$ systemctl start nvidia-docker\n==== AUTHENTICATING FOR org.freedesktop.systemd1.manage-units ====\nAuthentication is required to start 'nvidia-docker.service'.\nAuthenticating as: brian\nPassword:\n==== AUTHENTICATION COMPLETE ====\n$\n```\n\nOK, we should be ready to launch the image:\n\n```terminal\n$ nvidia-docker run -it tensorflow\u002Ftensorflow:latest-gpu bash\nroot@761a62c1cff1:\u002Fnotebooks#\n```\n\nThis is looking good. Let's try to start python:\n\n```terminal\nroot@761a62c1cff1:\u002Fnotebooks# python\nPython 2.7.12 (default, Nov 19 2016, 06:48:10)\n[GCC 5.4.0 20160609] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\u003E\u003E\u003E import tensorflow as tf\n\u003E\u003E\u003E\n```\n\nThat works! Let's try out the classic MNIST hand-written digit classification problem that comes packaged as a notebook with the container image:\n\n```terminal\n$ nvidia-docker run -it -p 8888:8888 tensorflow\u002Ftensorflow:latest-gpu\n[sudo] password for brian:\n[I 21:54:26.671 NotebookApp] Writing notebook server cookie secret to \u002Froot\u002F.local\u002Fshare\u002Fjupyter\u002Fruntime\u002Fnotebook_cookie_secret\n[W 21:54:26.689 NotebookApp] WARNING: The notebook server is listening on all IP addresses and not using encryption. This is not recommended.\n[I 21:54:26.693 NotebookApp] Serving notebooks from local directory: \u002Fnotebooks\n[I 21:54:26.693 NotebookApp] 0 active kernels\n[I 21:54:26.693 NotebookApp] The Jupyter Notebook is running at:\n[I 21:54:26.693 NotebookApp] http:\u002F\u002F[all ip addresses on your system]:8888\u002F?token=cda89aff96a3d4a9741cc755aac07f65f3aa372f60a198bd\n[I 21:54:26.693 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n[C 21:54:26.693 NotebookApp]\n\n    Copy\u002Fpaste this URL into your browser when you connect for the first time,\n    to login with a token:\n        http:\u002F\u002Flocalhost:8888\u002F?token=cda89aff96a3d4a9741cc755aac07f65f3aa372f60a198bd\n[I 21:54:34.489 NotebookApp] 302 GET \u002F?token=cda89aff96a3d4a9741cc755aac07f65f3aa372f60a198bd (172.17.0.1) 0.32ms\n[I 21:54:59.019 NotebookApp] Writing notebook-signing key to \u002Froot\u002F.local\u002Fshare\u002Fjupyter\u002Fnotebook_secret\n[W 21:54:59.023 NotebookApp] Notebook 3_mnist_from_scratch.ipynb is not trusted\n[W 21:54:59.049 NotebookApp] 404 GET \u002Fnbextensions\u002Fwidgets\u002Fnotebook\u002Fjs\u002Fextension.js?v=20171119215426 (172.17.0.1) 4.38ms referer=http:\u002F\u002Flocalhost:8888\u002Fnotebooks\u002F3_mnist_from_scratch.ipynb\n[I 21:54:59.813 NotebookApp] Kernel started: 00027a3e-59ae-47ce-90a5-752a9d1fe075\n[I 21:55:00.199 NotebookApp] Adapting to protocol v5.1 for kernel 00027a3e-59ae-47ce-90a5-752a9d1fe075\n[I 21:56:59.815 NotebookApp] Saving file at \u002F3_mnist_from_scratch.ipynb\n[W 21:56:59.816 NotebookApp] Notebook 3_mnist_from_scratch.ipynb is not trusted\n2017-11-19 21:57:03.988627: I tensorflow\u002Fcore\u002Fplatform\u002Fcpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n2017-11-19 21:57:04.070873: I tensorflow\u002Fstream_executor\u002Fcuda\u002Fcuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2017-11-19 21:57:04.071129: I tensorflow\u002Fcore\u002Fcommon_runtime\u002Fgpu\u002Fgpu_device.cc:1030] Found device 0 with properties:\nname: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.7335\npciBusID: 0000:01:00.0\ntotalMemory: 7.92GiB freeMemory: 7.44GiB\n2017-11-19 21:57:04.071143: I tensorflow\u002Fcore\u002Fcommon_runtime\u002Fgpu\u002Fgpu_device.cc:1120] Creating TensorFlow device (\u002Fdevice:GPU:0) -\u003E (device: 0, name: GeForce GTX 1080, pci bus id: 0000:01:00.0, compute capability: 6.1)\n```\n\nI was only able to get the entire notebook to run after making a few small configuration tweaks to the tensorflow Interactive Session to fix some memory issues:\n\n```python\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.75)\n\ns = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))\n\n# Use our newly created session as the default for\n# subsequent operations.\ns.as_default()\n\n# Initialize all the variables we defined above.\ntf.global_variables_initializer().run()\n```\n\nWithout setting `gpu_options`, Tensorflow allocates 95% of available GPU memory (according to [this SO question](https:\u002F\u002Fstackoverflow.com\u002Fquestions\u002F34514324\u002Ferror-using-tensorflow-with-gpu)).\n\nSetting it to `0.333` was too low and didn't allow for training to complete, but setting it to `0.75` seemed to work just fine.\n\nYou can monitor GPU memory usage on NVIDIA cards with the following command:\n\n```\n$ nvidia-smi\nSun Nov 19 17:03:03 2017\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 384.59                 Driver Version: 384.59                    |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage\u002FCap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N\u002FA |\n| 27%   32C    P8    10W \u002F 180W |   6707MiB \u002F  8105MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0       350    C   \u002Fusr\u002Fbin\u002Fpython                               6365MiB |\n|    0       554    G   \u002Fusr\u002Flib\u002Fxorg-server\u002FXorg                       19MiB |\n|    0       588    G   \u002Fusr\u002Fbin\u002Fgnome-shell                            28MiB |\n|    0       853    G   \u002Fusr\u002Flib\u002Fxorg-server\u002FXorg                      186MiB |\n|    0       873    G   compton                                          2MiB |\n|    0      1114    G   ...el-token=A50C2F183DB4F79482A2D8768ED1B285    64MiB |\n|    0      2190    G   ...el-token=1AC796A35DBDCDBE07AEC2FC1E8026C4    35MiB |\n+-----------------------------------------------------------------------------+\n```\n\nI think this was a success! I'm fairly certain that we were leveraging the GPU to run the MNIST hand-written digit notebook. I didn't see messages that CUDNN loaded, but I can find versions of both CUDNN and CUDA in the docker image:\n\n```terminal\nroot@80f65a971e9a:\u002F# ls \u002Fusr\u002Finclude\u002Fx86_64-linux-gnu\u002F\na.out.h  bits  cudnn_v6.h      fpu_control.h  gnu        python2.7\nasm      c++   expat_config.h  freetype2      ieee754.h  sys\n```\n\n```terminal\nroot@80f65a971e9a:\u002F# nvcc --version\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2016 NVIDIA Corporation\nBuilt on Tue_Jan_10_13:22:03_CST_2017\nCuda compilation tools, release 8.0, V8.0.61\n```\n\nIn previous attempts I had to register for an NVIDIA developer account and install these packages, but they seem to be packaged with the container.\n\nFinally, we can check the installed python packages:\n\n```terminal\nroot@80f65a971e9a:~# pip freeze | grep tensorflow\ntensorflow-gpu==1.4.0\ntensorflow-tensorboard==0.4.0rc2\nroot@80f65a971e9a:~#\n```\n\nThis looks good, but I'm still not 100% sure that everything was done properly. I would like to learn more about Tensorflow and also play around with some examples using Tensorboard. Let me know if you have any questions or comments about this setup, I'm still learning! Thanks for reading.\n\nJust for fun, here's a DeepDream rendering of a famous Donald Trump picture using Google's pre-trained [Inception model](https:\u002F\u002Fgithub.com\u002Fgoogle\u002Finception):\n\n![png](\u002Fstatic\u002Ftrump.png)\n\nFor comparison, here is the original image:\n\n![png](\u002Fstatic\u002Ftrump_original.jpg)\n"}}],fetch:{},mutations:[]}}("text","element","\n","p","span","code","token","div","nuxt-content-highlight","pre","line-numbers","punctuation","language-text","a",".","(",")","nofollow","noopener","noreferrer","_blank","operator","=","li","true",-1,"icon","icon-link","gpu_options","comment","\u002Fstatic\u002Ftrump.png","docker","installing-cuda-and-cudnn",2,"Installing CUDA and cudnn","installing-docker","Installing Docker","side-note","Side note","h2","nvidia-docker",":"," tf","0.75","\n\n","img","png","2023-07-27T23:40:00.271Z")));