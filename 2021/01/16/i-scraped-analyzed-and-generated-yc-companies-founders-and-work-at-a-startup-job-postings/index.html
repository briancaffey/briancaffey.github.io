<!DOCTYPE html><html  lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><title>Scraping, analyzing and generating companies, founders and job postings from YC&#x27;s Work at a Startup</title><style>html{font-family:Montserrat,Arial,Sans Serif;font-size:16px;word-spacing:1px;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;box-sizing:border-box}*,:after,:before{box-sizing:border-box;margin:0}.button--green{border:1px solid #3b8070;border-radius:4px;color:#3b8070;display:inline-block;padding:10px 30px;text-decoration:none}.button--green:hover{background-color:#3b8070;color:#fff}.button--grey{border:1px solid #35495e;border-radius:4px;color:#35495e;display:inline-block;margin-left:15px;padding:10px 30px;text-decoration:none}.button--grey:hover{background-color:#35495e;color:#fff}</style><style>span.emoji-mart-emoji[data-v-d2ff5fdf]{padding:0}.selected[data-v-d2ff5fdf]{text-shadow:.25px 0 0 #000}.picker[data-v-d2ff5fdf]{margin-left:auto;margin-right:auto;position:absolute;top:10px;transform:translate(50%,50%)}.top[data-v-d2ff5fdf]{background-color:var(--color-primary);height:3px;width:100%}</style><style>.selected[data-v-ed0088f5]{text-shadow:.9px 0 0}</style><style>span.emoji-mart-emoji[data-v-2649ce61]{padding:0;transition:transform .2s}span.emoji-mart-emoji[data-v-2649ce61]:hover{transform:scale(1.3)}.centered[data-v-2649ce61]{left:50vw;margin-left:auto;margin-right:auto;position:absolute;right:50vw}</style><style>.emoji-mart,.emoji-mart *{-webkit-box-sizing:border-box;box-sizing:border-box;line-height:1.15}.emoji-mart{display:-webkit-box;display:-ms-flexbox;display:flex;font-family:-apple-system,BlinkMacSystemFont,Helvetica Neue,sans-serif;font-size:16px;-webkit-box-orient:vertical;-webkit-box-direction:normal;background:#fff;border:1px solid #d9d9d9;border-radius:5px;color:#222427;-ms-flex-direction:column;flex-direction:column;height:420px}.emoji-mart-emoji{background:none;border:none;-webkit-box-shadow:none;box-shadow:none;padding:6px}.emoji-mart-emoji span{display:inline-block}.emoji-mart-preview-emoji .emoji-mart-emoji span{font-size:32px;height:38px;width:38px}.emoji-type-native{font-family:Segoe UI Emoji,Segoe UI Symbol,Segoe UI,Apple Color Emoji,Twemoji Mozilla,Noto Color Emoji,EmojiOne Color,Android Emoji;word-break:keep-all}.emoji-type-image{background-size:6100%}.emoji-type-image.emoji-set-apple{background-image:url(https://unpkg.com/emoji-datasource-apple@15.0.1/img/apple/sheets-256/64.png)}.emoji-type-image.emoji-set-facebook{background-image:url(https://unpkg.com/emoji-datasource-facebook@15.0.1/img/facebook/sheets-256/64.png)}.emoji-type-image.emoji-set-google{background-image:url(https://unpkg.com/emoji-datasource-google@15.0.1/img/google/sheets-256/64.png)}.emoji-type-image.emoji-set-twitter{background-image:url(https://unpkg.com/emoji-datasource-twitter@15.0.1/img/twitter/sheets-256/64.png)}.emoji-mart-bar{border:0 solid #d9d9d9}.emoji-mart-bar:first-child{border-bottom-width:1px;border-top-left-radius:5px;border-top-right-radius:5px}.emoji-mart-bar:last-child{border-bottom-left-radius:5px;border-bottom-right-radius:5px;border-top-width:1px}.emoji-mart-scroll{overflow-y:scroll;position:relative;-webkit-box-flex:1;-ms-flex:1;flex:1;padding:0 6px 6px;will-change:transform;z-index:0;-webkit-overflow-scrolling:touch}.emoji-mart-anchors{display:-webkit-box;display:-ms-flexbox;display:flex;-webkit-box-orient:horizontal;-webkit-box-direction:normal;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-ms-flex-pack:justify;color:#858585;justify-content:space-between;line-height:0;padding:0 6px}.emoji-mart-anchor{display:block;position:relative;-webkit-box-flex:1;background:none;border:none;-webkit-box-shadow:none;box-shadow:none;-ms-flex:1 1 auto;flex:1 1 auto;overflow:hidden;padding:12px 4px;text-align:center;-webkit-transition:color .1s ease-out;transition:color .1s ease-out}.emoji-mart-anchor-selected,.emoji-mart-anchor:hover{color:#464646}.emoji-mart-anchor-selected .emoji-mart-anchor-bar{bottom:0}.emoji-mart-anchor-bar{background-color:#464646;bottom:-3px;height:3px;left:0;position:absolute;width:100%}.emoji-mart-anchors i{display:inline-block;max-width:22px;width:100%}.emoji-mart-anchors svg{fill:currentColor;max-height:18px}.emoji-mart .scroller{height:250px;position:relative;-webkit-box-flex:1;-ms-flex:1;flex:1;padding:0 6px 6px;will-change:transform;z-index:0;-webkit-overflow-scrolling:touch}.emoji-mart-search{margin-top:6px;padding:0 6px}.emoji-mart-search input{border:1px solid #d9d9d9;border-radius:25px;display:block;font-size:16px;outline:0;padding:.2em .6em;width:100%}.emoji-mart-search-results{height:250px;overflow-y:scroll}.emoji-mart-category{position:relative}.emoji-mart-category .emoji-mart-emoji span{cursor:default;position:relative;text-align:center;z-index:1}.emoji-mart-category .emoji-mart-emoji:hover:before,.emoji-mart-emoji-selected:before{background-color:#f4f4f4;border-radius:100%;content:"";height:100%;left:0;opacity:1;position:absolute;top:0;width:100%;z-index:0}.emoji-mart-category-label{position:-webkit-sticky;position:sticky;top:0}.emoji-mart-static .emoji-mart-category-label{position:relative;z-index:2}.emoji-mart-category-label h3{background-color:#fff;background-color:#fffffff2;display:block;font-size:16px;font-weight:500;padding:5px 6px;width:100%}.emoji-mart-emoji{display:inline-block;font-size:0;position:relative}.emoji-mart-no-results{color:#858585;font-size:14px;padding-top:70px;text-align:center}.emoji-mart-no-results .emoji-mart-category-label{display:none}.emoji-mart-no-results .emoji-mart-no-results-label{margin-top:.2em}.emoji-mart-no-results .emoji-mart-emoji:hover:before{content:none}.emoji-mart-preview{height:70px;position:relative}.emoji-mart-preview-data,.emoji-mart-preview-emoji,.emoji-mart-preview-skins{position:absolute;top:50%;-webkit-transform:translateY(-50%);-ms-transform:translateY(-50%);transform:translateY(-50%)}.emoji-mart-preview-emoji{left:12px}.emoji-mart-preview-data{left:68px;right:12px;word-break:break-all}.emoji-mart-preview-skins{right:30px;text-align:right}.emoji-mart-preview-name{font-size:14px}.emoji-mart-preview-shortname{color:#888;font-size:12px}.emoji-mart-preview-emoticon+.emoji-mart-preview-emoticon,.emoji-mart-preview-shortname+.emoji-mart-preview-emoticon,.emoji-mart-preview-shortname+.emoji-mart-preview-shortname{margin-left:.5em}.emoji-mart-preview-emoticon{color:#bbb;font-size:11px}.emoji-mart-title span{display:inline-block;vertical-align:middle}.emoji-mart-title .emoji-mart-emoji{padding:0}.emoji-mart-title-label{color:#999a9c;font-size:21px;font-weight:300}.emoji-mart-skin-swatches{background-color:#fff;border:1px solid #d9d9d9;border-radius:12px;font-size:0;padding:2px 0}.emoji-mart-skin-swatches-opened .emoji-mart-skin-swatch{padding:0 2px;width:16px}.emoji-mart-skin-swatches-opened .emoji-mart-skin-swatch-selected:after{opacity:.75}.emoji-mart-skin-swatch{display:inline-block;-webkit-transition-duration:.125s;transition-duration:.125s;-webkit-transition-property:width,padding;transition-property:width,padding;-webkit-transition-timing-function:ease-out;transition-timing-function:ease-out;vertical-align:middle;width:0}.emoji-mart-skin-swatch:first-child{-webkit-transition-delay:0s;transition-delay:0s}.emoji-mart-skin-swatch:nth-child(2){-webkit-transition-delay:.03s;transition-delay:.03s}.emoji-mart-skin-swatch:nth-child(3){-webkit-transition-delay:.06s;transition-delay:.06s}.emoji-mart-skin-swatch:nth-child(4){-webkit-transition-delay:.09s;transition-delay:.09s}.emoji-mart-skin-swatch:nth-child(5){-webkit-transition-delay:.12s;transition-delay:.12s}.emoji-mart-skin-swatch:nth-child(6){-webkit-transition-delay:.15s;transition-delay:.15s}.emoji-mart-skin-swatch-selected{padding:0 2px;position:relative;width:16px}.emoji-mart-skin-swatch-selected:after{background-color:#fff;border-radius:100%;content:"";height:4px;left:50%;margin:-2px 0 0 -2px;opacity:0;pointer-events:none;position:absolute;top:50%;-webkit-transition:opacity .2s ease-out;transition:opacity .2s ease-out;width:4px}.emoji-mart-skin{border-radius:100%;display:inline-block;max-width:12px;padding-top:100%;width:100%}.emoji-mart-skin-tone-1{background-color:#ffc93a}.emoji-mart-skin-tone-2{background-color:#fadcbc}.emoji-mart-skin-tone-3{background-color:#e0bb95}.emoji-mart-skin-tone-4{background-color:#bf8f68}.emoji-mart-skin-tone-5{background-color:#9b643d}.emoji-mart-skin-tone-6{background-color:#594539}.emoji-mart .vue-recycle-scroller{position:relative}.emoji-mart .vue-recycle-scroller.direction-vertical:not(.page-mode){overflow-y:auto}.emoji-mart .vue-recycle-scroller.direction-horizontal:not(.page-mode){overflow-x:auto}.emoji-mart .vue-recycle-scroller.direction-horizontal{display:-webkit-box;display:-ms-flexbox;display:flex}.emoji-mart .vue-recycle-scroller__slot{-webkit-box-flex:1;-ms-flex:auto 0 0px;flex:auto 0 0}.emoji-mart .vue-recycle-scroller__item-wrapper{-webkit-box-flex:1;-webkit-box-sizing:border-box;box-sizing:border-box;-ms-flex:1;flex:1;overflow:hidden;position:relative}.emoji-mart .vue-recycle-scroller.ready .vue-recycle-scroller__item-view{left:0;position:absolute;top:0;will-change:transform}.emoji-mart .vue-recycle-scroller.direction-vertical .vue-recycle-scroller__item-wrapper{width:100%}.emoji-mart .vue-recycle-scroller.direction-horizontal .vue-recycle-scroller__item-wrapper{height:100%}.emoji-mart .vue-recycle-scroller.ready.direction-vertical .vue-recycle-scroller__item-view{width:100%}.emoji-mart .vue-recycle-scroller.ready.direction-horizontal .vue-recycle-scroller__item-view{height:100%}.emoji-mart .resize-observer[data-v-b329ee4c]{background-color:transparent;border:none;opacity:0}.emoji-mart .resize-observer[data-v-b329ee4c],.emoji-mart .resize-observer[data-v-b329ee4c] object{display:block;height:100%;left:0;overflow:hidden;pointer-events:none;position:absolute;top:0;width:100%;z-index:-1}.emoji-mart-search .hidden{display:none;visibility:hidden}</style><style>span.emoji-mart-emoji[data-v-03afe4fa]{padding:0;transition:transform .2s}span.emoji-mart-emoji[data-v-03afe4fa]:hover{transform:scale(1.3)}.picker[data-v-03afe4fa]{left:0;margin-left:auto;margin-right:auto;position:absolute;right:0;z-index:10000000000}.localepicker[data-v-03afe4fa]{background-color:var(--bg)}.localeText[data-v-03afe4fa]{color:var(--color-primary)}</style><style>.tag[data-v-eb2063c1]{background-color:var(--color-tag);transition:transform .2s}.tag[data-v-eb2063c1]:hover{transform:scale(1.05)}</style><style>pre code .line{display:block}</style><link rel="stylesheet" href="/_nuxt/entry.C_qR6n1r.css" crossorigin><link rel="stylesheet" href="/_nuxt/app.BAXwoxDU.css" crossorigin><link rel="preload" as="fetch" crossorigin="anonymous" href="/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings/_payload.json?711989cd-b755-45e7-b273-f0754c0f755f"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/U2gz5u3s.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/D3Q7tgbv.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/CAEbC5FA.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/BE4wn3fs.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/ivQeT1ix.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/BwRoW_yn.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Cz9IHiFo.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/C_-EP1mu.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/CeeZmN6j.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/CDdUvEIO.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/PV-tEdEs.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/BWfwsB7c.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/iyVKi4R7.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/CZYsndi7.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/H6MlkUZ9.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/CaawH2jc.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/D7kgLHFI.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/Fo6dHlhp.js"><link rel="modulepreload" as="script" crossorigin href="/_nuxt/C94jHEjt.js"><link rel="preload" as="fetch" fetchpriority="low" crossorigin="anonymous" href="/_nuxt/builds/meta/711989cd-b755-45e7-b273-f0754c0f755f.json"><link rel="prefetch" as="script" crossorigin href="/_nuxt/Dk67likk.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/BU1UZLbD.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/CZvWFDQc.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/yEdly4JE.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/CvvIFhEj.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/B5fv-1Xq.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/DFI9gCi9.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/DE3BAxce.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/uYY1jy-2.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/BiTVazLu.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/DnLIRtEt.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/CZsi5-5V.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/BDjFqGfp.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/Cebmboq7.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/CRRfaG9P.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/fV3BeRRD.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/6PKCu2pi.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/HSA0rOnf.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/Dbk39hGM.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/DlT8tiJO.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/b04OUO_Q.js"><link rel="prefetch" as="script" crossorigin href="/_nuxt/DPR8_a9D.js"><meta hid="description" name="description" content="Brian Caffey's personal website"><link rel="icon" type="image/x-icon" href="/favicon.ico"><meta name="robots" content="all"><meta property="twitter:creator" content="@briancaffey"><meta property="twitter:site" content="@briancaffey"><meta property="og:title" content="Scraping, analyzing and generating companies, founders and job postings from YC's Work at a Startup"><meta property="og:description" content="Scraping, analyzing and generating companies, founders and job postings from YC's Work at a Startup"><meta property="og:image" content="https://briancaffey.github.io/static/waas/yc.png"><meta property="twitter:image" content="https://briancaffey.github.io/static/waas/yc.png"><meta property="twitter:card" content="summary_large_image"><script type="module" src="/_nuxt/U2gz5u3s.js" crossorigin></script><script>"use strict";(()=>{const t=window,e=document.documentElement,c=["dark","light"],n=getStorageValue("localStorage","nuxt-color-mode")||"system";let i=n==="system"?u():n;const r=e.getAttribute("data-color-mode-forced");r&&(i=r),l(i),t["__NUXT_COLOR_MODE__"]={preference:n,value:i,getColorScheme:u,addColorScheme:l,removeColorScheme:d};function l(o){const s=""+o+"-mode",a="";e.classList?e.classList.add(s):e.className+=" "+s,a&&e.setAttribute("data-"+a,o)}function d(o){const s=""+o+"-mode",a="";e.classList?e.classList.remove(s):e.className=e.className.replace(new RegExp(s,"g"),""),a&&e.removeAttribute("data-"+a)}function f(o){return t.matchMedia("(prefers-color-scheme"+o+")")}function u(){if(t.matchMedia&&f("").media!=="not all"){for(const o of c)if(f(":"+o).matches)return o}return"light"}})();function getStorageValue(t,e){switch(t){case"localStorage":return window.localStorage.getItem(e);case"sessionStorage":return window.sessionStorage.getItem(e);case"cookie":return getCookie(e);default:return null}}function getCookie(t){const c=("; "+window.document.cookie).split("; "+t+"=");if(c.length===2)return c.pop()?.split(";").shift()}</script></head><body><div id="__nuxt"><div><div><div data-v-d2ff5fdf><div class="mx-auto flex py-2 px-2 sm:px-4 items-center max-w-6xl justify-center" data-v-d2ff5fdf><div class="justify-left flex-grow flex-cols-4" data-v-d2ff5fdf><a href="/" class="text-xl" data-v-d2ff5fdf><span class="hidden sm:inline text-2xl" data-v-d2ff5fdf>Brian Caffey</span><span class="inline sm:hidden" data-v-d2ff5fdf>JBC</span></a></div><div class="flex-grow relative" data-v-d2ff5fdf><nav z-index="10000" data-v-d2ff5fdf data-v-ed0088f5><div data-v-ed0088f5><ul class="items-right float-right hidden md:flex" data-v-ed0088f5><li class="px-4 text-lg" data-v-ed0088f5><a href="/blog/1" class="" data-v-ed0088f5>Blog</a></li><li class="px-4 text-lg" data-v-ed0088f5><a href="/contact" class="" data-v-ed0088f5>Contact</a></li></ul><div class="flex justify-end md:hidden z-1000" data-v-ed0088f5><button class="flex items-center px-3 py-2 border rounded menu-icon" data-v-ed0088f5><svg class="fill-current h-3 w-3" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg" data-v-ed0088f5><title data-v-ed0088f5>Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0v-2z" data-v-ed0088f5></path></svg></button></div><!----></div></nav></div></div><div class="picker" data-v-d2ff5fdf><div class="centered" data-v-d2ff5fdf data-v-2649ce61><div class="grid items-center justify-center" data-v-2649ce61><ul class="flex px-4" data-v-2649ce61><!--[--><li class="md:px-1 px-1 cursor-pointer" data-v-2649ce61><span aria-label="üñ•Ô∏è, desktop_computer" class="emoji-mart-emoji" data-v-2649ce61><span class="emoji-set-apple emoji-type-image" style="background-position:51.67% 95%;width:32px;height:32px;"></span></span></li><li class="md:px-1 px-1 cursor-pointer" data-v-2649ce61><span aria-label="üåû, sun_with_face" class="emoji-mart-emoji" data-v-2649ce61><span class="emoji-set-apple emoji-type-image" style="background-position:8.33% 48.33%;width:32px;height:32px;"></span></span></li><li class="md:px-1 px-1 cursor-pointer" data-v-2649ce61><span aria-label="üåö, new_moon_with_face" class="emoji-mart-emoji" data-v-2649ce61><span class="emoji-set-apple emoji-type-image" style="background-position:8.33% 41.67%;width:32px;height:32px;"></span></span></li><li class="md:px-1 px-1 cursor-pointer" data-v-2649ce61><span aria-label="‚òï, coffee" class="emoji-mart-emoji" data-v-2649ce61><span class="emoji-set-apple emoji-type-image" style="background-position:95% 30%;width:32px;height:32px;"></span></span></li><!--]--><li class="md:px-1 px-1 cursor-pointer" data-v-2649ce61><div data-v-2649ce61 data-v-03afe4fa><ul data-v-03afe4fa><li class="md:px-1 px-1 cursor-pointer" data-v-03afe4fa><span aria-label="üá∫üá∏, us, flag-us" class="emoji-mart-emoji" data-v-03afe4fa><span class="emoji-set-apple emoji-type-image" style="background-position:6.67% 45%;width:32px;height:32px;"></span></span></li></ul><div class="rounded-md z-10 picker" data-v-03afe4fa><!----></div></div></li></ul></div></div></div></div><!--[--><article><img onerror="this.setAttribute(&#39;data-error&#39;, 1)" alt="Scraping, analyzing and generating companies, founders and job postings from YC&#39;s Work at a Startup" data-nuxt-img srcset="/_ipx/f_webp/static/waas/yc.png 1x, /_ipx/f_webp/static/waas/yc.png 2x" class="pt-2 w-full object-cover" style="height:32rem;" src="/_ipx/f_webp/static/waas/yc.png"><div class="mx-auto max-w-5xl px-2 sm:px-4 md:px-4 lg:px-16 mt-2"><h1 class="prose text-4xl leading-9 py-4 font-bold">Scraping, analyzing and generating companies, founders and job postings from YC&#39;s Work at a Startup</h1><div class="flex flex-wrap -ml-1 py-2"><!--[--><a href="/blog/tags/python/" class="" data-v-eb2063c1><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-eb2063c1>python üè∑Ô∏è <!----></div></a><a href="/blog/tags/data/" class="" data-v-eb2063c1><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-eb2063c1>data üè∑Ô∏è <!----></div></a><a href="/blog/tags/scraping/" class="" data-v-eb2063c1><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-eb2063c1>scraping üè∑Ô∏è <!----></div></a><a href="/blog/tags/startups/" class="" data-v-eb2063c1><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-eb2063c1>startups üè∑Ô∏è <!----></div></a><a href="/blog/tags/yc/" class="" data-v-eb2063c1><div class="px-2 text-lg text-white shadow rounded-lg bg-black mx-1 mb-1 uppercase cursor-pointer tag" data-v-eb2063c1>yc üè∑Ô∏è <!----></div></a><!--]--></div><!----><p class="blog-date text-gray-500 mb-4">Last updated January 16, 2021</p><!----><div class="markdown"><p><!--[-->I always enjoy reading about new batches of YC companies. I came across YC&#39;s <a href="https://www.workatastartup.com/" rel="nofollow"><!--[-->Work at a Startup<!--]--></a> (WaaS) recently while browsing HN and got pretty curious about all of the available data points on companies, jobs and founders.<!--]--></p><p><!--[-->This article will outline my process for collecting, cleaning, visualizing and analyzing the dataset.<!--]--></p><p><!--[-->After filling out my profile, WaaS recommended 750 matching YC startups which collectively list 1614 open positions. I think this is all of the available job openings and hiring companies, but I&#39;m not sure.<!--]--></p><h2 id="scraping-data"><a href="#scraping-data"><!--[-->Scraping data<!--]--></a></h2><p><!--[-->I&#39;ve used a few different tools to scrape data and automate web browsers. For collecting this data, I ended up just writing some JavaScript directly in the browser console and <code><!--[-->Ctrl+S<!--]--></code>aved the page HTML and assets (company logos and founder photos).<!--]--></p><pre class="language-js shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span class="sJ8bj">// expand each companies to see full details and all postings
</span></span><span class="line" line="2"><span class="szBVR">const</span><span class="sj4cs"> toggleDetails</span><span class="szBVR"> =</span><span class="sVt8B"> document.</span><span class="sScJk">getElementsByClassName</span><span class="sVt8B">(</span><span class="sZZnC">&quot;checkbox-inline&quot;</span><span class="sVt8B">)[</span><span class="sj4cs">0</span><span class="sVt8B">]
</span></span><span class="line" line="3"><span class="sVt8B">toggleDetails.</span><span class="sScJk">click</span><span class="sVt8B">()
</span></span><span class="line" line="4"><span emptylineplaceholder="true">
</span></span><span class="line" line="5"><span class="sJ8bj">// automated scrolling, run this until it gets to the end
</span></span><span class="line" line="6"><span class="szBVR">const</span><span class="sj4cs"> scroll</span><span class="szBVR"> =</span><span class="sScJk"> setInterval</span><span class="sVt8B">(() </span><span class="szBVR">=&gt;</span><span class="sVt8B"> {window.</span><span class="sScJk">scrollTo</span><span class="sVt8B">(</span><span class="sj4cs">0</span><span class="sVt8B">,document.body.scrollHeight);}, </span><span class="sj4cs">3000</span><span class="sVt8B">)
</span></span><span class="line" line="7"><span emptylineplaceholder="true">
</span></span><span class="line" line="8"><span class="sJ8bj">// when it no longer scrolls, clear the interval
</span></span><span class="line" line="9"><span class="sScJk">clearInterval</span><span class="sVt8B">(scroll)
</span></span><span class="line" line="10"><span class="sVt8B">    &lt;</span><span class="sj4cs">vue-apex-charts
</span></span><span class="line" line="11"><span class="sScJk">      v-if</span><span class="szBVR">=</span><span class="sZZnC">&quot;chartOptions &amp;&amp; series&quot;
</span></span><span class="line" line="12"><span class="sScJk">      type</span><span class="szBVR">=</span><span class="sZZnC">&quot;bar&quot;
</span></span><span class="line" line="13"><span class="sScJk">      height</span><span class="szBVR">=</span><span class="sZZnC">&quot;350&quot;
</span></span><span class="line" line="14"><span class="s7hpK">      :options=&quot;chartOptions&quot;
</span></span><span class="line" line="15"><span class="s7hpK">      :series=&quot;series&quot;
</span></span><span class="line" line="16"><span class="sVt8B">    &gt;&lt;/</span><span class="sj4cs">vue-apex-charts</span><span class="sVt8B">&gt;
</span></span><span class="line" line="17"><span class="sJ8bj">// expand each job listing:
</span></span><span class="line" line="18"><span class="szBVR">const</span><span class="sj4cs"> jobs</span><span class="szBVR"> =</span><span class="sVt8B"> document.</span><span class="sScJk">getElementsByClassName</span><span class="sVt8B">(</span><span class="sZZnC">&quot;job-name&quot;</span><span class="sVt8B">)
</span></span><span class="line" line="19"><span class="szBVR">for</span><span class="sVt8B"> (</span><span class="szBVR">let</span><span class="sVt8B"> job </span><span class="szBVR">of</span><span class="sVt8B"> jobs) {
</span></span><span class="line" line="20"><span class="sVt8B">    job.</span><span class="sScJk">click</span><span class="sVt8B">()
</span></span><span class="line" line="21"><span class="sVt8B">}
</span></span><span class="line" line="22"><span emptylineplaceholder="true">
</span></span><span class="line" line="23"><span class="sJ8bj">// now Ctrl+S to save the HTML and images
</span></span></code><!--]--></pre><h2 id="parsing-the-html"><a href="#parsing-the-html"><!--[-->Parsing the HTML<!--]--></a></h2><p><!--[-->Next I&#39;ll parse the company data into a python list of dictionaries and then <code><!--[-->dumps<!--]--></code> it into a JSON file. This code is a little bit scrappy, here&#39;s the pseudo code:<!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span># pseudo code for parsing data
</span></span><span class="line" line="2"><span>html = open(&quot;data.html&quot;)
</span></span><span class="line" line="3"><span>parsed_html = parseHtml(html)
</span></span><span class="line" line="4"><span emptylineplaceholder="true">
</span></span><span class="line" line="5"><span>companies = []
</span></span><span class="line" line="6"><span>for company in parsed_html.find_all(&quot;company&quot;)
</span></span><span class="line" line="7"><span>    # company stats, founders and jobs
</span></span><span class="line" line="8"><span>    company_details = extract_company_details(company)
</span></span><span class="line" line="9"><span>    companies.append(company_details)
</span></span><span class="line" line="10"><span emptylineplaceholder="true">
</span></span><span class="line" line="11"><span>with open(&quot;output.json&quot;, &quot;wb&quot;) as f:
</span></span><span class="line" line="12"><span>    f.write(json.dumps(companies))
</span></span></code><!--]--></pre><p><!--[-->To scrape the data I used my go-to library for this type of task: BeautifulSoup. There were a few tricky parts:<!--]--></p><ul><!--[--><li><!--[-->Job details (visa requirements, salary, equity) were all labelled with the same class and they were inconsistent (sometimes salary or equity or both were excluded, for example).<!--]--></li><li><!--[-->Equity was mostly a range of percentages such as <code><!--[-->1% - 2%<!--]--></code> and sometimes a single percentage like <code><!--[-->1.5%<!--]--></code>. Some salary ranges had typos like <code><!--[-->$90k - $10k<!--]--></code><!--]--></li><li><!--[-->Years of experience required was also inconsistent with mixed types like <code><!--[-->3+ Years<!--]--></code>, <code><!--[-->Any (recent grad ok)<!--]--></code> and <code><!--[-->Senior or Juniors<!--]--></code>, for example.<!--]--></li><!--]--></ul><p><!--[-->These were all pretty easy to account for, it just required some additional logic to handle default values for <code><!--[-->&lt;div&gt;<!--]--></code>s that were not included as well as mixed data types and representations where there were inconsistencies.<!--]--></p><p><!--[-->The resulting JSON structure for the big array of companies looks like this:<!--]--></p><pre class="language-json shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span class="sVt8B">[
</span></span><span class="line" line="2"><span class="sVt8B">    {
</span></span><span class="line" line="3"><span class="sj4cs">        &quot;company_name&quot;</span><span class="sVt8B">: </span><span class="sZZnC">&quot;Startup A&quot;</span><span class="sVt8B">,
</span></span><span class="line" line="4"><span class="sj4cs">        &quot;logo&quot;</span><span class="sVt8B">: </span><span class="sZZnC">&quot;logo.png&quot;</span><span class="sVt8B">,
</span></span><span class="line" line="5"><span class="sj4cs">        &quot;jobs&quot;</span><span class="sVt8B">: [
</span></span><span class="line" line="6"><span class="sVt8B">            {
</span></span><span class="line" line="7"><span class="sj4cs">                &quot;title&quot;</span><span class="sVt8B">: </span><span class="sZZnC">&quot;Software Engineer&quot;</span><span class="sVt8B">,
</span></span><span class="line" line="8"><span class="sj4cs">                &quot;skills&quot;</span><span class="sVt8B">: [</span><span class="sZZnC">&quot;python&quot;</span><span class="sVt8B">, </span><span class="sZZnC">&quot;javascript&quot;</span><span class="sVt8B">],
</span></span><span class="line" line="9"><span class="sj4cs">                &quot;salary&quot;</span><span class="sVt8B">: {
</span></span><span class="line" line="10"><span class="sj4cs">                    &quot;min&quot;</span><span class="sVt8B">: </span><span class="sj4cs">90000</span><span class="sVt8B">,
</span></span><span class="line" line="11"><span class="sj4cs">                    &quot;max&quot;</span><span class="sVt8B">: </span><span class="sj4cs">110000</span><span class="sVt8B">,
</span></span><span class="line" line="12"><span class="sj4cs">                    &quot;avg&quot;</span><span class="sVt8B">: </span><span class="sj4cs">100000
</span></span><span class="line" line="13"><span class="sVt8B">                }
</span></span><span class="line" line="14"><span class="sVt8B">            }
</span></span><span class="line" line="15"><span class="sVt8B">        ],
</span></span><span class="line" line="16"><span class="sj4cs">        &quot;founders&quot;</span><span class="sVt8B">: [
</span></span><span class="line" line="17"><span class="sVt8B">            {
</span></span><span class="line" line="18"><span class="sj4cs">                &quot;name&quot;</span><span class="sVt8B">: </span><span class="sZZnC">&quot;Founder Name&quot;</span><span class="sVt8B">,
</span></span><span class="line" line="19"><span class="sj4cs">                &quot;linkedin&quot;</span><span class="sVt8B">: </span><span class="sZZnC">&quot;https://linkedin.com/founder&quot;</span><span class="sVt8B">,
</span></span><span class="line" line="20"><span class="sj4cs">                &quot;education&quot;</span><span class="sVt8B">: </span><span class="sZZnC">&quot;University A&quot;</span><span class="sVt8B">,
</span></span><span class="line" line="21"><span class="sj4cs">                &quot;image&quot;</span><span class="sVt8B">: </span><span class="sZZnC">&quot;abc.png&quot;
</span></span><span class="line" line="22"><span class="sVt8B">            }
</span></span><span class="line" line="23"><span class="sVt8B">        ]
</span></span><span class="line" line="24"><span class="sVt8B">    }
</span></span><span class="line" line="25"><span class="sVt8B">]
</span></span></code><!--]--></pre><h2 id="analysis"><a href="#analysis"><!--[-->Analysis<!--]--></a></h2><p><!--[-->Here are some of the biggest questions I wanted to answer along with some simple python I used for extracting data from the main dictionary/JSON object containing all companies and jobs. For the following code, assume I have read the JSON file back into a python dictionary.<!--]--></p><h3 id="what-are-the-most-in-demand-skills-for-yc-jobs"><a href="#what-are-the-most-in-demand-skills-for-yc-jobs"><!--[-->What are the most in demand skills for YC Jobs?<!--]--></a></h3><p><!--[-->I think skills are included mostly for engineering roles (not so much for sales, marketing, etc.). Here are the top skills:<!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span>skills = []
</span></span><span class="line" line="2"><span>for company in company_list:
</span></span><span class="line" line="3"><span>    if company[&quot;jobs&quot;] is not None:
</span></span><span class="line" line="4"><span>        for job in company[&quot;jobs&quot;]:
</span></span><span class="line" line="5"><span>            if job[&quot;job_skills&quot;] is not None:
</span></span><span class="line" line="6"><span>                for skill in job[&quot;job_skills&quot;]:
</span></span><span class="line" line="7"><span>                    skills.append(skill)
</span></span><span class="line" line="8"><span emptylineplaceholder="true">
</span></span><span class="line" line="9"><span>top_skills = Counter(skills).most_common()
</span></span><span class="line" line="10"><span>print(top_skills)
</span></span></code><!--]--></pre><span></span><p><!--[-->I&#39;ll try to briefly describe what I know about each of these if I know what it means (without Googling!):<!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span emptylineplaceholder="true">
</span></span><span class="line" line="2"><span>[
</span></span><span class="line" line="3"><span> (&#39;JAVASCRIPT&#39;, 330), # I have been using JS a lot recently with Vue
</span></span><span class="line" line="4"><span> (&#39;REACT&#39;, 323), # As a prefer to use Vue, I haven&#39;t used React in a while
</span></span><span class="line" line="5"><span> (&#39;PYTHON&#39;, 312), # I&#39;m a big Python fan, it was the first language I touched, happy to see it near the top!
</span></span><span class="line" line="6"><span> (&#39;AMAZON WEB SERVICES (AWS)&#39;, 200), # I like AWS a lot. I have really been enjoying using CDK to build infrastructure
</span></span><span class="line" line="7"><span> (&#39;NODE.JS&#39;, 195), # I would to do more with node this year. I generally use Python for web apps
</span></span><span class="line" line="8"><span> (&#39;POSTGRESQL&#39;, 132), # I have used Postgres ever since I started using Django and like it a lot
</span></span><span class="line" line="9"><span> (&#39;TYPESCRIPT&#39;, 114), # this is another goal of mine for 2021, it seems like an inevitability
</span></span><span class="line" line="10"><span> (&#39;JAVA&#39;, 79), # I have never used Java
</span></span><span class="line" line="11"><span> (&#39;SQL&#39;, 74), # I usually don&#39;t write my own SQL queries; I view SQL through the lense of an ORM
</span></span><span class="line" line="12"><span> (&#39;RUBY ON RAILS&#39;, 72), # I haven&#39;t used RoR
</span></span><span class="line" line="13"><span> (&#39;CSS&#39;, 71), # I like CSS Frameworks. Recently I&#39;m into Tailwind and Material UI. This site uses Tailwind
</span></span><span class="line" line="14"><span> (&#39;HTML&#39;, 71),
</span></span><span class="line" line="15"><span> (&#39;DOCKER&#39;, 66), # I am a big container fan! It is my preferred way to run software, locally and in the cloud
</span></span><span class="line" line="16"><span> (&#39;KUBERNETES&#39;, 58), # I read the Manning book on k8s. I prefer ECS or Swarm, but I might try using it more
</span></span><span class="line" line="17"><span> (&#39;GO&#39;, 58), # I haven&#39;t ever used Go, but it doesn&#39;t look too bad coming from Python
</span></span><span class="line" line="18"><span> (&#39;REACT NATIVE&#39;, 58),
</span></span><span class="line" line="19"><span> (&#39;C++&#39;, 55), # Also haven&#39;t used this, but I have a book on it
</span></span><span class="line" line="20"><span> (&#39;GRAPHQL&#39;, 48), # I tried GraphQL and built a HN clone in Django. I prefer REST but I get the appeal (for frontend developers)
</span></span><span class="line" line="21"><span> (&#39;GOOGLE CLOUD&#39;, 46), # I&#39;m not a big GCP as I mostly use AWS and Digital Ocean but I would like to try Cloud Run
</span></span><span class="line" line="22"><span> (&#39;RUBY&#39;, 44), # I haven&#39;t used it
</span></span><span class="line" line="23"><span> (&#39;DJANGO&#39;, 44), # Django is my go-to tool for building web apps and APIs. I love the admin, ORM and DRF
</span></span><span class="line" line="24"><span> (&#39;MACHINE LEARNING&#39;, 44), # I am familiar with some ML techniques but not very well practiced
</span></span><span class="line" line="25"><span> (&#39;MONGODB&#39;, 43), # Have used it before, but I try to use the postgres JSONField for storing NoSQL data when possible
</span></span><span class="line" line="26"><span> (&#39;IOS&#39;, 38), # I have an iPhone, but haven&#39;t used a Mac in a long time, mostly on Linux and Windows
</span></span><span class="line" line="27"><span> (&#39;MYSQL&#39;, 36), # I tend to use Postgres, I don&#39;t think I&#39;ve ever used this
</span></span><span class="line" line="28"><span> (&#39;ANDROID&#39;, 35), # Not something I have worked with
</span></span><span class="line" line="29"><span> (&#39;DATA ANALYTICS&#39;, 32), # I do a lot of this
</span></span><span class="line" line="30"><span> (&#39;GIT&#39;, 30), # I&#39;m very slowly trying to learn advanced git features. I have many abandoned &quot;rebase-practice&quot; repos
</span></span><span class="line" line="31"><span> (&#39;ANGULAR&#39;, 29), # I tried it once for about an hour, I know that people love to hate it, I&#39;m just not sure why
</span></span><span class="line" line="32"><span> (&#39;SWIFT&#39;, 29), # This is apparently a very popular language and has use cases outside of mobile development, but I&#39;ve never used it
</span></span><span class="line" line="33"><span> (&#39;LINUX&#39;, 28), # I spend lot of time using Linux machines, mostly Ubuntu.
</span></span><span class="line" line="34"><span> (&#39;SOFTWARE ARCHITECTURE&#39;, 24), # I like using diagrams.net to draw application infrastructure
</span></span><span class="line" line="35"><span> (&#39;KOTLIN&#39;, 23), # I think this is a framework for Java/Android?
</span></span><span class="line" line="36"><span> (&#39;TENSORFLOW&#39;, 22), # Google DL/ML library that I&#39;ll try to use later in this article
</span></span><span class="line" line="37"><span> (&#39;DISTRIBUTED SYSTEMS&#39;, 22), # Using AWS, I guess I have technically designed distributed systems but I wouldn&#39;t call it one of my skills
</span></span><span class="line" line="38"><span> (&#39;PHP&#39;, 22), # I almost learned it to support a WordPress site but opted to use JAMStack instead
</span></span><span class="line" line="39"><span> (&#39;DATA WAREHOUSING&#39;, 22), # I have used Google BigQuery before which I think counts for this skill
</span></span><span class="line" line="40"><span> (&#39;DEEP LEARNING&#39;, 20), # I&#39;m going to try to use this later in this article
</span></span><span class="line" line="41"><span> (&#39;DATA MODELING&#39;, 20), # To me this means writing Django models, or thinking about how to structure an API/json data, etc.
</span></span><span class="line" line="42"><span> (&#39;C#&#39;, 19), # Micrsoft language used for different things including game dev with Unity
</span></span><span class="line" line="43"><span> (&#39;FLASK&#39;, 19), # I&#39;m familiar with it but mostly prefer Django&#39;s batteries included philosophy
</span></span><span class="line" line="44"><span> (&#39;C&#39;, 19), # In learning about Linux I have read a bit of C, but never written any
</span></span><span class="line" line="45"><span> (&#39;REDIS&#39;, 18), # Fast, in memory key-value store with multiple data types. I use it for a few different things
</span></span><span class="line" line="46"><span> (&#39;MICROSERVICES&#39;, 18), #
</span></span><span class="line" line="47"><span> (&#39;COMPUTER VISION&#39;, 17), # I once used OpenCV on my Raspberry Pi
</span></span><span class="line" line="48"><span> (&#39;EXPRESS&#39;, 15), # I&#39;d like to learn how to use this in 2021
</span></span><span class="line" line="49"><span> (&#39;BASH/SHELL&#39;, 13), # I&#39;m not very fluent in bash but
</span></span><span class="line" line="50"><span> (&#39;OBJECTIVE-C&#39;, 13), # I haven&#39;t used this but I know it is popular for iOS development
</span></span><span class="line" line="51"><span> (&#39;FIREBASE&#39;, 12), # I have played around with Firebase, but I haven&#39;t built anything with it
</span></span><span class="line" line="52"><span> (&#39;SCALA&#39;, 11), # Functional programming language for JVM, I haven&#39;t used it
</span></span><span class="line" line="53"><span> (&#39;SOFTWARE SECURITY&#39;, 11),
</span></span><span class="line" line="54"><span> (&#39;UNITY&#39;, 11), # I used this once before to play around with VR development for HTC Vive
</span></span><span class="line" line="55"><span> (&#39;R&#39;, 11), # I haven&#39;t used R before, and I would probably reach for a Python library for doing statistics or ML-related things
</span></span><span class="line" line="56"><span> (&#39;KAFKA&#39;, 10), # I haven&#39;t used it but I&#39;m familiar with the ideas behind Kafka.
</span></span><span class="line" line="57"><span> (&#39;SPARK&#39;, 10), # I haven&#39;t used it and I&#39;m not really sure what it is
</span></span><span class="line" line="58"><span> (&#39;ELASTICSEARCH&#39;, 10), # I haven&#39;t used it before
</span></span><span class="line" line="59"><span> (&#39;ETL&#39;, 10), # Extract, Transform and Load
</span></span><span class="line" line="60"><span> (&#39;NATURAL LANGUAGE PROCESSING&#39;, 10),
</span></span><span class="line" line="61"><span> (&#39;HEROKU&#39;, 10), # I used this when first learning about Django, haven&#39;t used it in a while
</span></span><span class="line" line="62"><span> (&#39;NGINX&#39;, 9), # I use NGINX in most of my web apps as a reverse proxy
</span></span><span class="line" line="63"><span> (&#39;JENKINS&#39;, 9), # I haven&#39;t used it, I am a big GitLab fan and will use that whenever possible
</span></span><span class="line" line="64"><span> (&#39;RUST&#39;, 9), # I have read the Rust book and have played around with WASM
</span></span><span class="line" line="65"><span> (&#39;IMAGE PROCESSING&#39;, 8),
</span></span><span class="line" line="66"><span> (&#39;SERVERLESS&#39;, 8), # I currenty use Fargate and have also used Lambda and SQS and some other serverless AWS tools
</span></span><span class="line" line="67"><span> (&#39;BLOCKCHAIN&#39;, 8),
</span></span><span class="line" line="68"><span> (&#39;OPENCV&#39;, 8),
</span></span><span class="line" line="69"><span> (&#39;CAD DESIGN&#39;, 7), # I am a big fan of SketchUp and I&#39;m familiar with Blender as well, but I&#39;m not sure if these qualify as CAD design
</span></span><span class="line" line="70"><span> (&#39;JQUERY&#39;, 7), # It was the first library I worked with when I started learning javascript
</span></span><span class="line" line="71"><span> (&#39;HADOOP&#39;, 6), # It is related to map-reduce, I haven&#39;t used it before and I don&#39;t really know what it is. I know it is related to HDFS
</span></span><span class="line" line="72"><span> (&#39;.NET CORE&#39;, 6), # I haven&#39;t used it
</span></span><span class="line" line="73"><span> (&#39;TCP/IP&#39;, 6), # I&#39;m familiary with the basics
</span></span><span class="line" line="74"><span> (&#39;ELIXIR&#39;, 6), # I don&#39;t know, I think it is a framework for Erlang
</span></span><span class="line" line="75"><span> (&#39;INTERNET OF THINGS (IOT)&#39;, 5),
</span></span><span class="line" line="76"><span> (&#39;SASS&#39;, 5), # I think it is a framework for CSS. I frequently see node-sass errors from npm
</span></span><span class="line" line="77"><span> (&#39;OPENGL&#39;, 5),
</span></span><span class="line" line="78"><span> (&#39;DYNAMODB&#39;, 5), # I am familiar with it but haven&#39;t used it
</span></span><span class="line" line="79"><span> (&#39;GOOGLE APP ENGINE&#39;, 5), # I haven&#39;t used it before
</span></span><span class="line" line="80"><span> (&#39;UNIX&#39;, 4),
</span></span><span class="line" line="81"><span> (&#39;SPRING FRAMEWORK&#39;, 4), # A Java web framework that I haven&#39;t used
</span></span><span class="line" line="82"><span> (&#39;CUDA&#39;, 4), # I have used it indirectly when I used nvidia-docker to used Tensorflow
</span></span><span class="line" line="83"><span> (&#39;DART&#39;, 4), # I don&#39;t know what this is
</span></span><span class="line" line="84"><span> (&#39;ERLANG&#39;, 4), # A language that handles concurrency very well
</span></span><span class="line" line="85"><span> (&#39;RABBITMQ&#39;, 4), # Message queue, I have used it before but tend to use Redis as a message broker
</span></span><span class="line" line="86"><span> (&#39;KERAS&#39;, 4), # A helper/wrapper library for Tensorflow
</span></span><span class="line" line="87"><span> (&#39;SCSS&#39;, 4), # I think this is a language that compiles to CSS. CSS frameworks that I use use this
</span></span><span class="line" line="88"><span> (&#39;ML&#39;, 4), # I&#39;ve read some books and experimented but I&#39;m not a regular practitioner
</span></span><span class="line" line="89"><span> (&#39;MATLAB&#39;, 4), # A tool her programming with higher math
</span></span><span class="line" line="90"><span> (&#39;SPRING&#39;, 4), # A Java web framework. Not sure if different from Spring Boot. Never used it.
</span></span><span class="line" line="91"><span> (&#39;CASSANDRA&#39;, 4), # FB scalable database (NoSQL I think?) that does sharding really well
</span></span><span class="line" line="92"><span> (&#39;HIVE&#39;, 3), # Not sure what hive is. I think it related to Hadoop
</span></span><span class="line" line="93"><span> (&#39;PUPPET&#39;, 3), # Configuration management tool that I haven&#39;t ever used
</span></span><span class="line" line="94"><span> (&#39;REDSHIFT&#39;, 3), # AWS version of Google BigQuery
</span></span><span class="line" line="95"><span> (&#39;SQL SERVER&#39;, 3), # Not sure what this refers to, specifically.
</span></span><span class="line" line="96"><span> (&#39;GROOVY&#39;, 3), # I think this is a Java framework?
</span></span><span class="line" line="97"><span> (&#39;VERILOG&#39;, 3), # I&#39;ve never heard of this.
</span></span><span class="line" line="98"><span> (&#39;TORCH/PYTORCH&#39;, 3), # FB python deep learning library.
</span></span><span class="line" line="99"><span> (&#39;CLOJURE&#39;, 3), # A LISP derivate, functional language
</span></span><span class="line" line="100"><span> (&#39;MICROSOFT AZURE&#39;, 3), # I&#39;ve used Azure AD and thats it.
</span></span><span class="line" line="101"><span> (&#39;HBASE&#39;, 2), # I don&#39;t know what this is
</span></span><span class="line" line="102"><span> (&#39;RDS/AURORA&#39;, 2), # I use RDS and experimented with Aurora but don&#39;t know when/why to use it
</span></span><span class="line" line="103"><span> (&#39;FIRMWARE&#39;, 2), # What&#39;s between hardware and software
</span></span><span class="line" line="104"><span> (&#39;ABAP&#39;, 2), # I don&#39;t know
</span></span><span class="line" line="105"><span> (&#39;ARDUINO&#39;, 2), # I have one, but don&#39;t use it
</span></span><span class="line" line="106"><span> (&#39;MICROCONTROLLERS&#39;, 2), # Arduino might be an example of what this is
</span></span><span class="line" line="107"><span> (&#39;SOLIDITY&#39;, 2), # Don&#39;t know what this is
</span></span><span class="line" line="108"><span> (&#39;UNREAL ENGINE&#39;, 2), # Unity competitor, used for game development
</span></span><span class="line" line="109"><span> (&#39;COFFEESCRIPT&#39;, 2), # I think it is a dialect of JS, but I&#39;m not sure
</span></span><span class="line" line="110"><span> (&#39;LUA&#39;, 2), # I think this is what redis is written in, but I&#39;m not sure how to descbribe what it is
</span></span><span class="line" line="111"><span> (&#39;MACOS&#39;, 2), # I haven&#39;t used MacOS in a long time. I&#39;m tempted to try M1, but I also want to buid a new PC...
</span></span><span class="line" line="112"><span> (&#39;NEO4J&#39;, 2), # A graph database, I&#39;m not sure what a typical use case is for this
</span></span><span class="line" line="113"><span> (&#39;INFORMATION SECURITY&#39;, 2), # Unknown unknowns
</span></span><span class="line" line="114"><span> (&#39;REINFORCEMENT LEARNING (RL)&#39;, 2), # Not sure what this refers to specifically
</span></span><span class="line" line="115"><span> (&#39;DEVICE DRIVERS&#39;, 2), # Probably involves writing kernel modules
</span></span><span class="line" line="116"><span> (&#39;EMBEDDED LINUX&#39;, 2), # Not sure if Raspberry Pi is an example of this or not
</span></span><span class="line" line="117"><span> (&#39;ELASTIC STACK (ELK)&#39;, 1), # Useful for viewing log data (Elastic, Logstash and Kibana), haven&#39;t used it
</span></span><span class="line" line="118"><span> (&#39;IIS&#39;, 1), # I don&#39;t know
</span></span><span class="line" line="119"><span> (&#39;ORACLE&#39;, 1), # A big software company and a proprietary database (I think Django supports it)
</span></span><span class="line" line="120"><span> (&#39;F#&#39;, 1), # A programming language that I don&#39;t know anything about
</span></span><span class="line" line="121"><span> (&#39;SQLITE&#39;, 1), # A light-weight SQL-compatible file-based database
</span></span><span class="line" line="122"><span> (&#39;HASKELL&#39;, 1), # A functional programming language that I don&#39;t know
</span></span><span class="line" line="123"><span> (&#39;SCHEME&#39;, 1), # I&#39;m not sure, it may be something related to LISP
</span></span><span class="line" line="124"><span> (&#39;MS SQL&#39;, 1), # Never used this
</span></span><span class="line" line="125"><span> (&#39;MARIADB&#39;, 1), # An open source SQL database
</span></span><span class="line" line="126"><span> (&#39;MAVEN&#39;, 1), # I think it is a Java Framework
</span></span><span class="line" line="127"><span> (&#39;SEARCH&#39;, 1), # I don&#39;t know what this refers to
</span></span><span class="line" line="128"><span> (&#39;OCAML&#39;, 1), # I think I once read that high-frequency traders like to use this language, but I&#39;m not sure why
</span></span><span class="line" line="129"><span> (&#39;JULIA&#39;, 1), # A programming language used for math and statistics
</span></span><span class="line" line="130"><span> (&#39;GPU PROGRAMMING&#39;, 1), # I haven&#39;t done this before, probably uses C++
</span></span><span class="line" line="131"><span> (&#39;HACK&#39;, 1), # FB&#39;s version of PHP
</span></span><span class="line" line="132"><span> (&#39;XAMARIN&#39;, 1), # I dont&#39;t know what this is
</span></span><span class="line" line="133"><span> (&#39;CORDOVA&#39;, 1), # I think it is a tool for generating native apps from JS
</span></span><span class="line" line="134"><span> (&#39;SAS&#39;, 1), # I don&#39;t know what this is
</span></span><span class="line" line="135"><span> (&#39;ASSEMBLY&#39;, 1), # Low level language that gives instructions to CPU
</span></span><span class="line" line="136"><span> (&#39;XML&#39;, 1), # A data format, I use it for this site&#39;s sitemap and RSS feed
</span></span><span class="line" line="137"><span> (&#39;MEMCACHED&#39;, 1), # Used for caching. I haven&#39;t used it; I typically use redis where this might be an option
</span></span><span class="line" line="138"><span> (&#39;LESS&#39;, 1), # I think is is related to CSS?
</span></span><span class="line" line="139"><span> (&#39;AMAZON ECHO&#39;, 1) # I once built an open source Echo on a raspberry pi
</span></span><span class="line" line="140"><span>]
</span></span></code><!--]--></pre><p><!--[-->The list above gives a count of the different skills in all job postings sorted by the most common skills. But what about the most common skills listed together with any given skill? This would allow us to answer questions like &quot;what skills appear most frequently along with JavaScript?&quot;<!--]--></p><p><!--[-->We can find this with by doing:<!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span>skills_frequency = defaultdict(lambda: defaultdict(lambda: 0))
</span></span><span class="line" line="2"><span emptylineplaceholder="true">
</span></span><span class="line" line="3"><span>for company in company_list:
</span></span><span class="line" line="4"><span>    if company[&quot;jobs&quot;] is not None:
</span></span><span class="line" line="5"><span>        for job in company[&quot;jobs&quot;]:
</span></span><span class="line" line="6"><span>            if job[&quot;job_skills&quot;] is not None:
</span></span><span class="line" line="7"><span>                job_skills = job[&quot;job_skills&quot;]
</span></span><span class="line" line="8"><span emptylineplaceholder="true">
</span></span><span class="line" line="9"><span>                skill_tuples = itertools.permutations(job_skills, 2)
</span></span><span class="line" line="10"><span emptylineplaceholder="true">
</span></span><span class="line" line="11"><span>                for skill_tuple in skill_tuples:
</span></span><span class="line" line="12"><span>                    first = skill_tuple[0]
</span></span><span class="line" line="13"><span>                    second = skill_tuple[1]
</span></span><span class="line" line="14"><span emptylineplaceholder="true">
</span></span><span class="line" line="15"><span>                    skills_frequency[first][second] += 1
</span></span><span class="line" line="16"><span emptylineplaceholder="true">
</span></span><span class="line" line="17"><span>pprint.pprint(
</span></span><span class="line" line="18"><span>    {
</span></span><span class="line" line="19"><span>        key: sorted(value.items(), key=lambda kv: -kv[1])
</span></span><span class="line" line="20"><span>        for key, value in skills_frequency.items()
</span></span><span class="line" line="21"><span>    }
</span></span><span class="line" line="22"><span>)
</span></span></code><!--]--></pre><span></span><h3 id="what-are-these-companies-working-on"><a href="#what-are-these-companies-working-on"><!--[-->What are these companies working on?<!--]--></a></h3><p><!--[-->Here&#39;s a wordcloud made from the short company descriptions:<!--]--></p><p><!--[--><img onerror="this.setAttribute(&#39;data-error&#39;, 1)" alt="png" data-nuxt-img srcset="/_ipx/_/static/company_desc_wc.png 1x, /_ipx/_/static/company_desc_wc.png 2x" src="/_ipx/_/static/company_desc_wc.png"><!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span>import json
</span></span><span class="line" line="2"><span>import random
</span></span><span class="line" line="3"><span emptylineplaceholder="true">
</span></span><span class="line" line="4"><span>from collections import Counter
</span></span><span class="line" line="5"><span>from os import path
</span></span><span class="line" line="6"><span emptylineplaceholder="true">
</span></span><span class="line" line="7"><span>import matplotlib.pyplot as plt
</span></span><span class="line" line="8"><span>import numpy as np
</span></span><span class="line" line="9"><span emptylineplaceholder="true">
</span></span><span class="line" line="10"><span>from PIL import Image
</span></span><span class="line" line="11"><span>from wordcloud import WordCloud, STOPWORDS
</span></span><span class="line" line="12"><span emptylineplaceholder="true">
</span></span><span class="line" line="13"><span>HTML_FILE = &quot;waas_data.json&quot;
</span></span><span class="line" line="14"><span>with open(HTML_FILE, &#39;r&#39;) as j:
</span></span><span class="line" line="15"><span>     company_list = json.loads(j.read())
</span></span><span class="line" line="16"><span emptylineplaceholder="true">
</span></span><span class="line" line="17"><span>company_names = [company.get(&quot;company_name&quot;, &quot; &quot;).lower() for company in company_list]
</span></span><span class="line" line="18"><span>company_description_list = [company.get(&quot;company_desc&quot;, &quot; &quot;).lower().replace(&quot;.&quot;, &quot;&quot;) for company in company_list]
</span></span><span class="line" line="19"><span>company_descriptions = &quot; &quot;.join(company_description_list)
</span></span><span class="line" line="20"><span emptylineplaceholder="true">
</span></span><span class="line" line="21"><span>wc = WordCloud(background_color=&quot;white&quot;, width=1920, height=1080, max_words=500, stopwords=STOPWORDS, margin=10,
</span></span><span class="line" line="22"><span>               random_state=1).generate(company_descriptions)
</span></span><span class="line" line="23"><span emptylineplaceholder="true">
</span></span><span class="line" line="24"><span>default_colors = wc.to_array()
</span></span><span class="line" line="25"><span emptylineplaceholder="true">
</span></span><span class="line" line="26"><span>plt.figure(figsize=(40, 40))
</span></span><span class="line" line="27"><span>plt.imshow(wc, interpolation=&quot;bilinear&quot;)
</span></span><span class="line" line="28"><span emptylineplaceholder="true">
</span></span><span class="line" line="29"><span>plt.axis(&quot;off&quot;)
</span></span><span class="line" line="30"><span>plt.savefig(&#39;company_description_wc.png&#39;)
</span></span><span class="line" line="31"><span>plt.show()
</span></span></code><!--]--></pre><p><!--[-->Here&#39;s a breakdown of YC companies by category and sub category:<!--]--></p><span></span><h3 id="salary-equity-and-years-of-experience"><a href="#salary-equity-and-years-of-experience"><!--[-->Salary, Equity and Years of Experience<!--]--></a></h3><p><!--[-->Here&#39;s a scatterplot showing average salary and average equity for positions categorized by years of experience required.<!--]--></p><span></span><h3 id="logos"><a href="#logos"><!--[-->Logos<!--]--></a></h3><p><!--[-->Here&#39;s a look at about 600 of the 750 logos that were made available in the list of companies. The logos are sorted by their average hex color, which puts them on a gradient of dark to light:<!--]--></p><p><!--[--><img onerror="this.setAttribute(&#39;data-error&#39;, 1)" alt="png" data-nuxt-img srcset="/_ipx/_/static/waas/yc.png 1x, /_ipx/_/static/waas/yc.png 2x" src="/_ipx/_/static/waas/yc.png"><!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span>import os
</span></span><span class="line" line="2"><span>import PIL
</span></span><span class="line" line="3"><span>from PIL import Image
</span></span><span class="line" line="4"><span>from IPython.display import display, Image as IPyImage
</span></span><span class="line" line="5"><span>import matplotlib.pyplot as plt
</span></span><span class="line" line="6"><span>import matplotlib.image as mpimg
</span></span><span class="line" line="7"><span>%matplotlib inline
</span></span><span class="line" line="8"><span emptylineplaceholder="true">
</span></span><span class="line" line="9"><span>LOGO_DIR = &#39;data/waas_full_details_dump_files/&#39;
</span></span><span class="line" line="10"><span>yc_logos = [LOGO_DIR + x for x in os.listdir(LOGO_DIR) if x.endswith(&#39;.png&#39;)]
</span></span><span class="line" line="11"><span emptylineplaceholder="true">
</span></span><span class="line" line="12"><span>def average_img_hex(img):
</span></span><span class="line" line="13"><span>    &quot;&quot;&quot;
</span></span><span class="line" line="14"><span>    https://www.hackzine.org/getting-average-image-color-from-python.html
</span></span><span class="line" line="15"><span>    &quot;&quot;&quot;
</span></span><span class="line" line="16"><span>    img = Image.open(img)
</span></span><span class="line" line="17"><span emptylineplaceholder="true">
</span></span><span class="line" line="18"><span>    # leave out images not in RGB/RGBA mode
</span></span><span class="line" line="19"><span>    if img.mode in [&quot;LA&quot;, &quot;P&quot;, &quot;L&quot;]:
</span></span><span class="line" line="20"><span>        return
</span></span><span class="line" line="21"><span emptylineplaceholder="true">
</span></span><span class="line" line="22"><span>    # resize the image to 1 pixel and get the average hex value
</span></span><span class="line" line="23"><span>    img2 = img.resize((1, 1))
</span></span><span class="line" line="24"><span>    color = img2.getpixel((0, 0))
</span></span><span class="line" line="25"><span>    average_hex = &#39;#{:02x}{:02x}{:02x}&#39;.format(*color)
</span></span><span class="line" line="26"><span emptylineplaceholder="true">
</span></span><span class="line" line="27"><span>    return average_hex
</span></span><span class="line" line="28"><span emptylineplaceholder="true">
</span></span><span class="line" line="29"><span># sort images by average hex value
</span></span><span class="line" line="30"><span>sorted_images = sorted(
</span></span><span class="line" line="31"><span>    [(average_img_hex(img), img) for img in yc_logos if average_img_hex(img) is not None],
</span></span><span class="line" line="32"><span>    key=lambda x: x[0]
</span></span><span class="line" line="33"><span>)
</span></span><span class="line" line="34"><span emptylineplaceholder="true">
</span></span><span class="line" line="35"><span>images = sorted_images[:600]
</span></span><span class="line" line="36"><span emptylineplaceholder="true">
</span></span><span class="line" line="37"><span>fig, axes = plt.subplots(20, 30, figsize=(30, 15), sharex=False, sharey=False)
</span></span><span class="line" line="38"><span emptylineplaceholder="true">
</span></span><span class="line" line="39"><span>for img, ax in zip(images, axes.flat):
</span></span><span class="line" line="40"><span>    ax.imshow(mpimg.imread(img[1]))
</span></span><span class="line" line="41"><span>    ax.axis(&#39;off&#39;)
</span></span><span class="line" line="42"><span emptylineplaceholder="true">
</span></span><span class="line" line="43"><span>plt.savefig(&#39;yc.png&#39;)
</span></span><span class="line" line="44"><span>plt.show()
</span></span></code><!--]--></pre><p><!--[-->There are a lot of logos that have a similar design to Stripe&#39;s logo. Rose/peach/pamplemousse colored logos also seem to be popular.<!--]--></p><h3 id="founders"><a href="#founders"><!--[-->Founders<!--]--></a></h3><p><!--[-->Let&#39;s take a look at the founders. I came across the <a href="https://pypi.org/project/deepface/" rel="nofollow"><!--[-->deepface<!--]--></a> PyPI project an was impressed at how accurately it can classify face data.<!--]--></p><p><!--[-->Here&#39;s a sample of YC Founder headshots:<!--]--></p><p><!--[--><img onerror="this.setAttribute(&#39;data-error&#39;, 1)" alt="png" data-nuxt-img srcset="/_ipx/_/static/waas/yc_founders_sample.png 1x, /_ipx/_/static/waas/yc_founders_sample.png 2x" src="/_ipx/_/static/waas/yc_founders_sample.png"><!--]--></p><p><!--[-->Here&#39;s how I used the deepface library to add race, gender and age data for each of the headshot images:<!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span>IMG_DIR = &#39;data/waas_full_details_dump_files/&#39;
</span></span><span class="line" line="2"><span># headshots are all .jpg files, so we can get all headshots like this:
</span></span><span class="line" line="3"><span>founder_headshots = [x for x in os.listdir(IMG_DIR) if x.endswith(&#39;.jpg&#39;)]
</span></span><span class="line" line="4"><span>founder_count = len(founder_headshots)
</span></span><span class="line" line="5"><span emptylineplaceholder="true">
</span></span><span class="line" line="6"><span>img_paths = [IMG_DIR + x for x in founder_headshots]
</span></span><span class="line" line="7"><span>results = {}
</span></span><span class="line" line="8"><span emptylineplaceholder="true">
</span></span><span class="line" line="9"><span>for idx, img in enumerate(img_paths):
</span></span><span class="line" line="10"><span>    print(f&quot;analyzing {idx}/{founder_count}&quot;)
</span></span><span class="line" line="11"><span>    try:
</span></span><span class="line" line="12"><span>        img_key = img.split(&quot;/&quot;)[-1]
</span></span><span class="line" line="13"><span>        obj = DeepFace.analyze(
</span></span><span class="line" line="14"><span>            img_path=img,
</span></span><span class="line" line="15"><span>            actions=[&#39;age&#39;, &#39;gender&#39;, &#39;race&#39;, &#39;emotion&#39;],
</span></span><span class="line" line="16"><span>            enforce_detection=False
</span></span><span class="line" line="17"><span>        )
</span></span><span class="line" line="18"><span>        obj.update({&quot;img&quot;: img_key})
</span></span><span class="line" line="19"><span>        results[img_key] = obj
</span></span><span class="line" line="20"><span emptylineplaceholder="true">
</span></span><span class="line" line="21"><span>    except ValueError as e:
</span></span><span class="line" line="22"><span>        print(e)
</span></span><span class="line" line="23"><span emptylineplaceholder="true">
</span></span><span class="line" line="24"><span>with open(&quot;founder_images.json&quot;, &quot;w+&quot;) as f:
</span></span><span class="line" line="25"><span>    f.write(json.dumps(results))
</span></span></code><!--]--></pre><p><!--[-->There are more steps needed to transform this data to make it compatible for use with a histogram showing age, race and gender. Check out the Jupyter notebook linked at the end of this article to see the code used to make this data transformation. Here&#39;s a simple way to count founders grouped by race and gender:<!--]--></p><pre class="language-text"><!--[--><code>race_and_gender_count = defaultdict(lambda: 0)
for result in list(results):
    obj = results[result]
    gender = obj[&quot;gender&quot;]
    race = obj[&quot;dominant_race&quot;]
    # use (race, gender) tuple as defaultdict key and increment
    race_and_gender_count[(race, gender)] += 1

sorted(race_and_gender_count.items(), key=lambda x: x[1], reverse=True)
</code><!--]--></pre><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span>[((&#39;white&#39;, &#39;Man&#39;), 771),
</span></span><span class="line" line="2"><span> ((&#39;asian&#39;, &#39;Man&#39;), 217),
</span></span><span class="line" line="3"><span> ((&#39;latino hispanic&#39;, &#39;Man&#39;), 134),
</span></span><span class="line" line="4"><span> ((&#39;indian&#39;, &#39;Man&#39;), 117),
</span></span><span class="line" line="5"><span> ((&#39;middle eastern&#39;, &#39;Man&#39;), 111),
</span></span><span class="line" line="6"><span> ((&#39;black&#39;, &#39;Man&#39;), 84),
</span></span><span class="line" line="7"><span> ((&#39;white&#39;, &#39;Woman&#39;), 52),
</span></span><span class="line" line="8"><span> ((&#39;asian&#39;, &#39;Woman&#39;), 17),
</span></span><span class="line" line="9"><span> ((&#39;latino hispanic&#39;, &#39;Woman&#39;), 13),
</span></span><span class="line" line="10"><span> ((&#39;indian&#39;, &#39;Woman&#39;), 4),
</span></span><span class="line" line="11"><span> ((&#39;black&#39;, &#39;Woman&#39;), 1)]
</span></span></code><!--]--></pre><span></span><h3 id="founder-background-wordcloud"><a href="#founder-background-wordcloud"><!--[-->Founder background wordcloud<!--]--></a></h3><p><!--[-->Here&#39;s a wordcloudsshowing founder background, education and experience. The code for this is similar to the wordcloud shown previously for company descriptions.<!--]--></p><p><!--[--><img onerror="this.setAttribute(&#39;data-error&#39;, 1)" alt="png" data-nuxt-img srcset="/_ipx/_/static/founders_wc.png 1x, /_ipx/_/static/founders_wc.png 2x" src="/_ipx/_/static/founders_wc.png"><!--]--></p><h2 id="generating-yc-startup-companies"><a href="#generating-yc-startup-companies"><!--[-->Generating YC Startup Companies<!--]--></a></h2><p><!--[-->Finally, I&#39;ll try to generate some plausible descriptions of YC companies based on the descriptions of companies scraped from WaaS. I have read about big advancements made in text generation with GPT-3, but otherwise I&#39;m not familiar with text-generation or any other generative models.<!--]--></p><p><!--[-->My initial goal was to do this using a simple example that I could replicate locally using Tensorflow. Googling for <code><!--[-->text generation with python tensorflow<!--]--></code> led me to this tutorial: <a href="https://www.thepythoncode.com/article/text-generation-keras-python" rel="nofollow"><!--[-->https://www.thepythoncode.com/article/text-generation-keras-python<!--]--></a>. I was able to run the example, but the results were not very good, at least not as good as the results used in the example of generating text from a model trained on the text of &quot;Alice in Wonderland&quot;. This is probably because I ran 10 epochs instead of 30, but I didn&#39;t want to wait hours before getting results for each iteration.<!--]--></p><p><!--[-->Another Google search led me to <a href="https://minimaxir.com/2019/09/howto-gpt2/" rel="nofollow"><!--[-->this article on Max Woolf&#39;s Blog<!--]--></a> which I was able to get started with in just a few minutes. I combined the text from the 2 sections of the longer company descriptions: <code><!--[-->description<!--]--></code> and <code><!--[-->technology<!--]--></code>.<!--]--></p><p><!--[-->Here&#39;s the link to the Google Colab (anyone can view and comment):<!--]--></p><p><!--[--><a href="https://colab.research.google.com/drive/1u9b-FVGgUGcfifLy7bUXgoPe-pZ81rm3?usp=sharing" rel="nofollow"><!--[-->https://colab.research.google.com/drive/1u9b-FVGgUGcfifLy7bUXgoPe-pZ81rm3?usp=sharing<!--]--></a><!--]--></p><p><!--[-->Google Colab gives you access to an environment with a GPU suitable for working with GPT2. Here&#39;s an overview of the code used to train GPT2 on the company descriptions:<!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span>%tensorflow_version 1.x
</span></span><span class="line" line="2"><span>!pip install -q gpt-2-simple
</span></span><span class="line" line="3"><span>import gpt_2_simple as gpt2
</span></span><span class="line" line="4"><span>from datetime import datetime
</span></span><span class="line" line="5"><span>from google.colab import files
</span></span></code><!--]--></pre><p><!--[-->This installs <a href="https://github.com/minimaxir/gpt-2-simple" rel="nofollow"><!--[--><code><!--[-->gpt-2-simple<!--]--></code><!--]--></a> and gives us access to the Google Drive connected to the Google account used to sign in to Google Colab.<!--]--></p><p><!--[-->The GPU can be inspected with:<!--]--></p><pre class="language-text"><!--[--><code>!nvidia-smi
</code><!--]--></pre><pre class="language-text"><!--[--><code>+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   51C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |
|                               |                      |                 ERR! |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 418.67       CUDA Version: 10.1     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |
| N/A   51C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |
|                               |                      |                 ERR! |
+-------------------------------+----------------------+----------------------+

+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</code><!--]--></pre><p><!--[-->Next we download the GPT-2 model:<!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span>gpt2.download_gpt2(model_name=&quot;124M&quot;)
</span></span></code><!--]--></pre><p><!--[-->Then we mount Google Drive with the following command:<!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span>gpt2.mount_gdrive()
</span></span></code><!--]--></pre><p><!--[-->With our file (<code><!--[-->waas.txt<!--]--></code>) uploaded to Google Drive, the following<!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span>file_name = &quot;waas.txt&quot;
</span></span><span class="line" line="2"><span>gpt2.copy_file_from_gdrive(file_name)
</span></span></code><!--]--></pre><p><!--[-->Now the model needs to be fine-tuned:<!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span>sess = gpt2.start_tf_sess()
</span></span><span class="line" line="2"><span emptylineplaceholder="true">
</span></span><span class="line" line="3"><span>gpt2.finetune(
</span></span><span class="line" line="4"><span>    sess,
</span></span><span class="line" line="5"><span>    dataset=file_name,
</span></span><span class="line" line="6"><span>    model_name=&#39;124M&#39;,
</span></span><span class="line" line="7"><span>    steps=1000,
</span></span><span class="line" line="8"><span>    restore_from=&#39;fresh&#39;,
</span></span><span class="line" line="9"><span>    run_name=&#39;run1&#39;,
</span></span><span class="line" line="10"><span>    print_every=10,
</span></span><span class="line" line="11"><span>    sample_every=200,
</span></span><span class="line" line="12"><span>    save_every=500
</span></span><span class="line" line="13"><span>)
</span></span></code><!--]--></pre><p><!--[-->Here are some results from my first attempt at using Google Colab. Training the model will output a sample after every 200 steps. I have included only the first sample from the training, but you can see the output from each step in the Colab notebook.<!--]--></p><pre class="language-text"><!--[--><code>WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Loading checkpoint models/124M/model.ckpt
INFO:tensorflow:Restoring parameters from models/124M/model.ckpt
  0%|          | 0/1 [00:00&lt;?, ?it/s]Loading dataset...
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00&lt;00:00,  1.00it/s]
dataset has 128333 tokens
Training...
[10 | 28.79] loss=3.60 avg=3.60
[20 | 50.75] loss=3.30 avg=3.45
[30 | 73.39] loss=3.25 avg=3.38
[40 | 96.80] loss=3.18 avg=3.33
[50 | 121.40] loss=3.12 avg=3.29
[60 | 145.52] loss=3.10 avg=3.26
[70 | 169.15] loss=2.56 avg=3.16
[80 | 193.06] loss=2.46 avg=3.07
[90 | 217.28] loss=2.59 avg=3.01
[100 | 241.38] loss=2.49 avg=2.96
[110 | 265.33] loss=2.34 avg=2.90
[120 | 289.30] loss=2.52 avg=2.86
[130 | 313.46] loss=2.37 avg=2.82
[140 | 337.69] loss=2.38 avg=2.79
[150 | 361.84] loss=1.92 avg=2.73
[160 | 385.94] loss=2.25 avg=2.70
[170 | 410.01] loss=1.73 avg=2.63
[180 | 434.10] loss=1.66 avg=2.58
[190 | 458.18] loss=1.25 avg=2.50
[200 | 482.22] loss=1.47 avg=2.44
======== SAMPLE 1 ========

 to improve the usability of our Services and to provide better
 offline features through offline messaging. Our Platform
 connects users from across the country to collect data on
 non-US citizens abroad, and then gives US citizens a secure and
 authentic online presence while keeping their identities
 private. Our mission is to enable Americans to be more secure
 in online world.  We do this by putting a damper on online
 threats while preventing online attacks and slowing down the
 spread of cyberthreats. Backed by a world class Series A and B
 investments from leading technology firms, including Shas
 Ventures and Y Combinator, we\&#39;re an organization that believes
 in doing what is right. We\&#39;re built to last and provide an
 experience that\&#39;s built to last.\xa0We\&#39;ve partnered with some
 of the world\&#39;s top law enforcement institutions including the
 Washington DC Metropolitan Detention Center, National Domestic
 Relations Task Force, Lambda Legal, Lambda Legal National Labs,
 NIMBYs Angels of San Francisco and Rally Labs provide legal
 technology &amp; community education, as well as legal assistance/
 cure treatments. We\&#39;re a tech firm that\&#39;s built to last ‚Äòlots
 of years üôè. We\&#39;ve solved some really really hard problems in
 the past, and haven\&#39;t forgotten.We\&#39;re a team of passionate
 engineers, machine learning researchers, and business
 executives from Y Combinator and Naval Institute. We\&#39;ve just
 closed our Series B and C funding, and\&#39;s back at it with two
 more large-scale brothels and a bona fide law firm dedicated to
 bringing brothels to the people. Join us on this next chapter
 in our journey, and help us build the next Clark County jail.
 We\&#39;re looking for guys who can quickly learn leadership roles
 and fill in for leaders, not executives. We like to take what
 we learn and apply it to real problems. ReactJS, Node, Django,
 Postgres, and a sprinkle of AWS. ReactInfrastructure serves
 Express-like functions in the cloud. Our customers are law
 firms and other third-party service providers, largely
 comprised of tech startups. Our customers are generating
 billions of dollars in revenue through our platform every
 year.  Come join us and help us transform this dynamic into a
 platform-as-a-works. Rippling uses the following
 technologies:React Native JavaScriptFast, clean,
 nativeCSS3Deterministic executionReact NativeScriptWeb appLync,
 typescriptArchitecture-as-a-systemResponsible for maintaining
 and expanding the Ethereum and Bitcoin infrastructure. We\&#39;re
 based in New York City, and are backed by the VC-leading
 venture firms in the space. Our flagship product, Rippling, is
 an intuitive phone-in-a-person phone banking solution that
 integrates an RFID reader and password manager, as well as
 password managers dedicated to managing assets and managing
 cards. Users can create portfolios and trade on the Rippling
 marketplace, or access the technology to create their own
 portfolios on the Bitcoin and Ethereum markets. Simply put,
 Rippling is 21+ year old inventors. We\&#39;ve reinvented banking
 by making money available today through an open API. Banks now
 have an easy path to secure assets, including a digital wallet
 and code backed by an AllinAir‚Äôs digital asset portfolio. We
 are a small team of computer scientists building tools that
 improve customer experience, reduce wait times for businesses,
 and increase transparency in banking. Our platform runs on very
 little electricity, minimal mechanical power, and is 100x more
 robust 20 than traditional DPG/PGD systems. The system stores 1
 watt of energy and 8 watts of power per watt signal in a
 standard APS-C (Advanced Plasmon Super Capacitor Stacker).
 Cells in our cell-resistant cell-glide-based sprays secrete a
 protein that is targeted to trigger cell death, called a T
 cell. This triggered death is what causes breast cancer.
 Stacking together our diverse array of biological and chemical
 biology and chemical pathologies, and building in new energy
 efficiency technology to power our smart consumer products,
 we\&#39;re taking our users on an exciting journey toward modern
 energy efficiency. We are a team of computer scientists located
 in Barcelona, Spain, and we are focusing on the extremely first
 and foremost research and development applications in renewable
 energy. Current RCP is the largest R&amp;D and R&amp;E net for the 21st
 century, automating substantial paperwork and providing
 essential modern services. With the exception of emergency
 services and work, we are unaffected by the most common types
 of CO2 emissions including man-made nitrous oxide, human-made
 CO2, and volatile organic compounds. Current RCP delivers the
 highest quality, highest efficiency possible, including
 equipment, software, waste management, and notification
 systems, all in a modern, integrated and convenient way. By
 using RCP, consumers, businesses, civil society, researchers
 and others around the world can save money on power bills,
 reduce emissions and waste, receive timely assistance from the
 energy sector and be

[210 | 517.61] loss=1.62 avg=2.40

[...]

[1000 | 2448.17] loss=0.07 avg=0.47
Saving checkpoint/run1/model-1000
WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
</code><!--]--></pre><p><!--[-->Here&#39;s a sample generated using the trained model:<!--]--></p><blockquote><!--[--><p><!--[-->We are a small team of MIT-trained researchers and entrepreneurs based in Palo Alto, California. We&#39;re creating a new form of transportation for people and gear. Based in the heart of downtown LA, our downtown L.A. location will be the last remaining obstacle preventing people from making, selling, and visiting the Smithsonian. We&#39;re building a disruptive technology that impacts the way people interact in the world in a positive way. Token Transit is digitizing much of the way we travel for real. We are building it to work for everyone, digitizing billions of things we buy and sell every day. Our platform connects real users and non-users in a global network. Our first product, UNITY, made it from scratch and is in mixed state. We are helping to develop the first truly international distributed logistics network powered by an AI and a IoT. Our mission is to revolutionize how companies move containers, trucks, and other loads across borders. Our technology is being architected and being implemented by experts across the globe. Our annual revenue:$150M/year. How we work We are a small, fast growing company with a core team based in San Francisco, CA.  Our software is being used by thousands of customers worldwide. We are building our technology platform in two key areas: (1) automated supply chain forecasting for companies and (2) internal analysis of company data to help leaders analyze and improve production. Our YearEnd blog is currently looking for Senior Electricians &amp; Candidates. If you&#39;re excited about this exciting challenge, please apply. Burrow is a daily driver app for mobile that works on any device. With Burrow, your driver is on your phone to show your friends where you are going, which destinations you are on, and more. You can also add your phone to a list and get in-depth insights into the driving itself. We love to tie in-stream data, visualised by React Native, to the driving experience. We also take a data-driven approach to managing our customer list, managing our teams and our operations framework. Our API serves a large amount of native API functions, and using Cockroach to access these functions through microservices allowed us to interface with the relevant services (e.g. DynamoDB, Picnic and our own API). We also inserted a lot of debugging and monitoring functionality into the ecosystem. Our API serves a large amount of data - including relational and non-relational data - about where you are and what you&#39;ve wanted to do the longest, what you&#39;ve got, and where you are now. We also manage a lot of the operations of the platform and provide some of the data integrations with your existing relational and non-relational data. Technologies we use NodeJS, React, Apollo, Postgres, Heroku, Docker, and Tensorflow: Fluttertable, Datapoint, Pandas, Keras, Numpy, Scipy, Scikit, SciPy, scikit-learn AI-ron at MERN Automation is a Google-backed NARability company that is committed to being the leading platform for accurately measuring and diagnosing agricultural production. We have built proprietary software and software automation systems to make it easy for any government to track agricultural production and prices. Our primary technologies today are:Tables, Entry Points into Global Food Production, Pipeline and Grain Market, and GenomicData.utility.Upstream is revolutionizing how U.S. agriculture is produced and sold. We are serving the agronomists, farmers, market researchers, and data scientists in the USA. WWrendy is on a mission to enable breakthrough scientific research in agricultural technology. We are growing cassava in our bioreactors, improving crop health and producing more durables than we need to feed ourselves. We use machine learning to identify cancer-causing microbes in seeds and in consumer durables to make food more accessible and more sustainable. We are building an entirely new technical infrastructure for agricultural diagnostics: tractors, biores, and tractors-all with a singular goal of improving yields and feed the world. We have humble beginnings as a grocery delivery service and have since grown to serve millions of people every year. We are a tight-knit team of MIT-trained researchers, technologists, and businesspeople, who have built an industry-leading technology platform that uses sensors and software to analyze crop production data to create intelligent and efficient food products. Our mission is to help all farmers have a more sustainable crop, by using microbial discoveries to improve the health and prosperity of their communities. We&#39;re a well-funded, well-funded, yuletide startup. We&#39;re looking to grow and affordably upgrade our tech stack every year. We use less expensive tools and techniques to analyze and build comprehensive datasets on crop production and food safety to help farmers grow more food and avoid over-production. Rails / React / AWS We build, manage, and cybersecurity insurance through an on-premise platform. We<!--]--></p><!--]--></blockquote><p><!--[-->From this first attempt there are already a few ideas for YC startups:<!--]--></p><blockquote><!--[--><p><!--[-->We are helping to develop the first truly international distributed logistics network powered by an AI and a IoT. Our mission is to revolutionize how companies move containers, trucks, and other loads across borders. Our technology is being architected and being implemented by experts across the globe.<!--]--></p><!--]--></blockquote><blockquote><!--[--><p><!--[-->We have built proprietary software and software automation systems to make it easy for any government to track agricultural production and prices.<!--]--></p><!--]--></blockquote><p><!--[-->Next we can try improving the output by using some additional features of <code><!--[-->gpt-2-simple<!--]--></code>. One important setting is the size of the model. There are three released sizes of GPT-2:<!--]--></p><ul><!--[--><li><!--[--><code><!--[-->124M<!--]--></code> (default): the &quot;small&quot; model, 500MB on disk. This is the one used on my first try<!--]--></li><li><!--[--><code><!--[-->355M<!--]--></code>: the &quot;medium&quot; model, 1.5GB on disk.<!--]--></li><li><!--[--><code><!--[-->774M<!--]--></code>: the &quot;large&quot; model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)<!--]--></li><li><!--[--><code><!--[-->1558M<!--]--></code>: the &quot;extra large&quot;, true model. Will not work if a K80 GPU is attached to the notebook. (like <code><!--[-->774M<!--]--></code>, it cannot be finetuned).<!--]--></li><!--]--></ul><p><!--[-->We can try again using the 355M model. The <code><!--[-->large<!--]--></code> and <code><!--[-->extra large<!--]--></code> models won&#39;t work for our use case of finetuning the model on our sample text.<!--]--></p><p><!--[-->This would be a great time to plug my startup, but I don&#39;t have one. Instead, here are 10,000 startup ideas I generated with GPT-2 trained on the 335M model using the YC company descriptions for finetuning:<!--]--></p><pre class="language-py shiki shiki-themes github-light github-dark" style=""><!--[--><code><span class="line" line="1"><span>gpt2.generate_to_file(sess,
</span></span><span class="line" line="2"><span>                      destination_path=gen_file,
</span></span><span class="line" line="3"><span>                      length=150,
</span></span><span class="line" line="4"><span>                      prefix=&quot;we are building the world&#39;s first&quot;,
</span></span><span class="line" line="5"><span>                      temperature=0.7,
</span></span><span class="line" line="6"><span>                      nsamples=10000,
</span></span><span class="line" line="7"><span>                      batch_size=20,
</span></span><span class="line" line="8"><span>                      )
</span></span></code><!--]--></pre><span></span><h3 id="credits-links-and-learning-resources"><a href="#credits-links-and-learning-resources"><!--[-->Credits, Links and Learning Resources<!--]--></a></h3><p><!--[-->Here&#39;s a link to Max Woolf&#39;s blog which has a lot of helpful resources on using GPT-2. Max is the author of <code><!--[-->gpt-2-simple<!--]--></code> which is the Python package used in the Google Colab (Max is the author of that Google Colab as well):<!--]--></p><p><!--[--><a href="https://minimaxir.com/" rel="nofollow"><!--[-->https://minimaxir.com/<!--]--></a><!--]--></p><p><!--[-->Here are some resources for learning more about text generation. I came across Jay Alammar&#39;s blog which has a lot of great visualizations:<!--]--></p><p><!--[--><a href="https://jalammar.github.io/" rel="nofollow"><!--[-->https://jalammar.github.io/<!--]--></a><!--]--></p><p><!--[-->Jay also has a great YouTube channel:<!--]--></p><iframe width="100%" height="400" src="https://www.youtube.com/embed/MQnJZuBGmSQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe><p><!--[-->Here&#39;s the link to the source markdown file for this article: <a href="https://github.com/briancaffey/briancaffey.github.io/tree/master/content/2021/01/16" rel="nofollow"><!--[-->https://github.com/briancaffey/briancaffey.github.io/tree/master/content/2021/01/16<!--]--></a><!--]--></p><p><!--[-->Here&#39;s a link to the repo containing all of the scraped data and Jupyter notebooks used for exploring the data: <a href="https://gitlab.com/briancaffey/yc-waas-data" rel="nofollow"><!--[-->https://gitlab.com/briancaffey/yc-waas-data<!--]--></a><!--]--></p><p><!--[-->Here&#39;s the link to the Google Colab used for generating company descriptions with GPT-2 and gpt-2-simple: <a href="https://colab.research.google.com/drive/1u9b-FVGgUGcfifLy7bUXgoPe-pZ81rm3?usp=sharing#scrollTo=8DKMc0fiej4N" rel="nofollow"><!--[-->https://colab.research.google.com/drive/1u9b-FVGgUGcfifLy7bUXgoPe-pZ81rm3?usp=sharing#scrollTo=8DKMc0fiej4N<!--]--></a><!--]--></p><p><!--[-->Thank you for reading!<!--]--></p><style>html pre.shiki code .sJ8bj, html code.shiki .sJ8bj{--shiki-default:#6A737D;--shiki-dark:#6A737D}html pre.shiki code .szBVR, html code.shiki .szBVR{--shiki-default:#D73A49;--shiki-dark:#F97583}html pre.shiki code .sj4cs, html code.shiki .sj4cs{--shiki-default:#005CC5;--shiki-dark:#79B8FF}html pre.shiki code .sVt8B, html code.shiki .sVt8B{--shiki-default:#24292E;--shiki-dark:#E1E4E8}html pre.shiki code .sScJk, html code.shiki .sScJk{--shiki-default:#6F42C1;--shiki-dark:#B392F0}html pre.shiki code .sZZnC, html code.shiki .sZZnC{--shiki-default:#032F62;--shiki-dark:#9ECBFF}html pre.shiki code .s7hpK, html code.shiki .s7hpK{--shiki-default:#B31D28;--shiki-default-font-style:italic;--shiki-dark:#FDAEB7;--shiki-dark-font-style:italic}html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}</style></div><div class="text-center pb-4 pt-8"><button class="mc-btn rounded py-1 px-2"> Show Disqus Comments üí¨ </button></div><!----><h1></h1></div></article><!--]--><div class="mx-auto max-w-6xl p-4 lg:px-16 text-center"><hr class="mt-4"><div class="align-center py-4"><div class="pb-4">Join my mailing list to get updated whenever I publish a new article.</div><div class="flex align-center justify-center"><div id="mc_embed_signup" class="w-full md:w-1/2 flex-shrink justify-center"><form id="mc-embedded-subscribe-form" action="https://github.us2.list-manage.com/subscribe/post?u=43a795784ca963e25903a0da6&amp;id=9937fe4fc5" method="post" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate><div id="mc_embed_signup_scroll" class="grid grid-cols-1 sm:grid-cols-2 gap-4"><input id="mce-EMAIL" type="email" value="" name="EMAIL" placeholder="Enter your email address" class="rounded mc text-center" autocomplete="on"><div style="position:absolute;left:-5000px;" aria-hidden="true"><input type="text" name="b_43a795784ca963e25903a0da6_9937fe4fc5" tabindex="-1" value=""></div><div class="text-right" style="width:100%;"><input id="mc-embedded-subscribe" type="submit" value="Subscribe" name="subscribe" class="mc-btn rounded px-2 py-1 w-full"></div></div></form></div></div></div><hr><div class="py-4">Thanks for checking out my site!</div><div class="pb-4"> ¬© 2025 Brian Caffey </div></div></div></div></div><div id="teleports"></div><script type="application/json" data-nuxt-data="nuxt-app" data-ssr="true" id="__NUXT_DATA__" data-src="/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings/_payload.json?711989cd-b755-45e7-b273-f0754c0f755f">[{"state":1,"once":18,"_errors":19,"serverRendered":5,"path":21,"pinia":22,"prerenderedAt":23},["Reactive",2],{"$scolor-mode":3,"$si18n:cached-locale-configs":7,"$si18n:resolved-locale":8,"$ssite-config":9},{"preference":4,"value":4,"unknown":5,"forced":6},"system",true,false,{},"",{"_priority":10,"currentLocale":14,"defaultLocale":14,"env":15,"name":16,"url":17},{"name":11,"env":12,"url":11,"defaultLocale":13,"currentLocale":13},-3,-15,-2,"en-US","production","briancaffey.github.io","https://briancaffey.github.io",["Set"],["ShallowReactive",20],{"i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings":-1},"/2021/01/16/i-scraped-analyzed-and-generated-yc-companies-founders-and-work-at-a-startup-job-postings",{},1753130132310]</script><script>window.__NUXT__={};window.__NUXT__.config={public:{url:"https://briancaffey.github.io",content:{wsUrl:""},mdc:{components:{prose:true,map:{}},headings:{anchorLinks:{h1:false,h2:true,h3:true,h4:true,h5:false,h6:false}}},gtag:{enabled:true,initMode:"auto",id:"G-S8TVBBMW66",initCommands:[],config:{},tags:[],loadingStrategy:"defer",url:"https://www.googletagmanager.com/gtag/js"},i18n:{baseUrl:"",defaultLocale:"en",rootRedirect:"",redirectStatusCode:302,skipSettingLocaleOnNavigate:false,locales:[{code:"en",emoji:"flag-us",iso:"en-US",name:"English",flag:"üá∫üá∏",language:"en-US",_hreflang:"en-US",_sitemap:"en-US"},{code:"fr",emoji:"flag-fr",iso:"fr-FR",name:"Fran√ßais",flag:"üá´üá∑",language:"fr-FR",_hreflang:"fr-FR",_sitemap:"fr-FR"},{code:"zh",emoji:"flag-cn",iso:"zh-ZH",name:"ÁÆÄ‰Ωì‰∏≠Êñá",flag:"üá®üá≥",language:"zh-ZH",_hreflang:"zh-ZH",_sitemap:"zh-ZH"},{code:"ru",emoji:"flag-ru",iso:"ru-RU",name:"–†—É—Å—Å–∫–∏–π",flag:"üá∑üá∫",language:"ru-RU",_hreflang:"ru-RU",_sitemap:"ru-RU"},{code:"ja",emoji:"flag-jp",iso:"ja-JP",name:"Êó•Êú¨Ë™û",flag:"üáØüáµ",language:"ja-JP",_hreflang:"ja-JP",_sitemap:"ja-JP"},{code:"in",emoji:"flag-in",iso:"hi-IN",name:"‡§π‡§ø‡§Ç‡§¶‡•Ä",flag:"üáÆüá≥",language:"hi-IN",_hreflang:"hi-IN",_sitemap:"hi-IN"}],detectBrowserLanguage:{alwaysRedirect:false,cookieCrossOrigin:false,cookieDomain:"",cookieKey:"i18n_redirected",cookieSecure:false,fallbackLocale:"",redirectOn:"root",useCookie:true},experimental:{localeDetector:"",typedPages:true,typedOptionsAndMessages:false,alternateLinkCanonicalQueries:true,devCache:false,cacheLifetime:"",stripMessagesPayload:false,preload:false,strictSeo:false,nitroContextDetection:true},domainLocales:{en:{domain:""},fr:{domain:""},zh:{domain:""},ru:{domain:""},ja:{domain:""},in:{domain:""}}}},app:{baseURL:"/",buildId:"711989cd-b755-45e7-b273-f0754c0f755f",buildAssetsDir:"/_nuxt/",cdnURL:""}}</script></body></html>