[{"data":1,"prerenderedAt":5535},["ShallowReactive",2],{"all-articles":3},[4,515,2109],{"_path":5,"_dir":6,"_draft":7,"_partial":7,"_locale":8,"title":9,"description":10,"date":11,"image":12,"tags":13,"draft":7,"external":28,"comments":32,"body":33,"_type":509,"_id":510,"_source":511,"_file":512,"_stem":513,"_extension":514},"/2024/06/24/agents-of-inference-speed-of-light-nvidia-langchain-generative-ai-agents-developer-contest-update","24",false,"","Agents of Inference: Speed of Light -- Accelerating my Generative AI Agents project with NVIDIA NIMs, TensorRT and TensorRT-LLM","This article is a brief discusion on recent updates to my project for the Generative AI Agents Developer Contest by NVIDIA and LangChain","2024-06-24","/static/aoi/aoi_title.png",[14,15,16,17,18,19,20,21,22,23,24,25,26,27],"nvidia","langchain","agents","rtx","gpu","tensorrt","tensorrt-llm","ai","llm","llama","007","stable-diffusion","stable-video-diffusion","comfyui",[29],{"link":30,"site":31},"https://x.com/briancaffey/status/1802754703207583886","x",true,{"type":34,"children":35,"toc":501},"root",[36,45,62,67,124,130,143,149,154,168,177,190,198,206,211,220,225,233,238,246,305,310,318,323,331,345,351,356,364,377,385,390,398,403,409,423,428,436,441,449,454,462,467,472,478,483,491,496],{"type":37,"tag":38,"props":39,"children":41},"element","h2",{"id":40},"tldr",[42],{"type":43,"value":44},"text","tl;dr",{"type":37,"tag":46,"props":47,"children":48},"p",{},[49,51,60],{"type":43,"value":50},"\"Agents of Inference: Speed of Light\" is an update to my original entry for the Generative AI Agents Developer Contest by NVIDIA and LangChain. This update focuses on how I accelerated local text, image and video generation using TensorRT, TensorRT-LLM and NVIDIA NIMs. You can read the original article about \"Agents of Inference\" ",{"type":37,"tag":52,"props":53,"children":57},"a",{"href":54,"rel":55},"https://briancaffey.github.io/2024/06/17/agents-of-inference-nvidia-and-langchain-generative-ai-agent-developer-contest",[56],"nofollow",[58],{"type":43,"value":59},"here",{"type":43,"value":61},".",{"type":37,"tag":46,"props":63,"children":64},{},[65],{"type":43,"value":66},"Here's my original project submission post on ùïè that introduces the idea of generating short 007-style films using agents, LLMs and stable diffusion:",{"type":37,"tag":68,"props":69,"children":74},"blockquote",{"className":70,"dataTheme":73},[71,72],"twitter-tweet","tw-align-center","dark",[75,116,118],{"type":37,"tag":46,"props":76,"children":79},{"lang":77,"dir":78},"en","ltr",[80,82,86,88,94,96,102,103,109,110],{"type":43,"value":81},"Agents of Inference",{"type":37,"tag":83,"props":84,"children":85},"br",{},[],{"type":43,"value":87},"üç∏ü§µüèº‚Äç‚ôÇÔ∏è‚ö°Ô∏èüé•üé¨",{"type":37,"tag":52,"props":89,"children":91},{"href":90},"https://twitter.com/hashtag/NVIDIADevContest?src=hash&ref_src=twsrc%5Etfw",[92],{"type":43,"value":93},"#NVIDIADevContest",{"type":43,"value":95}," ",{"type":37,"tag":52,"props":97,"children":99},{"href":98},"https://twitter.com/hashtag/LangChain?src=hash&ref_src=twsrc%5Etfw",[100],{"type":43,"value":101},"#LangChain",{"type":43,"value":95},{"type":37,"tag":52,"props":104,"children":106},{"href":105},"https://twitter.com/NVIDIAAIDev?ref_src=twsrc%5Etfw",[107],{"type":43,"value":108},"@NVIDIAAIDev",{"type":43,"value":95},{"type":37,"tag":52,"props":111,"children":113},{"href":112},"https://t.co/VT3rgzFbD6",[114],{"type":43,"value":115},"pic.twitter.com/VT3rgzFbD6",{"type":43,"value":117},"‚Äî Brian Caffey (@briancaffey) ",{"type":37,"tag":52,"props":119,"children":121},{"href":120},"https://twitter.com/briancaffey/status/1802754703207583886?ref_src=twsrc%5Etfw",[122],{"type":43,"value":123},"June 17, 2024",{"type":37,"tag":125,"props":126,"children":129},"script",{"async":32,"src":127,"charSet":128},"https://platform.twitter.com/widgets.js","utf-8",[],{"type":37,"tag":46,"props":131,"children":132},{},[133,135,142],{"type":43,"value":134},"Here's a link to the ",{"type":37,"tag":52,"props":136,"children":139},{"href":137,"rel":138},"https://github.com/briancaffey/agents-of-inference",[56],[140],{"type":43,"value":141},"Agents of Inference code repository on GitHub",{"type":43,"value":61},{"type":37,"tag":38,"props":144,"children":146},{"id":145},"nvidia-nim-inference-microservices",[147],{"type":43,"value":148},"NVIDIA NIM inference microservices",{"type":37,"tag":46,"props":150,"children":151},{},[152],{"type":43,"value":153},"I thought NVIDIA NIMs was one of the most exciting announcements from GTC 2024. I'm a big fan of using docker containers everywhere, and the idea of standardizing NVIDIA tools and dependencies seemed to make a lot of sense. I had previously struggled to get TensorRT-LLM installed on Windows using example repos provided by NVIDIA.",{"type":37,"tag":46,"props":155,"children":156},{},[157,159,166],{"type":43,"value":158},"A few weeks ago NVIDIA announced that NVIDIA NIMs can be downloaded and run anywhere. I was able to download this NIM for the ",{"type":37,"tag":160,"props":161,"children":163},"code",{"className":162},[],[164],{"type":43,"value":165},"meta/llama3-8b-instruct",{"type":43,"value":167}," model:",{"type":37,"tag":46,"props":169,"children":170},{},[171],{"type":37,"tag":172,"props":173,"children":176},"img",{"alt":174,"src":175},"llama3 nim","/static/aoi/meta-llama3-nim.png",[],{"type":37,"tag":46,"props":178,"children":179},{},[180,182,188],{"type":43,"value":181},"Here are the logs for my NVIDIA NIM ",{"type":37,"tag":160,"props":183,"children":185},{"className":184},[],[186],{"type":43,"value":187},"Meta/Llama-3-8B-Instruct",{"type":43,"value":189}," running in docker container on Windows Subsystem for Linux on my NVIDIA GeForce RTX 4090 GPU-powered PC. Notice that it generates over 50 tokens per second!",{"type":37,"tag":46,"props":191,"children":192},{},[193],{"type":37,"tag":172,"props":194,"children":197},{"alt":195,"src":196},"trt llama3 local","/static/aoi/trt-llama3.png",[],{"type":37,"tag":46,"props":199,"children":200},{},[201],{"type":37,"tag":172,"props":202,"children":205},{"alt":203,"src":204},"token factory","/static/aoi/token-factory.png",[],{"type":37,"tag":46,"props":207,"children":208},{},[209],{"type":43,"value":210},"The one main hurdle I faced when running the NIM local was an error about no runnable profiles being available:",{"type":37,"tag":212,"props":213,"children":215},"pre",{"code":214},"ERROR 06-23 15:41:21.19 utils.py:21] Could not find a profile that is currently runnable with the detected hardware. Please check the system information below and make sure you have enough free GPUs.\nSYSTEM INFO\n- Free GPUs: \u003CNone>\n- Non-free GPUs:\n  -  [2684:10de] (0) NVIDIA GeForce RTX 4090 [current utilization: 7%]\n",[216],{"type":37,"tag":160,"props":217,"children":218},{"__ignoreMap":8},[219],{"type":43,"value":214},{"type":37,"tag":46,"props":221,"children":222},{},[223],{"type":43,"value":224},"This seemed odd, and I found another user with the same issue on the NVIDIA Developer Forum. I was able to get around this by going into the EUFI/BIOS of my PC and switch to integrated graphics:",{"type":37,"tag":46,"props":226,"children":227},{},[228],{"type":37,"tag":172,"props":229,"children":232},{"alt":230,"src":231},"bios","/static/aoi/bios.jpg",[],{"type":37,"tag":46,"props":234,"children":235},{},[236],{"type":43,"value":237},"It was great to be able to run \"Agents of Inference\" using NVIDIA NIM because it is just as simple as running a docker container:",{"type":37,"tag":212,"props":239,"children":241},{"code":240},"export CONTAINER_NAME=llama3-8b-instruct\nexport IMG_NAME=\"nvcr.io/nim/meta/${CONTAINER_NAME}:1.0.0\"\nexport LOCAL_NIM_CACHE=~/.cache/nim\nmkdir -p \"$LOCAL_NIM_CACHE\"\ndocker run -it --rm --name=$CONTAINER_NAME \\\n  --runtime=nvidia \\\n  --gpus all \\\n  --shm-size=16GB \\\n  -e NGC_API_KEY \\\n  -v \"$LOCAL_NIM_CACHE:/opt/nim/.cache\" \\\n  -u $(id -u) \\\n  -p 8000:8000 \\\n  $IMG_NAME\n",[242],{"type":37,"tag":160,"props":243,"children":244},{"__ignoreMap":8},[245],{"type":43,"value":240},{"type":37,"tag":46,"props":247,"children":248},{},[249,251,257,259,266,268,274,276,287,289,295,297,303],{"type":43,"value":250},"Before getting this to work, I was able to get a ",{"type":37,"tag":160,"props":252,"children":254},{"className":253},[],[255],{"type":43,"value":256},"/chat/completions",{"type":43,"value":258}," endpoint working with the Llama3 model on my fork of the ",{"type":37,"tag":52,"props":260,"children":263},{"href":261,"rel":262},"https://github.com/briancaffey/trt-llm-as-openai-windows/commit/edaa15fd026fe95e645e3d4ae9718dc3ecc3bb65",[56],[264],{"type":43,"value":265},"trt-llm-as-openai-windows",{"type":43,"value":267},". I borrowed code for the ",{"type":37,"tag":160,"props":269,"children":271},{"className":270},[],[272],{"type":43,"value":273},"TrtLlmAPI",{"type":43,"value":275}," from the ",{"type":37,"tag":52,"props":277,"children":280},{"href":278,"rel":279},"https://github.com/NVIDIA/ChatRTX",[56],[281],{"type":37,"tag":160,"props":282,"children":284},{"className":283},[],[285],{"type":43,"value":286},"NVIDIA/ChatRTX",{"type":43,"value":288}," repo and a function from ",{"type":37,"tag":160,"props":290,"children":292},{"className":291},[],[293],{"type":43,"value":294},"llama-index",{"type":43,"value":296}," called ",{"type":37,"tag":160,"props":298,"children":300},{"className":299},[],[301],{"type":43,"value":302},"messages_to_prompt_v3_instruct",{"type":43,"value":304}," which encodes messages with special tokens for chat. This was an interesting exercise and it taught me a lot about how LLMs do chat. I would like to continue working on this fork and see how to implement streaming endpoints for the Llama 3 model.",{"type":37,"tag":46,"props":306,"children":307},{},[308],{"type":43,"value":309},"Here is how Llama 3 does the instruct prompting:",{"type":37,"tag":212,"props":311,"children":313},{"code":312},"\u003C|begin_of_text|>\u003C|start_header_id|>system\u003C|end_header_id|>\n\nYou are a helpful AI assistant for travel tips and recommendations\u003C|eot_id|>\u003C|start_header_id|>user\u003C|end_header_id|>\n\nWhat can you help me with?\u003C|eot_id|>\u003C|start_header_id|>assistant\u003C|end_header_id|>\n",[314],{"type":37,"tag":160,"props":315,"children":316},{"__ignoreMap":8},[317],{"type":43,"value":312},{"type":37,"tag":46,"props":319,"children":320},{},[321],{"type":43,"value":322},"Compare this with how it was done with Llama2 chat:",{"type":37,"tag":212,"props":324,"children":326},{"code":325},"\u003Cs>[INST] \u003C\u003CSYS>>\n{{ system_prompt }}\n\u003C\u003C/SYS>>\n\n{{ user_message_1 }} [/INST] {{ model_answer_1 }} \u003C/s>\n\u003Cs>[INST] {{ user_message_2 }} [/INST]\n",[327],{"type":37,"tag":160,"props":328,"children":329},{"__ignoreMap":8},[330],{"type":43,"value":325},{"type":37,"tag":46,"props":332,"children":333},{},[334,336,343],{"type":43,"value":335},"You can read more about the difference between Llama 2 and 3 on the ",{"type":37,"tag":52,"props":337,"children":340},{"href":338,"rel":339},"https://llama.meta.com/docs/model-cards-and-prompt-formats",[56],[341],{"type":43,"value":342},"Model Card & Prompt formats",{"type":43,"value":344}," page on Meta's Llama website.",{"type":37,"tag":38,"props":346,"children":348},{"id":347},"langsmith",[349],{"type":43,"value":350},"LangSmith",{"type":37,"tag":46,"props":352,"children":353},{},[354],{"type":43,"value":355},"I recently started using LangSmith. It is an awesome product and it ties in really well to doing prototype work like in my project \"Agents of Inference\". I wish I had started using it earlier in my development cycle! All you need to do is add an API key to your environment and your application automatically starts tracing LLM calls. It also works well with LangGraph and allows you to trace the execution path of your graph. Also it is good to be aware that there are other products similar to LangSmith like LangFuse. I also saw a really neat demo from Datadog at GTC showing an alpha version of their LLM tracing and observability product.",{"type":37,"tag":46,"props":357,"children":358},{},[359],{"type":37,"tag":172,"props":360,"children":363},{"alt":361,"src":362},"langsmith screenshot","/static/aoi/langsmith.png",[],{"type":37,"tag":46,"props":365,"children":366},{},[367,369,375],{"type":43,"value":368},"LangSmith can also be helpful when the wrong JSON shape is parsed. I had a lot of difficulty with this in my project. When I used the Q4_K_M gguf quantized ",{"type":37,"tag":160,"props":370,"children":372},{"className":371},[],[373],{"type":43,"value":374},"Meta-Llama-3 8B-Instruct",{"type":43,"value":376}," model I had no issues with output parsing. Switching to the TensorRT-LLM model provided by the NIM resulted in some parsing errors. The application would report that JSON could not be parsed because the result contained text like: \"Here is the JSON that you requested\". I was able to get around this by changing the prompt template from:",{"type":37,"tag":212,"props":378,"children":380},{"code":379},"Answer the user query.\n",[381],{"type":37,"tag":160,"props":382,"children":383},{"__ignoreMap":8},[384],{"type":43,"value":379},{"type":37,"tag":46,"props":386,"children":387},{},[388],{"type":43,"value":389},"to",{"type":37,"tag":212,"props":391,"children":393},{"code":392},"Don't include ANYTHING except for valid JSON in your response. Answer the user query.\n",[394],{"type":37,"tag":160,"props":395,"children":396},{"__ignoreMap":8},[397],{"type":43,"value":392},{"type":37,"tag":46,"props":399,"children":400},{},[401],{"type":43,"value":402},"This was the most frustrating part of development, and I'm still getting occasional errors that I just skip over. I'm also probably have not exhausted all of the tools that LangChain provides to avoid these types of errors. Don't assume that output parsing that works with one model will work with another! This is another good reason to use something like LangSmith when developing LLM-based applications.",{"type":37,"tag":38,"props":404,"children":406},{"id":405},"comfyui-tensorrt",[407],{"type":43,"value":408},"ComfyUI TensorRT",{"type":37,"tag":46,"props":410,"children":411},{},[412,414,421],{"type":43,"value":413},"My goal with \"Agents of Inference\" was to be able to test out how small upstream prompt changes can impact the quality and consistency of a series of generated images and videos. Iteration speed is very important! I was able to significantly speed up image and video generation by using the ",{"type":37,"tag":52,"props":415,"children":418},{"href":416,"rel":417},"https://github.com/comfyanonymous/ComfyUI_TensorRT",[56],[419],{"type":43,"value":420},"ComfyUI TensorRT custom nodes",{"type":43,"value":422},". These nodes allow you to build engines with specifications for parameters that can be either static or dynamic. I had better luck with building dynamic engines. I was able to build and use engines for Stable Diffusion SDXL and Stable Video Diffusion XT.",{"type":37,"tag":46,"props":424,"children":425},{},[426],{"type":43,"value":427},"Building a TensorRT engine for ComfyUI can be done using the following workflow:",{"type":37,"tag":46,"props":429,"children":430},{},[431],{"type":37,"tag":172,"props":432,"children":435},{"alt":433,"src":434},"trt comfyUI build process","/static/aoi/comfyui-trt-svd-xt.png",[],{"type":37,"tag":46,"props":437,"children":438},{},[439],{"type":43,"value":440},"The engines can then be used in custom workflows like the following:",{"type":37,"tag":46,"props":442,"children":443},{},[444],{"type":37,"tag":172,"props":445,"children":448},{"alt":446,"src":447},"trt comfyui workflow","/static/aoi/svd-workflow-trt.png",[],{"type":37,"tag":46,"props":450,"children":451},{},[452],{"type":43,"value":453},"Once these workflows are configured and are working as expected, you can export them in API format (JSON) and use them to make API calls to the ComfyUI backend. The agents for stable diffusion and stable video diffusion made API calls in this way and it worked pretty well.",{"type":37,"tag":46,"props":455,"children":456},{},[457],{"type":37,"tag":172,"props":458,"children":461},{"alt":459,"src":460},"comfy its","/static/aoi/comfy-its.png",[],{"type":37,"tag":46,"props":463,"children":464},{},[465],{"type":43,"value":466},"Using 50 iterations, I was able to generate 1024x576 images in 3 seconds or about 19 iterations per second (it/s). Videos",{"type":37,"tag":46,"props":468,"children":469},{},[470],{"type":43,"value":471},"ComfyUI is still early in development and it refers to itself as \"alpha software\" even though it has a large adoption by a very active community already. I'm excited to see what is next from the developers of ComfyUI.",{"type":37,"tag":38,"props":473,"children":475},{"id":474},"speed-of-light",[476],{"type":43,"value":477},"Speed of Light",{"type":37,"tag":46,"props":479,"children":480},{},[481],{"type":43,"value":482},"\"Speed of Light\" is a term that I learned from a stable diffusion talk at GTC.",{"type":37,"tag":68,"props":484,"children":485},{},[486],{"type":37,"tag":46,"props":487,"children":488},{},[489],{"type":43,"value":490},"SOL analysis reveals how your code performs, and device utilization compared to relevant maximums.",{"type":37,"tag":46,"props":492,"children":493},{},[494],{"type":43,"value":495},"Adding TensorRT and TensorRT-LLM to inference services on my RTX PC helped increase the throughput of text, image and video generation for my \"Agents of Inference\" project. I'm looking forward to learning more about profiling and optimization techniques for both LLMs and Stable Diffusion workloads.",{"type":37,"tag":46,"props":497,"children":498},{},[499],{"type":43,"value":500},"Thanks again to NVIDIA and LangChain for organizing this contest! It was a lot of fun to learn about builing agents with LangChain and LangGraph and the latest developments from NVIDIA in Generative AI.",{"title":8,"searchDepth":502,"depth":502,"links":503},2,[504,505,506,507,508],{"id":40,"depth":502,"text":44},{"id":145,"depth":502,"text":148},{"id":347,"depth":502,"text":350},{"id":405,"depth":502,"text":408},{"id":474,"depth":502,"text":477},"markdown","content:2024:06:24:agents-of-inference-speed-of-light-nvidia-langchain-generative-ai-agents-developer-contest-update.md","content","2024/06/24/agents-of-inference-speed-of-light-nvidia-langchain-generative-ai-agents-developer-contest-update.md","2024/06/24/agents-of-inference-speed-of-light-nvidia-langchain-generative-ai-agents-developer-contest-update","md",{"_path":516,"_dir":517,"_draft":7,"_partial":7,"_locale":8,"title":518,"description":519,"date":520,"image":12,"tags":521,"draft":7,"external":522,"comments":32,"body":524,"_type":509,"_id":2106,"_source":511,"_file":2107,"_stem":2108,"_extension":514},"/2024/06/17/agents-of-inference-nvidia-and-langchain-generative-ai-agent-developer-contest","17","Agents of Inference: My submission for NVIDIA's Generative AI Agents Developer Contest by NVIDIA and LangChain","This article discusses my entry for NVIDIA's Generative AI Agents Developer Contest entry: Agents of Inference","2024-06-17",[14,15,16,17,18,19,20,21,22,23,24,25,26,27],[523],{"link":30,"site":31},{"type":34,"children":525,"toc":2085},[526,532,543,547,552,557,593,596,606,612,617,623,628,634,639,684,692,697,704,709,723,736,748,1132,1137,1180,1185,1350,1376,1382,1387,1493,1521,1528,1533,1539,1544,1623,1629,1634,1736,1744,1749,1754,1807,1828,1834,1855,1901,1906,1911,1917,1930,1938,1944,1981,1984,1989,1994,2000,2005,2011,2016,2022,2027,2035,2040,2046,2058,2064,2069,2074,2079],{"type":37,"tag":38,"props":527,"children":529},{"id":528},"update",[530],{"type":43,"value":531},"Update",{"type":37,"tag":46,"props":533,"children":534},{},[535,537],{"type":43,"value":536},"I recently posted another article about optimizing this project with TensorRT and TensorRT-LLM running on local NVIDIA NIM inference microservices, please have a look here: ",{"type":37,"tag":52,"props":538,"children":541},{"href":539,"rel":540},"https://briancaffey.github.io/2024/06/24/agents-of-inference-speed-of-light-nvidia-langchain-generative-ai-agents-developer-contest-update",[56],[542],{"type":43,"value":539},{"type":37,"tag":38,"props":544,"children":545},{"id":40},[546],{"type":43,"value":44},{"type":37,"tag":46,"props":548,"children":549},{},[550],{"type":43,"value":551},"‚ÄúAgents of Inference‚Äù is my entry for the Generative AI Agents Developer Contest by NVIDIA and LangChain. This project aims to integrate techniques for generating text, images and video to create an application capable of producing short thematic films. In this article, I will detail how I developed the project leveraging LangGraph‚Äîa library for building stateful, multi-actor applications with LLMs--and hybrid AI workflows using NVIDIA AI-powered tools and technologies running on RTX PCs and in the cloud.",{"type":37,"tag":46,"props":553,"children":554},{},[555],{"type":43,"value":556},"Here's my project submission post on ùïè:",{"type":37,"tag":68,"props":558,"children":560},{"className":559,"dataTheme":73},[71,72],[561,588,589],{"type":37,"tag":46,"props":562,"children":563},{"lang":77,"dir":78},[564,565,568,569,573,574,578,579,583,584],{"type":43,"value":81},{"type":37,"tag":83,"props":566,"children":567},{},[],{"type":43,"value":87},{"type":37,"tag":52,"props":570,"children":571},{"href":90},[572],{"type":43,"value":93},{"type":43,"value":95},{"type":37,"tag":52,"props":575,"children":576},{"href":98},[577],{"type":43,"value":101},{"type":43,"value":95},{"type":37,"tag":52,"props":580,"children":581},{"href":105},[582],{"type":43,"value":108},{"type":43,"value":95},{"type":37,"tag":52,"props":585,"children":586},{"href":112},[587],{"type":43,"value":115},{"type":43,"value":117},{"type":37,"tag":52,"props":590,"children":591},{"href":120},[592],{"type":43,"value":123},{"type":37,"tag":125,"props":594,"children":595},{"async":32,"src":127,"charSet":128},[],{"type":37,"tag":46,"props":597,"children":598},{},[599,600,605],{"type":43,"value":134},{"type":37,"tag":52,"props":601,"children":603},{"href":137,"rel":602},[56],[604],{"type":43,"value":141},{"type":43,"value":61},{"type":37,"tag":38,"props":607,"children":609},{"id":608},"nvidias-generative-ai-agents-developer-contest",[610],{"type":43,"value":611},"NVIDIA's Generative AI Agents Developer Contest",{"type":37,"tag":46,"props":613,"children":614},{},[615],{"type":43,"value":616},"AI agents are having a moment. They are the building blocks for building \"applications that reason\", and LangChain is a company that provides a comprehensive set of tools for developing, deploying and monitoring AI agents. I have struggled to understand how I can build or use agents in my own projects, and with the contest I have been able to just scratch the surface of what is possible with AI agents--but I think it is a promising paradigm for developing AI-driven applications.",{"type":37,"tag":38,"props":618,"children":620},{"id":619},"coming-up-with-an-idea",[621],{"type":43,"value":622},"Coming up with an idea",{"type":37,"tag":46,"props":624,"children":625},{},[626],{"type":43,"value":627},"I love stable diffusion. I closely follow the development of the three leading applications for generating images with stable dissuion models: Stable Diffusion WebUI, InvokeAI and ComfyUI. Write a prompt, instantly see the result, tweak the prompt and generate again. This is the basic process by which I have previously used stable diffusion. It is a satisfying mental exercise that feeds the creative and imaginative part of my brain. My idea for this project came from wanting to automate this process: use large language models to build cohesive scenes and detailed prompts and then feed them into my stable diffusion programs via API. Using LangChain and LangGraph allowed me to rapidly prototype the idea and start generating short feature films in the style of my favorite British Secret Agent: 007.",{"type":37,"tag":38,"props":629,"children":631},{"id":630},"putting-together-the-puzzle-pieces",[632],{"type":43,"value":633},"Putting together the puzzle pieces",{"type":37,"tag":46,"props":635,"children":636},{},[637],{"type":43,"value":638},"Here's how I set up an MVP for my project project to get started. I set up a simple graph (a linked list, really) that included the following nodes. *Important: in this context, a node is an agent, and that agent is a simple Python function. It takes one parameter which is the state, a Python dictionary, that holds the output of LLM calls that the agents make. Not all nodes make LLM calls, some just run basic functions like initializing directories or calling external stable diffusion APIs.",{"type":37,"tag":640,"props":641,"children":642},"ul",{},[643,649,654,659,664,669,674,679],{"type":37,"tag":644,"props":645,"children":646},"li",{},[647],{"type":43,"value":648},"Casting Agent ‚Üí come up with some characters",{"type":37,"tag":644,"props":650,"children":651},{},[652],{"type":43,"value":653},"Location Agent ‚Üí come up with some locations",{"type":37,"tag":644,"props":655,"children":656},{},[657],{"type":43,"value":658},"Synopsis Agent ‚Üí write a synopsis based on the characters and locations",{"type":37,"tag":644,"props":660,"children":661},{},[662],{"type":43,"value":663},"Scene Agent ‚Üí write some number of scenes based on the synopsis based on the synopsis",{"type":37,"tag":644,"props":665,"children":666},{},[667],{"type":43,"value":668},"Shot agent ‚Üí describe some number of camera shots for each scene based on the scene",{"type":37,"tag":644,"props":670,"children":671},{},[672],{"type":43,"value":673},"Photography agent ‚Üí take each shot description and generate and image",{"type":37,"tag":644,"props":675,"children":676},{},[677],{"type":43,"value":678},"Videography agent ‚Üí take each image generated by the photography agent and convert it to a 4 second clip using stable video diffusion",{"type":37,"tag":644,"props":680,"children":681},{},[682],{"type":43,"value":683},"Editor agent ‚Üí compile the movie clips together",{"type":37,"tag":46,"props":685,"children":686},{},[687],{"type":37,"tag":172,"props":688,"children":691},{"alt":689,"src":690},"simple graph of agents of inference","/static/aoi/graph.png",[],{"type":37,"tag":46,"props":693,"children":694},{},[695],{"type":43,"value":696},"It may look simple, but there is a lot going on in this graph.",{"type":37,"tag":698,"props":699,"children":701},"h3",{"id":700},"casting-and-location",[702],{"type":43,"value":703},"Casting and Location",{"type":37,"tag":46,"props":705,"children":706},{},[707],{"type":43,"value":708},"The first two agents in my graph are tasked with generating characters and locations that would appear in a British secret agent film. The prompts used for these agents are as follows:",{"type":37,"tag":68,"props":710,"children":711},{},[712],{"type":37,"tag":46,"props":713,"children":714},{},[715,721],{"type":37,"tag":716,"props":717,"children":718},"strong",{},[719],{"type":43,"value":720},"casting",{"type":43,"value":722},": \"Come up with four to five characters who will appear in an upcoming British spy movie. The list should include the main character who is male, the villain, an attractive female actress who eventually falls in love with the main character, and some other characters as well.\"",{"type":37,"tag":68,"props":724,"children":725},{},[726],{"type":37,"tag":46,"props":727,"children":728},{},[729,734],{"type":37,"tag":716,"props":730,"children":731},{},[732],{"type":43,"value":733},"locations",{"type":43,"value":735},": \"Provide three main locations that can be used in an international British Spy movie. The locations should include a variety of cities, remote environments, iconic landmarks, etc. The locations should make for good background scenes for an action movie with lots of stunts, chases, explosions, fights, etc. and other things you would find in an action movie. Be sure to include the country and a description of the environment where these places are.\"",{"type":37,"tag":46,"props":737,"children":738},{},[739,741,746],{"type":43,"value":740},"These agents leverage the LangChain Expression Language (LCEL) to generate ",{"type":37,"tag":716,"props":742,"children":743},{},[744],{"type":43,"value":745},"structured output",{"type":43,"value":747}," based on Pydantic models. For",{"type":37,"tag":212,"props":749,"children":753},{"code":750,"language":751,"meta":8,"className":752,"style":8},"class Character(BaseModel):\n    \"\"\"\n    The type for character that the casting agent casts for a role in the movie\n    \"\"\"\n    full_name: str = Field(description=\"The character's name\")\n    short_name: str = Field(description=\"The character's short name\")\n    background: str = Field(description=\"The character's background\")\n    physical_traits: str = Field(description=\"The physical traits of the character\")\n    ethnicity: str = Field(description=\"The character's ethnicity\")\n    gender: str = Field(description=\"The character's gender, either male of female\")\n    nationality: str = Field(description=\"The character's nationality\")\n    main_character: bool = Field(description=\"If the character is or is not the main character\")\n\n","python","language-python shiki shiki-themes github-light github-dark monokai",[754],{"type":37,"tag":160,"props":755,"children":756},{"__ignoreMap":8},[757,792,801,810,818,865,903,941,979,1017,1055,1093],{"type":37,"tag":758,"props":759,"children":762},"span",{"class":760,"line":761},"line",1,[763,769,775,781,787],{"type":37,"tag":758,"props":764,"children":766},{"style":765},"--shiki-default:#D73A49;--shiki-dark:#F97583;--shiki-sepia:#66D9EF;--shiki-default-font-style:inherit;--shiki-dark-font-style:inherit;--shiki-sepia-font-style:italic",[767],{"type":43,"value":768},"class",{"type":37,"tag":758,"props":770,"children":772},{"style":771},"--shiki-default:#6F42C1;--shiki-dark:#B392F0;--shiki-sepia:#A6E22E;--shiki-default-text-decoration:inherit;--shiki-dark-text-decoration:inherit;--shiki-sepia-text-decoration:underline",[773],{"type":43,"value":774}," Character",{"type":37,"tag":758,"props":776,"children":778},{"style":777},"--shiki-default:#24292E;--shiki-dark:#E1E4E8;--shiki-sepia:#F8F8F2",[779],{"type":43,"value":780},"(",{"type":37,"tag":758,"props":782,"children":784},{"style":783},"--shiki-default:#6F42C1;--shiki-dark:#B392F0;--shiki-sepia:#A6E22E;--shiki-default-font-style:inherit;--shiki-dark-font-style:inherit;--shiki-sepia-font-style:italic;--shiki-default-text-decoration:inherit;--shiki-dark-text-decoration:inherit;--shiki-sepia-text-decoration:underline",[785],{"type":43,"value":786},"BaseModel",{"type":37,"tag":758,"props":788,"children":789},{"style":777},[790],{"type":43,"value":791},"):\n",{"type":37,"tag":758,"props":793,"children":794},{"class":760,"line":502},[795],{"type":37,"tag":758,"props":796,"children":798},{"style":797},"--shiki-default:#032F62;--shiki-dark:#9ECBFF;--shiki-sepia:#E6DB74",[799],{"type":43,"value":800},"    \"\"\"\n",{"type":37,"tag":758,"props":802,"children":804},{"class":760,"line":803},3,[805],{"type":37,"tag":758,"props":806,"children":807},{"style":797},[808],{"type":43,"value":809},"    The type for character that the casting agent casts for a role in the movie\n",{"type":37,"tag":758,"props":811,"children":813},{"class":760,"line":812},4,[814],{"type":37,"tag":758,"props":815,"children":816},{"style":797},[817],{"type":43,"value":800},{"type":37,"tag":758,"props":819,"children":821},{"class":760,"line":820},5,[822,827,833,839,844,850,855,860],{"type":37,"tag":758,"props":823,"children":824},{"style":777},[825],{"type":43,"value":826},"    full_name: ",{"type":37,"tag":758,"props":828,"children":830},{"style":829},"--shiki-default:#005CC5;--shiki-dark:#79B8FF;--shiki-sepia:#66D9EF;--shiki-default-font-style:inherit;--shiki-dark-font-style:inherit;--shiki-sepia-font-style:italic",[831],{"type":43,"value":832},"str",{"type":37,"tag":758,"props":834,"children":836},{"style":835},"--shiki-default:#D73A49;--shiki-dark:#F97583;--shiki-sepia:#F92672",[837],{"type":43,"value":838}," =",{"type":37,"tag":758,"props":840,"children":841},{"style":777},[842],{"type":43,"value":843}," Field(",{"type":37,"tag":758,"props":845,"children":847},{"style":846},"--shiki-default:#E36209;--shiki-dark:#FFAB70;--shiki-sepia:#FD971F;--shiki-default-font-style:inherit;--shiki-dark-font-style:inherit;--shiki-sepia-font-style:italic",[848],{"type":43,"value":849},"description",{"type":37,"tag":758,"props":851,"children":852},{"style":835},[853],{"type":43,"value":854},"=",{"type":37,"tag":758,"props":856,"children":857},{"style":797},[858],{"type":43,"value":859},"\"The character's name\"",{"type":37,"tag":758,"props":861,"children":862},{"style":777},[863],{"type":43,"value":864},")\n",{"type":37,"tag":758,"props":866,"children":868},{"class":760,"line":867},6,[869,874,878,882,886,890,894,899],{"type":37,"tag":758,"props":870,"children":871},{"style":777},[872],{"type":43,"value":873},"    short_name: ",{"type":37,"tag":758,"props":875,"children":876},{"style":829},[877],{"type":43,"value":832},{"type":37,"tag":758,"props":879,"children":880},{"style":835},[881],{"type":43,"value":838},{"type":37,"tag":758,"props":883,"children":884},{"style":777},[885],{"type":43,"value":843},{"type":37,"tag":758,"props":887,"children":888},{"style":846},[889],{"type":43,"value":849},{"type":37,"tag":758,"props":891,"children":892},{"style":835},[893],{"type":43,"value":854},{"type":37,"tag":758,"props":895,"children":896},{"style":797},[897],{"type":43,"value":898},"\"The character's short name\"",{"type":37,"tag":758,"props":900,"children":901},{"style":777},[902],{"type":43,"value":864},{"type":37,"tag":758,"props":904,"children":906},{"class":760,"line":905},7,[907,912,916,920,924,928,932,937],{"type":37,"tag":758,"props":908,"children":909},{"style":777},[910],{"type":43,"value":911},"    background: ",{"type":37,"tag":758,"props":913,"children":914},{"style":829},[915],{"type":43,"value":832},{"type":37,"tag":758,"props":917,"children":918},{"style":835},[919],{"type":43,"value":838},{"type":37,"tag":758,"props":921,"children":922},{"style":777},[923],{"type":43,"value":843},{"type":37,"tag":758,"props":925,"children":926},{"style":846},[927],{"type":43,"value":849},{"type":37,"tag":758,"props":929,"children":930},{"style":835},[931],{"type":43,"value":854},{"type":37,"tag":758,"props":933,"children":934},{"style":797},[935],{"type":43,"value":936},"\"The character's background\"",{"type":37,"tag":758,"props":938,"children":939},{"style":777},[940],{"type":43,"value":864},{"type":37,"tag":758,"props":942,"children":944},{"class":760,"line":943},8,[945,950,954,958,962,966,970,975],{"type":37,"tag":758,"props":946,"children":947},{"style":777},[948],{"type":43,"value":949},"    physical_traits: ",{"type":37,"tag":758,"props":951,"children":952},{"style":829},[953],{"type":43,"value":832},{"type":37,"tag":758,"props":955,"children":956},{"style":835},[957],{"type":43,"value":838},{"type":37,"tag":758,"props":959,"children":960},{"style":777},[961],{"type":43,"value":843},{"type":37,"tag":758,"props":963,"children":964},{"style":846},[965],{"type":43,"value":849},{"type":37,"tag":758,"props":967,"children":968},{"style":835},[969],{"type":43,"value":854},{"type":37,"tag":758,"props":971,"children":972},{"style":797},[973],{"type":43,"value":974},"\"The physical traits of the character\"",{"type":37,"tag":758,"props":976,"children":977},{"style":777},[978],{"type":43,"value":864},{"type":37,"tag":758,"props":980,"children":982},{"class":760,"line":981},9,[983,988,992,996,1000,1004,1008,1013],{"type":37,"tag":758,"props":984,"children":985},{"style":777},[986],{"type":43,"value":987},"    ethnicity: ",{"type":37,"tag":758,"props":989,"children":990},{"style":829},[991],{"type":43,"value":832},{"type":37,"tag":758,"props":993,"children":994},{"style":835},[995],{"type":43,"value":838},{"type":37,"tag":758,"props":997,"children":998},{"style":777},[999],{"type":43,"value":843},{"type":37,"tag":758,"props":1001,"children":1002},{"style":846},[1003],{"type":43,"value":849},{"type":37,"tag":758,"props":1005,"children":1006},{"style":835},[1007],{"type":43,"value":854},{"type":37,"tag":758,"props":1009,"children":1010},{"style":797},[1011],{"type":43,"value":1012},"\"The character's ethnicity\"",{"type":37,"tag":758,"props":1014,"children":1015},{"style":777},[1016],{"type":43,"value":864},{"type":37,"tag":758,"props":1018,"children":1020},{"class":760,"line":1019},10,[1021,1026,1030,1034,1038,1042,1046,1051],{"type":37,"tag":758,"props":1022,"children":1023},{"style":777},[1024],{"type":43,"value":1025},"    gender: ",{"type":37,"tag":758,"props":1027,"children":1028},{"style":829},[1029],{"type":43,"value":832},{"type":37,"tag":758,"props":1031,"children":1032},{"style":835},[1033],{"type":43,"value":838},{"type":37,"tag":758,"props":1035,"children":1036},{"style":777},[1037],{"type":43,"value":843},{"type":37,"tag":758,"props":1039,"children":1040},{"style":846},[1041],{"type":43,"value":849},{"type":37,"tag":758,"props":1043,"children":1044},{"style":835},[1045],{"type":43,"value":854},{"type":37,"tag":758,"props":1047,"children":1048},{"style":797},[1049],{"type":43,"value":1050},"\"The character's gender, either male of female\"",{"type":37,"tag":758,"props":1052,"children":1053},{"style":777},[1054],{"type":43,"value":864},{"type":37,"tag":758,"props":1056,"children":1058},{"class":760,"line":1057},11,[1059,1064,1068,1072,1076,1080,1084,1089],{"type":37,"tag":758,"props":1060,"children":1061},{"style":777},[1062],{"type":43,"value":1063},"    nationality: ",{"type":37,"tag":758,"props":1065,"children":1066},{"style":829},[1067],{"type":43,"value":832},{"type":37,"tag":758,"props":1069,"children":1070},{"style":835},[1071],{"type":43,"value":838},{"type":37,"tag":758,"props":1073,"children":1074},{"style":777},[1075],{"type":43,"value":843},{"type":37,"tag":758,"props":1077,"children":1078},{"style":846},[1079],{"type":43,"value":849},{"type":37,"tag":758,"props":1081,"children":1082},{"style":835},[1083],{"type":43,"value":854},{"type":37,"tag":758,"props":1085,"children":1086},{"style":797},[1087],{"type":43,"value":1088},"\"The character's nationality\"",{"type":37,"tag":758,"props":1090,"children":1091},{"style":777},[1092],{"type":43,"value":864},{"type":37,"tag":758,"props":1094,"children":1096},{"class":760,"line":1095},12,[1097,1102,1107,1111,1115,1119,1123,1128],{"type":37,"tag":758,"props":1098,"children":1099},{"style":777},[1100],{"type":43,"value":1101},"    main_character: ",{"type":37,"tag":758,"props":1103,"children":1104},{"style":829},[1105],{"type":43,"value":1106},"bool",{"type":37,"tag":758,"props":1108,"children":1109},{"style":835},[1110],{"type":43,"value":838},{"type":37,"tag":758,"props":1112,"children":1113},{"style":777},[1114],{"type":43,"value":843},{"type":37,"tag":758,"props":1116,"children":1117},{"style":846},[1118],{"type":43,"value":849},{"type":37,"tag":758,"props":1120,"children":1121},{"style":835},[1122],{"type":43,"value":854},{"type":37,"tag":758,"props":1124,"children":1125},{"style":797},[1126],{"type":43,"value":1127},"\"If the character is or is not the main character\"",{"type":37,"tag":758,"props":1129,"children":1130},{"style":777},[1131],{"type":43,"value":864},{"type":37,"tag":46,"props":1133,"children":1134},{},[1135],{"type":43,"value":1136},"LCEL offers wonderful syntactic sugar, I can use this model in a parse and pip that into the output from the mode:",{"type":37,"tag":212,"props":1138,"children":1140},{"code":1139,"language":751,"meta":8,"className":752,"style":8},"chain = prompt | model | parser\n",[1141],{"type":37,"tag":160,"props":1142,"children":1143},{"__ignoreMap":8},[1144],{"type":37,"tag":758,"props":1145,"children":1146},{"class":760,"line":761},[1147,1152,1156,1161,1166,1171,1175],{"type":37,"tag":758,"props":1148,"children":1149},{"style":777},[1150],{"type":43,"value":1151},"chain ",{"type":37,"tag":758,"props":1153,"children":1154},{"style":835},[1155],{"type":43,"value":854},{"type":37,"tag":758,"props":1157,"children":1158},{"style":777},[1159],{"type":43,"value":1160}," prompt ",{"type":37,"tag":758,"props":1162,"children":1163},{"style":835},[1164],{"type":43,"value":1165},"|",{"type":37,"tag":758,"props":1167,"children":1168},{"style":777},[1169],{"type":43,"value":1170}," model ",{"type":37,"tag":758,"props":1172,"children":1173},{"style":835},[1174],{"type":43,"value":1165},{"type":37,"tag":758,"props":1176,"children":1177},{"style":777},[1178],{"type":43,"value":1179}," parser\n",{"type":37,"tag":46,"props":1181,"children":1182},{},[1183],{"type":43,"value":1184},"This results in our structured data:",{"type":37,"tag":212,"props":1186,"children":1190},{"code":1187,"language":1188,"meta":8,"className":1189,"style":8},"cast:\n- background: Former MI6 agent\n  ethnicity: British\n  full_name: James Alexander\n  gender: Male\n  main_character: true\n  nationality: British\n  physical_traits: Tall, dark hair, blue eyes\n  short_name: Jamie\n","yml","language-yml shiki shiki-themes github-light github-dark monokai",[1191],{"type":37,"tag":160,"props":1192,"children":1193},{"__ignoreMap":8},[1194,1208,1231,1248,1265,1282,1300,1316,1333],{"type":37,"tag":758,"props":1195,"children":1196},{"class":760,"line":761},[1197,1203],{"type":37,"tag":758,"props":1198,"children":1200},{"style":1199},"--shiki-default:#22863A;--shiki-dark:#85E89D;--shiki-sepia:#F92672",[1201],{"type":43,"value":1202},"cast",{"type":37,"tag":758,"props":1204,"children":1205},{"style":777},[1206],{"type":43,"value":1207},":\n",{"type":37,"tag":758,"props":1209,"children":1210},{"class":760,"line":502},[1211,1216,1221,1226],{"type":37,"tag":758,"props":1212,"children":1213},{"style":777},[1214],{"type":43,"value":1215},"- ",{"type":37,"tag":758,"props":1217,"children":1218},{"style":1199},[1219],{"type":43,"value":1220},"background",{"type":37,"tag":758,"props":1222,"children":1223},{"style":777},[1224],{"type":43,"value":1225},": ",{"type":37,"tag":758,"props":1227,"children":1228},{"style":797},[1229],{"type":43,"value":1230},"Former MI6 agent\n",{"type":37,"tag":758,"props":1232,"children":1233},{"class":760,"line":803},[1234,1239,1243],{"type":37,"tag":758,"props":1235,"children":1236},{"style":1199},[1237],{"type":43,"value":1238},"  ethnicity",{"type":37,"tag":758,"props":1240,"children":1241},{"style":777},[1242],{"type":43,"value":1225},{"type":37,"tag":758,"props":1244,"children":1245},{"style":797},[1246],{"type":43,"value":1247},"British\n",{"type":37,"tag":758,"props":1249,"children":1250},{"class":760,"line":812},[1251,1256,1260],{"type":37,"tag":758,"props":1252,"children":1253},{"style":1199},[1254],{"type":43,"value":1255},"  full_name",{"type":37,"tag":758,"props":1257,"children":1258},{"style":777},[1259],{"type":43,"value":1225},{"type":37,"tag":758,"props":1261,"children":1262},{"style":797},[1263],{"type":43,"value":1264},"James Alexander\n",{"type":37,"tag":758,"props":1266,"children":1267},{"class":760,"line":820},[1268,1273,1277],{"type":37,"tag":758,"props":1269,"children":1270},{"style":1199},[1271],{"type":43,"value":1272},"  gender",{"type":37,"tag":758,"props":1274,"children":1275},{"style":777},[1276],{"type":43,"value":1225},{"type":37,"tag":758,"props":1278,"children":1279},{"style":797},[1280],{"type":43,"value":1281},"Male\n",{"type":37,"tag":758,"props":1283,"children":1284},{"class":760,"line":867},[1285,1290,1294],{"type":37,"tag":758,"props":1286,"children":1287},{"style":1199},[1288],{"type":43,"value":1289},"  main_character",{"type":37,"tag":758,"props":1291,"children":1292},{"style":777},[1293],{"type":43,"value":1225},{"type":37,"tag":758,"props":1295,"children":1297},{"style":1296},"--shiki-default:#005CC5;--shiki-dark:#79B8FF;--shiki-sepia:#AE81FF",[1298],{"type":43,"value":1299},"true\n",{"type":37,"tag":758,"props":1301,"children":1302},{"class":760,"line":905},[1303,1308,1312],{"type":37,"tag":758,"props":1304,"children":1305},{"style":1199},[1306],{"type":43,"value":1307},"  nationality",{"type":37,"tag":758,"props":1309,"children":1310},{"style":777},[1311],{"type":43,"value":1225},{"type":37,"tag":758,"props":1313,"children":1314},{"style":797},[1315],{"type":43,"value":1247},{"type":37,"tag":758,"props":1317,"children":1318},{"class":760,"line":943},[1319,1324,1328],{"type":37,"tag":758,"props":1320,"children":1321},{"style":1199},[1322],{"type":43,"value":1323},"  physical_traits",{"type":37,"tag":758,"props":1325,"children":1326},{"style":777},[1327],{"type":43,"value":1225},{"type":37,"tag":758,"props":1329,"children":1330},{"style":797},[1331],{"type":43,"value":1332},"Tall, dark hair, blue eyes\n",{"type":37,"tag":758,"props":1334,"children":1335},{"class":760,"line":981},[1336,1341,1345],{"type":37,"tag":758,"props":1337,"children":1338},{"style":1199},[1339],{"type":43,"value":1340},"  short_name",{"type":37,"tag":758,"props":1342,"children":1343},{"style":777},[1344],{"type":43,"value":1225},{"type":37,"tag":758,"props":1346,"children":1347},{"style":797},[1348],{"type":43,"value":1349},"Jamie\n",{"type":37,"tag":46,"props":1351,"children":1352},{},[1353,1355,1361,1363,1374],{"type":43,"value":1354},"I saved the state for all \"Agents of Inference\" invocations in the ",{"type":37,"tag":160,"props":1356,"children":1358},{"className":1357},[],[1359],{"type":43,"value":1360},"output",{"type":43,"value":1362}," directory of my ",{"type":37,"tag":52,"props":1364,"children":1367},{"href":1365,"rel":1366},"https://github.com/briancaffey/agents-of-inference/tree/main/output",[56],[1368],{"type":37,"tag":160,"props":1369,"children":1371},{"className":1370},[],[1372],{"type":43,"value":1373},"agents-of-inference",{"type":43,"value":1375}," GitHub repo. I didn't commit the images and videos, but you can follow @AgentInference on X to see more of the results from my development process and future improvements, as well!",{"type":37,"tag":698,"props":1377,"children":1379},{"id":1378},"synopsis-agent",[1380],{"type":43,"value":1381},"Synopsis Agent",{"type":37,"tag":46,"props":1383,"children":1384},{},[1385],{"type":43,"value":1386},"With a cast of characters and locations selected, we need a synopsis to determine what happens. Here's the prompt:",{"type":37,"tag":212,"props":1388,"children":1392},{"code":1389,"language":1390,"meta":8,"className":1391,"style":8},"synopsis: |\n  Generate a synopsis for a British spy agent movie in the style of the James Bond series. The synopsis should include the following elements:\n  Protagonist: A charismatic and skilled British secret agent with a code name (e.g., \"Agent X\") who works for a top-secret government agency (e.g., MI6).\n  Antagonist: A formidable villain with a grand, sinister plan that threatens global security. The antagonist should have a unique, memorable persona and a well-defined motivation.\n  Mission: Outline the high-stakes mission that the protagonist must undertake to thwart the antagonist‚Äôs plan.\n  Gadgets and Vehicles: Mention the cutting-edge gadgets and vehicles that the protagonist uses throughout the mission. These should be inventive and integral to the plot.\n  Action Sequences: Include a brief description of some thrilling action sequences, such as car, boat, plane chases, hand-to-hand combat, and daring escapes, and dangerous situations.\n  Big Reveal: There is a big reveal toward the end of the storyline that is surprising and the reveal helps to move the story along.\n  Climactic Showdown: Describe the final confrontation between the protagonist and the antagonist. This should be intense and action-packed, leading to a satisfying resolution. Should include details about the main character is victorious.\n  Setting: Ensure that the settings are diverse and visually striking, adding to the overall excitement and suspense of the story. This should involve multiple locations in exotic environments, the wilderness, in dangerous situations, on board planes, trains, boats and fancy cars, etc.\n  Tone and Style: Maintain the sophisticated, suave, and adventurous tone that is characteristic of the James Bond series. Include elements of intrigue, romance, and humor.\n","yaml","language-yaml shiki shiki-themes github-light github-dark monokai",[1393],{"type":37,"tag":160,"props":1394,"children":1395},{"__ignoreMap":8},[1396,1413,1421,1429,1437,1445,1453,1461,1469,1477,1485],{"type":37,"tag":758,"props":1397,"children":1398},{"class":760,"line":761},[1399,1404,1408],{"type":37,"tag":758,"props":1400,"children":1401},{"style":1199},[1402],{"type":43,"value":1403},"synopsis",{"type":37,"tag":758,"props":1405,"children":1406},{"style":777},[1407],{"type":43,"value":1225},{"type":37,"tag":758,"props":1409,"children":1410},{"style":835},[1411],{"type":43,"value":1412},"|\n",{"type":37,"tag":758,"props":1414,"children":1415},{"class":760,"line":502},[1416],{"type":37,"tag":758,"props":1417,"children":1418},{"style":797},[1419],{"type":43,"value":1420},"  Generate a synopsis for a British spy agent movie in the style of the James Bond series. The synopsis should include the following elements:\n",{"type":37,"tag":758,"props":1422,"children":1423},{"class":760,"line":803},[1424],{"type":37,"tag":758,"props":1425,"children":1426},{"style":797},[1427],{"type":43,"value":1428},"  Protagonist: A charismatic and skilled British secret agent with a code name (e.g., \"Agent X\") who works for a top-secret government agency (e.g., MI6).\n",{"type":37,"tag":758,"props":1430,"children":1431},{"class":760,"line":812},[1432],{"type":37,"tag":758,"props":1433,"children":1434},{"style":797},[1435],{"type":43,"value":1436},"  Antagonist: A formidable villain with a grand, sinister plan that threatens global security. The antagonist should have a unique, memorable persona and a well-defined motivation.\n",{"type":37,"tag":758,"props":1438,"children":1439},{"class":760,"line":820},[1440],{"type":37,"tag":758,"props":1441,"children":1442},{"style":797},[1443],{"type":43,"value":1444},"  Mission: Outline the high-stakes mission that the protagonist must undertake to thwart the antagonist‚Äôs plan.\n",{"type":37,"tag":758,"props":1446,"children":1447},{"class":760,"line":867},[1448],{"type":37,"tag":758,"props":1449,"children":1450},{"style":797},[1451],{"type":43,"value":1452},"  Gadgets and Vehicles: Mention the cutting-edge gadgets and vehicles that the protagonist uses throughout the mission. These should be inventive and integral to the plot.\n",{"type":37,"tag":758,"props":1454,"children":1455},{"class":760,"line":905},[1456],{"type":37,"tag":758,"props":1457,"children":1458},{"style":797},[1459],{"type":43,"value":1460},"  Action Sequences: Include a brief description of some thrilling action sequences, such as car, boat, plane chases, hand-to-hand combat, and daring escapes, and dangerous situations.\n",{"type":37,"tag":758,"props":1462,"children":1463},{"class":760,"line":943},[1464],{"type":37,"tag":758,"props":1465,"children":1466},{"style":797},[1467],{"type":43,"value":1468},"  Big Reveal: There is a big reveal toward the end of the storyline that is surprising and the reveal helps to move the story along.\n",{"type":37,"tag":758,"props":1470,"children":1471},{"class":760,"line":981},[1472],{"type":37,"tag":758,"props":1473,"children":1474},{"style":797},[1475],{"type":43,"value":1476},"  Climactic Showdown: Describe the final confrontation between the protagonist and the antagonist. This should be intense and action-packed, leading to a satisfying resolution. Should include details about the main character is victorious.\n",{"type":37,"tag":758,"props":1478,"children":1479},{"class":760,"line":1019},[1480],{"type":37,"tag":758,"props":1481,"children":1482},{"style":797},[1483],{"type":43,"value":1484},"  Setting: Ensure that the settings are diverse and visually striking, adding to the overall excitement and suspense of the story. This should involve multiple locations in exotic environments, the wilderness, in dangerous situations, on board planes, trains, boats and fancy cars, etc.\n",{"type":37,"tag":758,"props":1486,"children":1487},{"class":760,"line":1057},[1488],{"type":37,"tag":758,"props":1489,"children":1490},{"style":797},[1491],{"type":43,"value":1492},"  Tone and Style: Maintain the sophisticated, suave, and adventurous tone that is characteristic of the James Bond series. Include elements of intrigue, romance, and humor.\n",{"type":37,"tag":46,"props":1494,"children":1495},{},[1496,1498,1504,1506,1512,1514,1519],{"type":43,"value":1497},"The synopsis to any good film is key, so I decided to use a feature of LangGraph that would allow a ",{"type":37,"tag":160,"props":1499,"children":1501},{"className":1500},[],[1502],{"type":43,"value":1503},"synopsis_review_agent",{"type":43,"value":1505}," to provide multiple rounds of feedback to the ",{"type":37,"tag":160,"props":1507,"children":1509},{"className":1508},[],[1510],{"type":43,"value":1511},"synopsis_agent",{"type":43,"value":1513}," to make it even better. Here's what the new graph look like after implementing the ",{"type":37,"tag":160,"props":1515,"children":1517},{"className":1516},[],[1518],{"type":43,"value":1503},{"type":43,"value":1520}," using conditional graph edges:",{"type":37,"tag":46,"props":1522,"children":1523},{},[1524],{"type":37,"tag":172,"props":1525,"children":1527},{"alt":1503,"src":1526},"/static/aoi/graph_with_cycle.png",[],{"type":37,"tag":46,"props":1529,"children":1530},{},[1531],{"type":43,"value":1532},"Conditional edges are a very powerful feature and I just used it in one part of my graph. Other parts of the graph could benefit from this as well, and they can allow for \"human-in-the-loop\" interactions which are becoming very popular in AI-powered applications.",{"type":37,"tag":698,"props":1534,"children":1536},{"id":1535},"scene-and-shot-agents",[1537],{"type":43,"value":1538},"Scene and shot agents",{"type":37,"tag":46,"props":1540,"children":1541},{},[1542],{"type":43,"value":1543},"With our perfected synopsis, we are ready to put more agents to work. The scene agent builds out the basic structure of the storyline. It provides a structured list of the main sections of the movie. The shot agent then loops over the scenes and creates a number of different shots for the given scene. This was an effective way to have consistent thematic content for shots within a scene. Here are the prompts I used for the scene and shot agents:",{"type":37,"tag":212,"props":1545,"children":1547},{"code":1546,"language":1390,"meta":8,"className":1391,"style":8},"scenes: |\n  Create a list of detailed scenes for an exciting and entertaining British spy film. The scenes should be comprehensive and include all scenes necessary for a complete film. Each scene should include the following elements:\n  Location: Describe the location and setting of the scene, including any notable landmarks, time of day, and general atmosphere.\n  Characters Involved: List the main characters present in the scene, with a brief description of their roles and appearances.\n  Description of What Happens: Provide a detailed account of the action, and key events that take place in the scene.\nshot: |\n  You are a film director working on a new British spy film and your writers have provided you with a scene. Your task is to come up with four to five shots that will be filmed during the scene. The shot descriptions needs to be specific and should include a varietry of closeup shots on characters, environment shots that consider the scene location and shots of specific items or other things that are featured in the scene. Each shot should also have a title. The description should be a brief densely worded block of text that captures the important elements of the scene. Consider the style of camera angle, lighting, character expressions, clothing, and other important visual elements for each shot. Be very descriptive. The description will be used to generate an image of the shot. Also, there should be at most one actor for each shot that contains people. Don't use the name of the character, instead use a physical description of the character based on their physical traits described below if needed. Also consider what the actor is wearing in the description.\n",[1548],{"type":37,"tag":160,"props":1549,"children":1550},{"__ignoreMap":8},[1551,1567,1575,1583,1591,1599,1615],{"type":37,"tag":758,"props":1552,"children":1553},{"class":760,"line":761},[1554,1559,1563],{"type":37,"tag":758,"props":1555,"children":1556},{"style":1199},[1557],{"type":43,"value":1558},"scenes",{"type":37,"tag":758,"props":1560,"children":1561},{"style":777},[1562],{"type":43,"value":1225},{"type":37,"tag":758,"props":1564,"children":1565},{"style":835},[1566],{"type":43,"value":1412},{"type":37,"tag":758,"props":1568,"children":1569},{"class":760,"line":502},[1570],{"type":37,"tag":758,"props":1571,"children":1572},{"style":797},[1573],{"type":43,"value":1574},"  Create a list of detailed scenes for an exciting and entertaining British spy film. The scenes should be comprehensive and include all scenes necessary for a complete film. Each scene should include the following elements:\n",{"type":37,"tag":758,"props":1576,"children":1577},{"class":760,"line":803},[1578],{"type":37,"tag":758,"props":1579,"children":1580},{"style":797},[1581],{"type":43,"value":1582},"  Location: Describe the location and setting of the scene, including any notable landmarks, time of day, and general atmosphere.\n",{"type":37,"tag":758,"props":1584,"children":1585},{"class":760,"line":812},[1586],{"type":37,"tag":758,"props":1587,"children":1588},{"style":797},[1589],{"type":43,"value":1590},"  Characters Involved: List the main characters present in the scene, with a brief description of their roles and appearances.\n",{"type":37,"tag":758,"props":1592,"children":1593},{"class":760,"line":820},[1594],{"type":37,"tag":758,"props":1595,"children":1596},{"style":797},[1597],{"type":43,"value":1598},"  Description of What Happens: Provide a detailed account of the action, and key events that take place in the scene.\n",{"type":37,"tag":758,"props":1600,"children":1601},{"class":760,"line":867},[1602,1607,1611],{"type":37,"tag":758,"props":1603,"children":1604},{"style":1199},[1605],{"type":43,"value":1606},"shot",{"type":37,"tag":758,"props":1608,"children":1609},{"style":777},[1610],{"type":43,"value":1225},{"type":37,"tag":758,"props":1612,"children":1613},{"style":835},[1614],{"type":43,"value":1412},{"type":37,"tag":758,"props":1616,"children":1617},{"class":760,"line":905},[1618],{"type":37,"tag":758,"props":1619,"children":1620},{"style":797},[1621],{"type":43,"value":1622},"  You are a film director working on a new British spy film and your writers have provided you with a scene. Your task is to come up with four to five shots that will be filmed during the scene. The shot descriptions needs to be specific and should include a varietry of closeup shots on characters, environment shots that consider the scene location and shots of specific items or other things that are featured in the scene. Each shot should also have a title. The description should be a brief densely worded block of text that captures the important elements of the scene. Consider the style of camera angle, lighting, character expressions, clothing, and other important visual elements for each shot. Be very descriptive. The description will be used to generate an image of the shot. Also, there should be at most one actor for each shot that contains people. Don't use the name of the character, instead use a physical description of the character based on their physical traits described below if needed. Also consider what the actor is wearing in the description.\n",{"type":37,"tag":698,"props":1624,"children":1626},{"id":1625},"stable-diffusion-and-stable-video-diffusion-agents",[1627],{"type":43,"value":1628},"Stable Diffusion and Stable Video Diffusion agents",{"type":37,"tag":46,"props":1630,"children":1631},{},[1632],{"type":43,"value":1633},"The stable diffusion agent makes an API call to a local instance of the Stable Diffusion WebUI API, saves the generated image and saves a reference to that image in the state:",{"type":37,"tag":212,"props":1635,"children":1637},{"code":1636,"language":1390,"meta":8,"className":1391,"style":8},"- description: A medium close-up shot of Ethan Jameson's face, with a concerned expression,\n    as he reads the message from Natalie Jackson. The lighting is dim, with only a\n    single lamp on his desk casting a warm glow. His eyes are narrowed, and his brow\n    is furrowed in concentration. He is wearing a dark blue suit and a white shirt.\n  image: 000.png\n  title: Ethan's Concerned Expression\n  video: 000.mp4\n",[1638],{"type":37,"tag":160,"props":1639,"children":1640},{"__ignoreMap":8},[1641,1661,1669,1677,1685,1702,1719],{"type":37,"tag":758,"props":1642,"children":1643},{"class":760,"line":761},[1644,1648,1652,1656],{"type":37,"tag":758,"props":1645,"children":1646},{"style":777},[1647],{"type":43,"value":1215},{"type":37,"tag":758,"props":1649,"children":1650},{"style":1199},[1651],{"type":43,"value":849},{"type":37,"tag":758,"props":1653,"children":1654},{"style":777},[1655],{"type":43,"value":1225},{"type":37,"tag":758,"props":1657,"children":1658},{"style":797},[1659],{"type":43,"value":1660},"A medium close-up shot of Ethan Jameson's face, with a concerned expression,\n",{"type":37,"tag":758,"props":1662,"children":1663},{"class":760,"line":502},[1664],{"type":37,"tag":758,"props":1665,"children":1666},{"style":797},[1667],{"type":43,"value":1668},"    as he reads the message from Natalie Jackson. The lighting is dim, with only a\n",{"type":37,"tag":758,"props":1670,"children":1671},{"class":760,"line":803},[1672],{"type":37,"tag":758,"props":1673,"children":1674},{"style":797},[1675],{"type":43,"value":1676},"    single lamp on his desk casting a warm glow. His eyes are narrowed, and his brow\n",{"type":37,"tag":758,"props":1678,"children":1679},{"class":760,"line":812},[1680],{"type":37,"tag":758,"props":1681,"children":1682},{"style":797},[1683],{"type":43,"value":1684},"    is furrowed in concentration. He is wearing a dark blue suit and a white shirt.\n",{"type":37,"tag":758,"props":1686,"children":1687},{"class":760,"line":820},[1688,1693,1697],{"type":37,"tag":758,"props":1689,"children":1690},{"style":1199},[1691],{"type":43,"value":1692},"  image",{"type":37,"tag":758,"props":1694,"children":1695},{"style":777},[1696],{"type":43,"value":1225},{"type":37,"tag":758,"props":1698,"children":1699},{"style":797},[1700],{"type":43,"value":1701},"000.png\n",{"type":37,"tag":758,"props":1703,"children":1704},{"class":760,"line":867},[1705,1710,1714],{"type":37,"tag":758,"props":1706,"children":1707},{"style":1199},[1708],{"type":43,"value":1709},"  title",{"type":37,"tag":758,"props":1711,"children":1712},{"style":777},[1713],{"type":43,"value":1225},{"type":37,"tag":758,"props":1715,"children":1716},{"style":797},[1717],{"type":43,"value":1718},"Ethan's Concerned Expression\n",{"type":37,"tag":758,"props":1720,"children":1721},{"class":760,"line":905},[1722,1727,1731],{"type":37,"tag":758,"props":1723,"children":1724},{"style":1199},[1725],{"type":43,"value":1726},"  video",{"type":37,"tag":758,"props":1728,"children":1729},{"style":777},[1730],{"type":43,"value":1225},{"type":37,"tag":758,"props":1732,"children":1733},{"style":797},[1734],{"type":43,"value":1735},"000.mp4\n",{"type":37,"tag":46,"props":1737,"children":1738},{},[1739],{"type":37,"tag":172,"props":1740,"children":1743},{"alt":1741,"src":1742},"A medium close-up shot of Ethan Jameson's face","/static/aoi/ethan.png",[],{"type":37,"tag":46,"props":1745,"children":1746},{},[1747],{"type":43,"value":1748},"With the perfectly prompted image in hand, we can use Stable Video Diffusion to bring it to life. I prompted phind to come up with a FastAPI service that would accept an image in a post request and return a short video created with stable video diffusion using the diffusers library.",{"type":37,"tag":46,"props":1750,"children":1751},{},[1752],{"type":43,"value":1753},"Stable video diffusion can generate about 4 seconds of text at 7 frames per second. This isn't great, but I was able to use ffmpeg to do frame interpolation bringing the frame rate to a much smoother 14 fps using motion compensated interpolation (MCI):",{"type":37,"tag":212,"props":1755,"children":1759},{"code":1756,"language":1757,"meta":8,"className":1758,"style":8},"ffmpeg -i output/1718453390/final.mp4 -crf 10 -vf \"minterpolate=fps=14:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1\" output/1718453390/final.14fps.mp4\n","bash","language-bash shiki shiki-themes github-light github-dark monokai",[1760],{"type":37,"tag":160,"props":1761,"children":1762},{"__ignoreMap":8},[1763],{"type":37,"tag":758,"props":1764,"children":1765},{"class":760,"line":761},[1766,1772,1777,1782,1787,1792,1797,1802],{"type":37,"tag":758,"props":1767,"children":1769},{"style":1768},"--shiki-default:#6F42C1;--shiki-dark:#B392F0;--shiki-sepia:#A6E22E",[1770],{"type":43,"value":1771},"ffmpeg",{"type":37,"tag":758,"props":1773,"children":1774},{"style":1296},[1775],{"type":43,"value":1776}," -i",{"type":37,"tag":758,"props":1778,"children":1779},{"style":797},[1780],{"type":43,"value":1781}," output/1718453390/final.mp4",{"type":37,"tag":758,"props":1783,"children":1784},{"style":1296},[1785],{"type":43,"value":1786}," -crf",{"type":37,"tag":758,"props":1788,"children":1789},{"style":1296},[1790],{"type":43,"value":1791}," 10",{"type":37,"tag":758,"props":1793,"children":1794},{"style":1296},[1795],{"type":43,"value":1796}," -vf",{"type":37,"tag":758,"props":1798,"children":1799},{"style":797},[1800],{"type":43,"value":1801}," \"minterpolate=fps=14:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1\"",{"type":37,"tag":758,"props":1803,"children":1804},{"style":797},[1805],{"type":43,"value":1806}," output/1718453390/final.14fps.mp4\n",{"type":37,"tag":46,"props":1808,"children":1809},{},[1810,1812,1818,1820,1826],{"type":43,"value":1811},"Finally, the ",{"type":37,"tag":160,"props":1813,"children":1815},{"className":1814},[],[1816],{"type":43,"value":1817},"editor_agent",{"type":43,"value":1819}," uses ",{"type":37,"tag":160,"props":1821,"children":1823},{"className":1822},[],[1824],{"type":43,"value":1825},"moviepy",{"type":43,"value":1827}," to join the clips together into a single video.",{"type":37,"tag":38,"props":1829,"children":1831},{"id":1830},"development-environment",[1832],{"type":43,"value":1833},"Development environment",{"type":37,"tag":46,"props":1835,"children":1836},{},[1837,1839,1845,1847,1853],{"type":43,"value":1838},"I struggled to optimize the ",{"type":37,"tag":160,"props":1840,"children":1842},{"className":1841},[],[1843],{"type":43,"value":1844},"meta-llama/Meta-Llama-3-8B-Instruct",{"type":43,"value":1846}," with TensorRT-LLM, so I ran LLM inference on a combination of older Llama2 TensorRT-LLM models, and ",{"type":37,"tag":160,"props":1848,"children":1850},{"className":1849},[],[1851],{"type":43,"value":1852},"Meta-Llama-3-8B-Instruct",{"type":43,"value":1854}," on LM Studio (which I found to be painfully slow compared to TensorRT-LLM).",{"type":37,"tag":46,"props":1856,"children":1857},{},[1858,1860,1866,1868,1874,1876,1882,1884,1891,1893,1899],{"type":43,"value":1859},"If you provide an ",{"type":37,"tag":160,"props":1861,"children":1863},{"className":1862},[],[1864],{"type":43,"value":1865},"NVIDIA_API_KEY",{"type":43,"value":1867}," in the ",{"type":37,"tag":160,"props":1869,"children":1871},{"className":1870},[],[1872],{"type":43,"value":1873},".env",{"type":43,"value":1875}," file, LLM calls will be made using the ",{"type":37,"tag":160,"props":1877,"children":1879},{"className":1878},[],[1880],{"type":43,"value":1881},"meta/llam3-70b-instruct",{"type":43,"value":1883}," model on ",{"type":37,"tag":52,"props":1885,"children":1888},{"href":1886,"rel":1887},"https://build.nvidia.com/meta/llama3-70b",[56],[1889],{"type":43,"value":1890},"build.nvidia.com/meta/llama3-70b",{"type":43,"value":1892},". In fact, ",{"type":37,"tag":160,"props":1894,"children":1896},{"className":1895},[],[1897],{"type":43,"value":1898},"build.nvidia.com",{"type":43,"value":1900}," also provides stable diffusion and stable video diffusion inference via API. This would be very convenient in the event that my RTX PCs become compromised.",{"type":37,"tag":46,"props":1902,"children":1903},{},[1904],{"type":43,"value":1905},"My RTX 4090 GPU with 24 GB of memory was able to run lots of different inference servers concurrently (LLM, Stable Diffusion WebUI, ComfyUI, InvokeAI, Stable Video Diffusion FastAPI service), but I generally stuck to doing one type of inference at a time, otherwise things would grind to a hault or crash. I also experimented with ChatTTS, a new text-to-speech model.",{"type":37,"tag":46,"props":1907,"children":1908},{},[1909],{"type":43,"value":1910},"I developed this project on a MacBook Pro, and I used my RTX PC as if it were a remote service providing inference for text, images and video. This is a helpful mindset when working with hybrid AI workflows that leverage inference services both on local machines and in the cloud.",{"type":37,"tag":38,"props":1912,"children":1914},{"id":1913},"how-it-works",[1915],{"type":43,"value":1916},"How it works",{"type":37,"tag":46,"props":1918,"children":1919},{},[1920,1922,1928],{"type":43,"value":1921},"To run the program, you need to install python dependencies and then run an OpenAI compatible LLM and Stable Duffsion WebUI server with the ",{"type":37,"tag":160,"props":1923,"children":1925},{"className":1924},[],[1926],{"type":43,"value":1927},"--api",{"type":43,"value":1929}," flag. You also need to run the Stable Video Diffusion service. Apologies for any hardcoded local IP address in the source code. Deadlines, you know! With everything configured, you can run the following command:",{"type":37,"tag":212,"props":1931,"children":1933},{"code":1932},"~/git/github/agents-of-inference$ poetry run python agents_of_inference/main.py\n## üìÄ Using local models üìÄ ##\n## üé≠ Generating Cast üé≠ ##\n## üó∫Ô∏è Generating Locations üó∫Ô∏è ##\n## ‚úçÔ∏è Generating Synopsis ‚úçÔ∏è ##\n## going to synopsis_review_agent ##\n## üìë Reviewing Synopsis üìë ##\n## ‚úçÔ∏è Generating Synopsis ‚úçÔ∏è ##\n## going to synopsis_review_agent ##\n## üìë Reviewing Synopsis üìë ##\n## ‚úçÔ∏è Generating Synopsis ‚úçÔ∏è ##\n## going to scene_agent ##\n## üìí Generating Scenes üìí ##\n## üé¨ Generating Shots üé¨ ##\n## Generated 5 shots for scene 1/5 ##\n## Generated 5 shots for scene 2/5 ##\n## Generated 5 shots for scene 3/5 ##\n## Generated 5 shots for scene 4/5 ##\n## Generated 5 shots for scene 5/5 ##\n\n000/0025\nA medium shot of a bustling Tokyo street, with neon lights reflecting off wet pavement. Jim Thompson, dressed in a black leather jacket and dark jeans, walks purposefully through the crowd, his piercing blue eyes scanning the area. The sound design features the hum of traffic and chatter of pedestrians.\nGenerated image output/1718426686/images/000.png\n\n001/0025\nA tight close-up shot of Emily Chen's face, her piercing brown eyes intense as she briefs Jim on the situation. Her short black hair is styled neatly, and she wears a crisp white blouse with a silver necklace. The camera lingers on her lips as she speaks, emphasizing the importance of the information.\nGenerated image output/1718426686/images/001.png\n\nGenerated video output/1718426686/videos/000.mp4\n== stable video diffusion generation complete ==\nGenerated video output/1718426686/videos/001.mp4\n== stable video diffusion generation complete ==\n",[1934],{"type":37,"tag":160,"props":1935,"children":1936},{"__ignoreMap":8},[1937],{"type":43,"value":1932},{"type":37,"tag":38,"props":1939,"children":1941},{"id":1940},"demo-video-for-contest-submission",[1942],{"type":43,"value":1943},"Demo Video for Contest Submission",{"type":37,"tag":68,"props":1945,"children":1948},{"className":1946,"dataMediaMaxWidth":1947},[71,72],"560",[1949,1976,1977],{"type":37,"tag":46,"props":1950,"children":1951},{"lang":77,"dir":78},[1952,1953,1956,1957,1961,1962,1966,1967,1971,1972],{"type":43,"value":81},{"type":37,"tag":83,"props":1954,"children":1955},{},[],{"type":43,"value":87},{"type":37,"tag":52,"props":1958,"children":1959},{"href":90},[1960],{"type":43,"value":93},{"type":43,"value":95},{"type":37,"tag":52,"props":1963,"children":1964},{"href":98},[1965],{"type":43,"value":101},{"type":43,"value":95},{"type":37,"tag":52,"props":1968,"children":1969},{"href":105},[1970],{"type":43,"value":108},{"type":43,"value":95},{"type":37,"tag":52,"props":1973,"children":1974},{"href":112},[1975],{"type":43,"value":115},{"type":43,"value":117},{"type":37,"tag":52,"props":1978,"children":1979},{"href":120},[1980],{"type":43,"value":123},{"type":37,"tag":125,"props":1982,"children":1983},{"async":32,"src":127,"charSet":128},[],{"type":37,"tag":46,"props":1985,"children":1986},{},[1987],{"type":43,"value":1988},"Making this video was a lot of fun. The \"Agents of Inference\" highlight reel includes some of the most interesting, exciting and fun clips that I found in the dozens of short films it created. It is important to note that a lot of the content is not very good. Misunderstood prompts, color confusion (prompt includes green eyes, but other things in the scene are also conspicuously green), unrealistic or noisy motion from Stable Video Diffusion--these are some of the issues you will find in the films. Generating AI images sometimes feels like panning for gold: you go through a lot of sediment to get a few good flakes.",{"type":37,"tag":46,"props":1990,"children":1991},{},[1992],{"type":43,"value":1993},"Also, I added a few short animations that I made with Blender. The final scene shows the NVIDIA Omniverse orange humanoid from the barrel of a pistol. I think we are rapidly approaching a future where agents can generate full-scale theatrical movies by generating OpenUSD code, directly or indirectly. Maybe for the next NVIDIA Developer contest!",{"type":37,"tag":38,"props":1995,"children":1997},{"id":1996},"shortcomings-of-my-project",[1998],{"type":43,"value":1999},"Shortcomings of my project",{"type":37,"tag":46,"props":2001,"children":2002},{},[2003],{"type":43,"value":2004},"My goodness, how embarrasing. There are quite a few shortcomings that can be easily identified looking over the output and the source code. Here are a few:",{"type":37,"tag":698,"props":2006,"children":2008},{"id":2007},"character-variety",[2009],{"type":43,"value":2010},"Character variety",{"type":37,"tag":46,"props":2012,"children":2013},{},[2014],{"type":43,"value":2015},"When generating characters I would frequently see one named Dr. Sophia Patel who is apparently a brilliant cryptologist. Other characters would often have different names or backgrounds, but a saw Dr. Sophia Patel more often than not.",{"type":37,"tag":698,"props":2017,"children":2019},{"id":2018},"character-consistency",[2020],{"type":43,"value":2021},"Character consistency",{"type":37,"tag":46,"props":2023,"children":2024},{},[2025],{"type":43,"value":2026},"The characters are not consistent. This is a notoriously difficult problem to solve, but I made a lot of progress on it during this contest. I experimented with calling the ComfyUI API to run a custom workflow built with the ComfyUI graph-based workflow tool for face transfer:",{"type":37,"tag":46,"props":2028,"children":2029},{},[2030],{"type":37,"tag":172,"props":2031,"children":2034},{"alt":2032,"src":2033},"Dr. Sophia Patel","/static/aoi/sophia.png",[],{"type":37,"tag":46,"props":2036,"children":2037},{},[2038],{"type":43,"value":2039},"Using ComfyUI would be nice, but it wouldn't be as easy to tap into cloud APIs if my workflow heavily relied on ComfyUI server with custom models.",{"type":37,"tag":698,"props":2041,"children":2043},{"id":2042},"understanding-langchain",[2044],{"type":43,"value":2045},"Understanding LangChain",{"type":37,"tag":46,"props":2047,"children":2048},{},[2049,2051,2056],{"type":43,"value":2050},"I started out with the idea I would store all LLM calls to a local JSON to serve as a cache, allowing me to avoid regenerating responses from early in the workflow. This worked well, until I tried to serialize an Annotated list (required for cycles such as the one used with ",{"type":37,"tag":160,"props":2052,"children":2054},{"className":2053},[],[2055],{"type":43,"value":1503},{"type":43,"value":2057},"). I ended up wasting a lot of time trying to figure this out, and I came across some built-in LangChain features for storing state in memory and in Sqlite. I'm sure there are other areas where I used the wrong pattern, but I turned over a lot of stones and look forward to continuing development with LangChain.",{"type":37,"tag":38,"props":2059,"children":2061},{"id":2060},"whats-next",[2062],{"type":43,"value":2063},"What's next?",{"type":37,"tag":46,"props":2065,"children":2066},{},[2067],{"type":43,"value":2068},"Thank you to NVIDIA and LangChain for organizing this contest. It was a great way to explore a powerful toolset for automated content generation using AI agents.",{"type":37,"tag":46,"props":2070,"children":2071},{},[2072],{"type":43,"value":2073},"Video models like Dream Machine and Sora have made some big splashes on the internet and the results are remarkable. However, I'm still almost more interested in finding the limitations of quality content using open-source models on consumer hardware like RTX GPUs.",{"type":37,"tag":46,"props":2075,"children":2076},{},[2077],{"type":43,"value":2078},"I would also have loved to generate my own music for these films. I am a Suno poweruser and love the songs I have generated on that site. Will the gap between video and music generation on private, payed services and local machines? Or does it just need time to catch up? Hopefully a future installment of \"Agents of Inference\" will integrate music and voice, and can't wait to hear it!",{"type":37,"tag":2080,"props":2081,"children":2082},"style",{},[2083],{"type":43,"value":2084},"html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .sepia .shiki span {color: var(--shiki-sepia);background: var(--shiki-sepia-bg);font-style: var(--shiki-sepia-font-style);font-weight: var(--shiki-sepia-font-weight);text-decoration: var(--shiki-sepia-text-decoration);}html.sepia .shiki span {color: var(--shiki-sepia);background: var(--shiki-sepia-bg);font-style: var(--shiki-sepia-font-style);font-weight: var(--shiki-sepia-font-weight);text-decoration: var(--shiki-sepia-text-decoration);}",{"title":8,"searchDepth":502,"depth":502,"links":2086},[2087,2088,2089,2090,2091,2097,2098,2099,2100,2105],{"id":528,"depth":502,"text":531},{"id":40,"depth":502,"text":44},{"id":608,"depth":502,"text":611},{"id":619,"depth":502,"text":622},{"id":630,"depth":502,"text":633,"children":2092},[2093,2094,2095,2096],{"id":700,"depth":803,"text":703},{"id":1378,"depth":803,"text":1381},{"id":1535,"depth":803,"text":1538},{"id":1625,"depth":803,"text":1628},{"id":1830,"depth":502,"text":1833},{"id":1913,"depth":502,"text":1916},{"id":1940,"depth":502,"text":1943},{"id":1996,"depth":502,"text":1999,"children":2101},[2102,2103,2104],{"id":2007,"depth":803,"text":2010},{"id":2018,"depth":803,"text":2021},{"id":2042,"depth":803,"text":2045},{"id":2060,"depth":502,"text":2063},"content:2024:06:17:agents-of-inference-nvidia-and-langchain-generative-ai-agent-developer-contest.md","2024/06/17/agents-of-inference-nvidia-and-langchain-generative-ai-agent-developer-contest.md","2024/06/17/agents-of-inference-nvidia-and-langchain-generative-ai-agent-developer-contest",{"_path":2110,"_dir":2111,"_draft":7,"_partial":7,"_locale":8,"title":2112,"description":2113,"date":2114,"image":2115,"tags":2116,"external":2122,"comments":32,"body":2131,"_type":509,"_id":5532,"_source":511,"_file":5533,"_stem":5534,"_extension":514},"/2023/08/27/python-vue-chinese-llama-2-and-the-three-body-problem","27","Python, Vue, Chinese-LLaMA-2 and The Three-Body Problem","Translating The Three-Body Problem book to English with Chinese LLMs, making visualizations with stable diffusion and running n-body simulations with CUDA","2023-11-23","/static/three-body-problem/cover.png",[2117,23,22,21,2118,751,14,2119,18,25,15,2120,2121],"three-body-problem","chinese","cuda","vue","three.js",[2123,2126,2129],{"link":2124,"site":2125},"https://news.ycombinator.com/item?id=38393757","hn",{"link":2127,"site":2128},"https://www.reddit.com/r/threebodyproblem/comments/1823l5j/python_vue_chinesellama2_and_the_threebody_problem/","reddit",{"link":2130,"site":31},"https://twitter.com/briancaffey/status/1727710878349332614",{"type":34,"children":2132,"toc":5515},[2133,2138,2143,2186,2191,2196,2202,2207,2215,2229,2234,2242,2247,2255,2260,2268,2273,2283,2288,2294,2299,2322,2327,2360,2366,2380,2393,2399,2413,2418,2445,2453,2459,2464,2469,2474,2479,2487,2492,2497,2502,2525,2531,2536,2770,2778,2791,2799,2807,3005,3017,3025,3030,3068,3074,3079,3087,3097,3105,3113,3118,3124,3129,3135,3140,4246,4251,4362,4367,4777,4804,4809,4983,4996,5009,5173,5178,5237,5250,5255,5316,5328,5333,5338,5343,5351,5357,5362,5367,5373,5378,5386,5391,5399,5404,5409,5414,5420,5433,5438,5489,5503,5511],{"type":37,"tag":2134,"props":2135,"children":2136},"h1",{"id":40},[2137],{"type":43,"value":44},{"type":37,"tag":46,"props":2139,"children":2140},{},[2141],{"type":43,"value":2142},"This articles brings together several of my interest, both old and new:",{"type":37,"tag":640,"props":2144,"children":2145},{},[2146,2151,2156,2161,2166,2171,2176,2181],{"type":37,"tag":644,"props":2147,"children":2148},{},[2149],{"type":43,"value":2150},"The Sci-Fi book series 'Three-Body Problem' by Liu Cixun",{"type":37,"tag":644,"props":2152,"children":2153},{},[2154],{"type":43,"value":2155},"Chinese language",{"type":37,"tag":644,"props":2157,"children":2158},{},[2159],{"type":43,"value":2160},"NLP techniques",{"type":37,"tag":644,"props":2162,"children":2163},{},[2164],{"type":43,"value":2165},"Large Language Models (LLMs)",{"type":37,"tag":644,"props":2167,"children":2168},{},[2169],{"type":43,"value":2170},"Stable Diffusion",{"type":37,"tag":644,"props":2172,"children":2173},{},[2174],{"type":43,"value":2175},"Data visualization and 3D graphics",{"type":37,"tag":644,"props":2177,"children":2178},{},[2179],{"type":43,"value":2180},"Mathematics",{"type":37,"tag":644,"props":2182,"children":2183},{},[2184],{"type":43,"value":2185},"NVIDIA / CUDA",{"type":37,"tag":46,"props":2187,"children":2188},{},[2189],{"type":43,"value":2190},"This is a linguistic, artistic and computational experiment with the two big AI algorithms of 2023: large language models (LLMs) and Stable Diffusion. I used the leading open-source LLMs from China‚Äôs tech sector to translate and summarize the text of Chinese author Liu Cixin‚Äôs award-winning science fiction novel: The Three-Body Problem. The book's storyline is based on a simple yet elusive problem from classical physics: predicting the movement of three gravitationally-attracted objects in space. I generated code for simulations and visualizations of this physics problem to present my own solutions to the three-body problem based on parallel computation. I also used Stable Diffusion to portray the imaginitive solutions to the three-body physics problem from one of the book‚Äôs main settings: an immersive virtual-reality game that spans centries of world history.",{"type":37,"tag":46,"props":2192,"children":2193},{},[2194],{"type":43,"value":2195},"I also share some of my experiences in China as an exchange student and research manager in the renewable energy technology sector. I wrote this article in English and translated it into Chinese using the same large language models I used to translate the Chinese text of the sci-fi novel into English. Warning: this article contains spoilers for the first book in the trilogy!",{"type":37,"tag":38,"props":2197,"children":2199},{"id":2198},"back-story",[2200],{"type":43,"value":2201},"Back story",{"type":37,"tag":46,"props":2203,"children":2204},{},[2205],{"type":43,"value":2206},"A few months ago my company announced that another round of layoffs was to come the following week. I'm on an engineering team that had already been impacted by a few rounds of layoffs in the past year, and I was expecting to be let go. On an impulse I bought a book at the top of my reading list from Amazon: \"Three-Body Problem\". It is an award-winning Sci-Fi trilogy written by Liu Cixin, a Chinese computer engineer who started writing the book as a series of essays that were published in China's \"World of Sci-Fi\" magazine.",{"type":37,"tag":46,"props":2208,"children":2209},{},[2210],{"type":37,"tag":172,"props":2211,"children":2214},{"alt":2212,"src":2213},"Images of Three Body Problem Book Series","/static/three-body-problem/books.png",[],{"type":37,"tag":46,"props":2216,"children":2217},{},[2218,2220,2227],{"type":43,"value":2219},"I started learning Chinese in college, adding a major in Chinese Language to the mathematics major I decided on in my freshman year after taking vector calculus and linear algebra. In my sophmore year I did a semester abroad at Fudan University's ",{"type":37,"tag":52,"props":2221,"children":2224},{"href":2222,"rel":2223},"https://ices.fudan.edu.cn/6628/list.htm",[56],[2225],{"type":43,"value":2226},"International Cultural Exchange School",{"type":43,"value":2228},". In 2007, living and studying Chinese in Shanghai as a 19 year old American was a really fun time. I was placed in an advanced-level course with a diverse group of students where English was not the lowest common linguistic denominator. We had a demanding cirriculum that emphasized reading, listening and speaking Chinese, but most of the language learning came through extracirricular activities: exploring Shanghai's food scene, bartering with vendors at the fabric markets, late night clubbing, walking around the Bund and the French Concession and chatting with my taxi cab drivers. It is hard to imagine how I did this without an iPhone, but I was able to get pretty far with an old Nokia 3310.",{"type":37,"tag":46,"props":2230,"children":2231},{},[2232],{"type":43,"value":2233},"At the end of one night of particularly heavy drinking, some of my classmates and I dropped in on an wangba (internet cafe) before heading back to the international dorm. Chinese internet cafes in 2007 were an expansive underground dens of computers, monitors, MMORPGs, FPSs, cigarets, and on-demand instant noodles delivered directly to your seat through an app on the desktop. That night our game of choice was Counter-Strike. In one of the lowest points of my gaming career, my classmates and I were crushed by our Chinese counterterrorist opponent.",{"type":37,"tag":46,"props":2235,"children":2236},{},[2237],{"type":37,"tag":172,"props":2238,"children":2241},{"alt":2239,"src":2240},"Chinese internet cafe","/static/three-body-problem/wangba.webp",[],{"type":37,"tag":46,"props":2243,"children":2244},{},[2245],{"type":43,"value":2246},"My favorite memory of that semester at Fudan University was travelling on an epic over-night sleeper train from Shanghai to Guangxi province with a school-sponsored class trip to see Guilin. Multiple games of sam-yuk-gu (3-6-9) ran in parallel across the matrix of 3-by-2 sleeper car bunk beds lining the train car like workloads distributed across multiple GPU cores. The rules of 3-6-9 are simple: a group of people go around in a circle counting up from 1. If your number contains a 3, 6 or 9, you clap once for each occurance of the number instead of saying your number. The first person to break the rules takes a drink. Then repeat indefinitely. The next morning we all boarded a boat cruise in a daze to see the Lijiang river's stunning limestone peaks featured on the 20 yuan note:",{"type":37,"tag":46,"props":2248,"children":2249},{},[2250],{"type":37,"tag":172,"props":2251,"children":2254},{"alt":2252,"src":2253},"20 yuan note with Guilin rock formations","/static/three-body-problem/twenty_small.gif",[],{"type":37,"tag":46,"props":2256,"children":2257},{},[2258],{"type":43,"value":2259},"My second job after college took me back to China where I specialized in the technologies, policies and applications of large scale battery projects as a research manager for China's energy storage industry association. The job exposed me to the power industry and cutting-edge battery projects, and also sharpened my technical Chinese as I was frequently reading, translating in a bi-linguagl environment. It was fun  I didn't realize it at the time, but that job was great preperation for reading Chinese Sci-Fi novels.",{"type":37,"tag":46,"props":2261,"children":2262},{},[2263],{"type":37,"tag":172,"props":2264,"children":2267},{"alt":2265,"src":2266},"State Grid HQ in Xi Cheng","/static/three-body-problem/invokeai/castles.png",[],{"type":37,"tag":46,"props":2269,"children":2270},{},[2271],{"type":43,"value":2272},"My first introduction to the 'Three-Body Problem' book came from one of my best friends from college. He lived at the inner-most leaf-node of one of Beijing's most labrythnian hutongs next to a family that trained racing pigeons. My friend and I bonded over our study of Chinese language, classical guitar and our experiences in Beijing. I strongly considered his recommendation to check out ‰∏â‰Ωì (Three Body), the Chinese Sci-Fi novel about alien life in a solar system with three stars as he described it, but I never had the chance to read the book.",{"type":37,"tag":2274,"props":2275,"children":2282},"iframe",{"width":2276,"height":2277,"src":2278,"title":2279,"frameBorder":2280,"allow":2281,"allowFullScreen":32},"100%",315,"https://www.youtube.com/embed/5lj99Uz1d50?si=TwrypbY4vTfeWGRf","YouTube video player","0","accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share",[],{"type":37,"tag":46,"props":2284,"children":2285},{},[2286],{"type":43,"value":2287},"Almost 10 years later I came across across a preview for the Netflix production of \"3 Body Problem\" scheduled to come out in early 2024. With the possibility of loosing my job weighing heavily on me, I picked up the books on Amazon hoping to have something to if I was going to be layed off. Over the weekend I was able to read a few of the chapters on my Kindle. I had not completely forgotten how to speak Chinese, and I could easily look up words and translate entire paragraphs with Google Translate.",{"type":37,"tag":38,"props":2289,"children":2291},{"id":2290},"chinese-in-numbers",[2292],{"type":43,"value":2293},"Chinese in numbers",{"type":37,"tag":46,"props":2295,"children":2296},{},[2297],{"type":43,"value":2298},"Here's a quick primer on the Chinese language from a mathematical perspective. This will be helpful before jumping into using NLP and LLMs with Chinese text later in this article.",{"type":37,"tag":46,"props":2300,"children":2301},{},[2302,2304,2311,2313,2320],{"type":43,"value":2303},"First, how many Chinese characters are there? This question isn't specific enough to have a single answer. A common rule of thumb that I have heard before says that there are over 50,000 characters in total with roughly 10,000 characters in use and about 3,000 characters frequently used in Chinese media and newspapers (",{"type":37,"tag":52,"props":2305,"children":2308},{"href":2306,"rel":2307},"https://en.wikipedia.org/wiki/Chinese_language#Vocabulary",[56],[2309],{"type":43,"value":2310},"source",{"type":43,"value":2312},"). ",{"type":37,"tag":52,"props":2314,"children":2317},{"href":2315,"rel":2316},"https://stackoverflow.com/a/1366113/6084948",[56],[2318],{"type":43,"value":2319},"This answer",{"type":43,"value":2321}," from StackOverflow's legendary #1 ranked user VonC gives a good answer based on the number of Unicode characters in the CJK Unified Ideographs block: 20,992.",{"type":37,"tag":46,"props":2323,"children":2324},{},[2325],{"type":43,"value":2326},"Here are some numbers and statistics to be better understand the text of the Three-Body Problem Chinese text:",{"type":37,"tag":640,"props":2328,"children":2329},{},[2330,2335,2340,2345,2350,2355],{"type":37,"tag":644,"props":2331,"children":2332},{},[2333],{"type":43,"value":2334},"188,380 total charactes in the book",{"type":37,"tag":644,"props":2336,"children":2337},{},[2338],{"type":43,"value":2339},"2,859 unique characters in the book",{"type":37,"tag":644,"props":2341,"children":2342},{},[2343],{"type":43,"value":2344},"36 chapters in the book",{"type":37,"tag":644,"props":2346,"children":2347},{},[2348],{"type":43,"value":2349},"average of 69.78 paragraphs per chapter",{"type":37,"tag":644,"props":2351,"children":2352},{},[2353],{"type":43,"value":2354},"total of 2,512 paragraphs in the book",{"type":37,"tag":644,"props":2356,"children":2357},{},[2358],{"type":43,"value":2359},"average of 74.99 characters per paragraph",{"type":37,"tag":698,"props":2361,"children":2363},{"id":2362},"character-frequency",[2364],{"type":43,"value":2365},"Character Frequency",{"type":37,"tag":46,"props":2367,"children":2368},{},[2369,2371,2378],{"type":43,"value":2370},"Let's look at how frequently each character in the book is used. We can also combine this with some data on the overall frequency of Chinese characters. The best measurement I found for overall character frequency is from ",{"type":37,"tag":52,"props":2372,"children":2375},{"href":2373,"rel":2374},"https://lingua.mtsu.edu/chinese-computing/statistics/char/list.php?Which=MO",[56],[2376],{"type":43,"value":2377},"Middle Tennessee State University",{"type":43,"value":2379},". Here's a visualization that shows of all of unique characters in the book. The height of a column represents how frequently a character occurs in the book, and the color represents the relatively frequency of the character in Chinese language overall.",{"type":37,"tag":2381,"props":2382,"children":2385},"div",{"className":2383},[2384],"wrap",[2386],{"type":37,"tag":2274,"props":2387,"children":2392},{"className":2388,"src":2390,"width":2276,"height":2391},[2389],"p-4","https://briancaffey.github.io/three-body-problem/tjs/load.html",550,[],{"type":37,"tag":38,"props":2394,"children":2396},{"id":2395},"meta-llms-and-grass-mud-horse",[2397],{"type":43,"value":2398},"Meta, LLMs, and Grass Mud Horse",{"type":37,"tag":46,"props":2400,"children":2401},{},[2402,2404,2411],{"type":43,"value":2403},"In recent months I have been following the development of big open source AI projects. Two projects in particular are InvokeAI, an image generation tool based on Stable Diffusion, and ",{"type":37,"tag":52,"props":2405,"children":2408},{"href":2406,"rel":2407},"https://ai.meta.com/llama/",[56],[2409],{"type":43,"value":2410},"LLaMA 2",{"type":43,"value":2412},", the latest generation of Meta's open source LLM. The name LLaMA stands for 'Large Language Model Meta AI', which happens to be the same spelling as the word for the domesticated South American camelid: llama. Before going deeper into LLMs we need a quick Chinese lesson.",{"type":37,"tag":46,"props":2414,"children":2415},{},[2416],{"type":43,"value":2417},"ËçâÊ≥•È©¨ is a non-technical word that referes to animals like Llama or Alpaca. It can be directly translated as \"Grass Mud Horse\" and it is phonetically similar to the most common Chinese profanity: Êìç‰Ω†Â¶à, which literally means \"f*** your mother\". The characters in these two words are nearly synonymous: the sounds of both words are \"cao ni ma\", but the tones are different, which in Chinese changes the meaning completely. The llama is basically a legendary Chinese internet meme subversive in the face of government censorship. ü¶ô was approved as part of Unicode 11.0 in 2018. The extended version of this profanity is ËçâÊ≥•È©¨ÊààÂ£Å (C«éon√≠m«é Gƒìb√¨: Grass Mud Horse Gobi), refering to the geographical origin of this mythical creature: the Gobi Dessert. This term is more explicit as it synonymous with \"f*** your mother's c***\". Coincidentally, the Gobi Desert is a region of Inner Mongolia which borders the mountainous region of Greater Khingan Range (Â§ßÂÖ¥ÂÆâÂ≤≠), the location of Red Coast and Radar Peak in Three-Body Problem where Ye Wenjie makes first contact with the Trisolarians.",{"type":37,"tag":46,"props":2419,"children":2420},{},[2421,2423,2434,2436,2443],{"type":43,"value":2422},"I requested access to Meta's LLaMa 2 models as soon as they came out and I was able to get it to run on my NVIDIA RTX 4090 GPU. I also joined a subreddit called ",{"type":37,"tag":52,"props":2424,"children":2427},{"href":2425,"rel":2426},"https://www.reddit.com/r/LocalLLaMA/",[56],[2428],{"type":37,"tag":160,"props":2429,"children":2431},{"className":2430},[],[2432],{"type":43,"value":2433},"r/LocalLLaMa",{"type":43,"value":2435}," with over seventy thousand members discussing how to run large language models on consumer hardware. Another annoucement that caught my attention in July was the release of ",{"type":37,"tag":52,"props":2437,"children":2440},{"href":2438,"rel":2439},"https://github.com/ymcui/Chinese-LLaMA-Alpaca-2",[56],[2441],{"type":43,"value":2442},"Chinese LLaMa 2",{"type":43,"value":2444},", an open-source large language model trained on Chinese and English which does very well against Chinese Language LLM Benchmarks such as the CMMCU: Chinese Massive Multitask Language Understanding.",{"type":37,"tag":46,"props":2446,"children":2447},{},[2448],{"type":37,"tag":172,"props":2449,"children":2452},{"alt":2450,"src":2451},"image of CMMLU","/static/three-body-problem/cmmlu.jpeg",[],{"type":37,"tag":38,"props":2454,"children":2456},{"id":2455},"translation-in-and-of-the-three-body-problem",[2457],{"type":43,"value":2458},"Translation in and of The Three-Body Problem",{"type":37,"tag":46,"props":2460,"children":2461},{},[2462],{"type":43,"value":2463},"There are two important plot developments related to language translation in the Three-Body Problem novel, both of which involve book‚Äôs main female protagonist Ye Wenjie. First, copying the translation of Rachel Carson's 'Silent Spring' leads to her being relegated to the Red Coast project. At the Red Coast Ye Wenjie communicates with extraterrestrial life through a universal translation technology developed by the top-secret project.",{"type":37,"tag":46,"props":2465,"children":2466},{},[2467],{"type":43,"value":2468},"Ken Liu‚Äôs translation of the Three-Body Problem book from Chinese to English places the events during the Cultural Revolution at the beginning of the book rather than in the middle of the book. According to Liu, this was done in order to avoid attention of government censors, and his original intention was to tell the story in this way, starting with the events of the late 1960's in China.",{"type":37,"tag":46,"props":2470,"children":2471},{},[2472],{"type":43,"value":2473},"I tried translating the Chinese text of the Three-Body Problem book using LLMs. I started with the Chinese-LLaMA-2 model and then tried Qwen-7B-Chat, Baichuan-13B-Chat when these models came out. I found that the Qwen-7B-Chat model worked best for my translation tasks. Qwen is short for Qian Wen (ÂçÉÈóÆ, or \"one thousand questions\") and is developed by Alibaba Cloud.",{"type":37,"tag":46,"props":2475,"children":2476},{},[2477],{"type":43,"value":2478},"How do you get an LLM to translate text? Ultimately the quality of the translation returned by the LLM depends on the prompt and other parameters used for inference. I experimented with both chat and completion approaches and tried lots of different kinds of prompts. The models I worked with have a 4K context window (the number of tokens the model can take as input when generating responses), so for translation tasks I had the LLM work on one paragraph at a time. Here's the prompt I used with the Qwen-7B-Chat model:",{"type":37,"tag":212,"props":2480,"children":2482},{"code":2481},"\"‰Ω†ÊòØ‰∏ÄÂêçÁøªËØë„ÄÇËØ∑Â∞ÜÊØèÊù°Ê∂àÊÅØ‰ªé‰∏≠ÊñáÁøªËØëÊàêËã±Êñá„ÄÇ\"\n(You are a translator. Please translate each message from Chinese to English.)\n",[2483],{"type":37,"tag":160,"props":2484,"children":2485},{"__ignoreMap":8},[2486],{"type":43,"value":2481},{"type":37,"tag":46,"props":2488,"children":2489},{},[2490],{"type":43,"value":2491},"I did some basic prompt engineering to get the LLM to translate the books in the Three-Body problem paragraph by paragraph. My computer was able to translate the first book overnight in under 500 minutes. Here are the results of my translation of Three-Body Problem with Qwen-7B-Chat model:",{"type":37,"tag":2274,"props":2493,"children":2496},{"className":2494,"src":2495,"width":2276,"height":2391},[2389],"https://briancaffey.github.io/three-body-problem/reader/?book=three_body&chapterNumber=1",[],{"type":37,"tag":46,"props":2498,"children":2499},{},[2500],{"type":43,"value":2501},"It was interesting to see the failure modes of translation tasks for the different models. Most of the time the LLM was able to provided accurate translations. Some of the failure modes I observed were:",{"type":37,"tag":640,"props":2503,"children":2504},{},[2505,2510,2515,2520],{"type":37,"tag":644,"props":2506,"children":2507},{},[2508],{"type":43,"value":2509},"a few Chinese characters would show up in the English translations",{"type":37,"tag":644,"props":2511,"children":2512},{},[2513],{"type":43,"value":2514},"a complete Chinese sentence would show up in an otherwise complete translation of a paragraph",{"type":37,"tag":644,"props":2516,"children":2517},{},[2518],{"type":43,"value":2519},"The LLM refused to translate certain paragraphs that included violent imagery, such as the violent scenes from the Cultural Revolution chapters",{"type":37,"tag":644,"props":2521,"children":2522},{},[2523],{"type":43,"value":2524},"If the sentence it was asked to translate was a question, the LLM would respond in Chinese to the question rather than providing a translation of the question itself",{"type":37,"tag":698,"props":2526,"children":2528},{"id":2527},"tokenization",[2529],{"type":43,"value":2530},"Tokenization",{"type":37,"tag":46,"props":2532,"children":2533},{},[2534],{"type":43,"value":2535},"When you feed a prompt to an LLM, it first puts the prompt through a process called tokenization. Tokenization takes a string of text and breaks it down into tokens (defined by the Large Language Model you are using). The process of tokenization is similar to the tokenization done by spaCy mentioned earlier. These tokens produced by LLM tokenization are numbers. Here's an example of tokenization in action using the Chinese-Llama-2 model:",{"type":37,"tag":212,"props":2537,"children":2539},{"code":2538,"language":751,"meta":8,"className":752,"style":8},"import json\nimport os\nfrom llama_cpp import Llama, LlamaTokenizer\n\nllm = Llama(\n    model_path=\"/path/to/models/ggml-model-q4_0.bin\",\n    n_ctx=4096,\n    n_gpu_layers=30\n)\n\ntokenizer = LlamaTokenizer(llama=llm)\n\nTEXT=\"Âú®ÈÇ£‰∏™Â∑≤Ë¢´ÂøòÂç¥ÁöÑÊó•Â≠êÈáåÔºåÂÆÉÁöÑ‰∏ñÁïåÈ¢†Ë¶Ü‰∫Ü„ÄÇÊ≥•ÂúüÈ£ûËµ∞ÔºåÂá∫Áé∞‰∫Ü‰∏ÄÊù°ÂèàÊ∑±ÂèàÂÆΩÁöÑÂ≥°Ë∞∑ÔºåÁÑ∂ÂêéÊ≥•ÂúüÂèàËΩ∞ÈöÜÈöÜÂú∞È£ûÂõûÊù•ÔºåÂ≥°Ë∞∑Ê∂àÂ§±‰∫ÜÔºåÂú®ÂéüÊù•Â≥°Ë∞∑ÁöÑÂ∞ΩÂ§¥Âá∫Áé∞‰∫Ü‰∏ÄÂ∫ßÈªëËâ≤ÁöÑÂ≠§Â≥∞„ÄÇÂÖ∂ÂÆûÔºåÂú®ËøôÁâáÂπøÈòîÁöÑÁñÜÂüü‰∏äÔºåËøôÁßç‰∫ãÂ∏∏Â∏∏ÂèëÁîüÔºåÊ≥•ÂúüÈ£ûËµ∞ÂèàÈ£ûÂõûÔºåÂ≥°Ë∞∑Âá∫Áé∞ÂèàÊ∂àÂ§±ÔºåÁÑ∂ÂêéÊòØÂ≠§Â≥∞Èôç‰∏¥ÔºåÂ•ΩÂÉèÊòØÁªôÊØèÊ¨°ÁÅæÂèòÊâì‰∏ä‰∏Ä‰∏™ÈÜíÁõÆÁöÑÊ†áËÆ∞„ÄÇË§êËöÅÂíåÂá†Áôæ‰∏™ÂêåÊóèÂ∏¶ÁùÄÂπ∏Â≠òÁöÑËöÅÂêéÂêëÂ§™Èò≥ËêΩ‰∏ãÁöÑÊñπÂêëËµ∞‰∫Ü‰∏ÄÊÆµË∑ØÔºåÂª∫Á´ã‰∫ÜÊñ∞ÁöÑÂ∏ùÂõΩ„ÄÇ\"\ntokens = tokenizer.encode(TEXT)\n",[2540],{"type":37,"tag":160,"props":2541,"children":2542},{"__ignoreMap":8},[2543,2556,2568,2590,2598,2615,2637,2658,2675,2682,2689,2719,2726,2744],{"type":37,"tag":758,"props":2544,"children":2545},{"class":760,"line":761},[2546,2551],{"type":37,"tag":758,"props":2547,"children":2548},{"style":835},[2549],{"type":43,"value":2550},"import",{"type":37,"tag":758,"props":2552,"children":2553},{"style":777},[2554],{"type":43,"value":2555}," json\n",{"type":37,"tag":758,"props":2557,"children":2558},{"class":760,"line":502},[2559,2563],{"type":37,"tag":758,"props":2560,"children":2561},{"style":835},[2562],{"type":43,"value":2550},{"type":37,"tag":758,"props":2564,"children":2565},{"style":777},[2566],{"type":43,"value":2567}," os\n",{"type":37,"tag":758,"props":2569,"children":2570},{"class":760,"line":803},[2571,2576,2581,2585],{"type":37,"tag":758,"props":2572,"children":2573},{"style":835},[2574],{"type":43,"value":2575},"from",{"type":37,"tag":758,"props":2577,"children":2578},{"style":777},[2579],{"type":43,"value":2580}," llama_cpp ",{"type":37,"tag":758,"props":2582,"children":2583},{"style":835},[2584],{"type":43,"value":2550},{"type":37,"tag":758,"props":2586,"children":2587},{"style":777},[2588],{"type":43,"value":2589}," Llama, LlamaTokenizer\n",{"type":37,"tag":758,"props":2591,"children":2592},{"class":760,"line":812},[2593],{"type":37,"tag":758,"props":2594,"children":2595},{"emptyLinePlaceholder":32},[2596],{"type":43,"value":2597},"\n",{"type":37,"tag":758,"props":2599,"children":2600},{"class":760,"line":820},[2601,2606,2610],{"type":37,"tag":758,"props":2602,"children":2603},{"style":777},[2604],{"type":43,"value":2605},"llm ",{"type":37,"tag":758,"props":2607,"children":2608},{"style":835},[2609],{"type":43,"value":854},{"type":37,"tag":758,"props":2611,"children":2612},{"style":777},[2613],{"type":43,"value":2614}," Llama(\n",{"type":37,"tag":758,"props":2616,"children":2617},{"class":760,"line":867},[2618,2623,2627,2632],{"type":37,"tag":758,"props":2619,"children":2620},{"style":846},[2621],{"type":43,"value":2622},"    model_path",{"type":37,"tag":758,"props":2624,"children":2625},{"style":835},[2626],{"type":43,"value":854},{"type":37,"tag":758,"props":2628,"children":2629},{"style":797},[2630],{"type":43,"value":2631},"\"/path/to/models/ggml-model-q4_0.bin\"",{"type":37,"tag":758,"props":2633,"children":2634},{"style":777},[2635],{"type":43,"value":2636},",\n",{"type":37,"tag":758,"props":2638,"children":2639},{"class":760,"line":905},[2640,2645,2649,2654],{"type":37,"tag":758,"props":2641,"children":2642},{"style":846},[2643],{"type":43,"value":2644},"    n_ctx",{"type":37,"tag":758,"props":2646,"children":2647},{"style":835},[2648],{"type":43,"value":854},{"type":37,"tag":758,"props":2650,"children":2651},{"style":1296},[2652],{"type":43,"value":2653},"4096",{"type":37,"tag":758,"props":2655,"children":2656},{"style":777},[2657],{"type":43,"value":2636},{"type":37,"tag":758,"props":2659,"children":2660},{"class":760,"line":943},[2661,2666,2670],{"type":37,"tag":758,"props":2662,"children":2663},{"style":846},[2664],{"type":43,"value":2665},"    n_gpu_layers",{"type":37,"tag":758,"props":2667,"children":2668},{"style":835},[2669],{"type":43,"value":854},{"type":37,"tag":758,"props":2671,"children":2672},{"style":1296},[2673],{"type":43,"value":2674},"30\n",{"type":37,"tag":758,"props":2676,"children":2677},{"class":760,"line":981},[2678],{"type":37,"tag":758,"props":2679,"children":2680},{"style":777},[2681],{"type":43,"value":864},{"type":37,"tag":758,"props":2683,"children":2684},{"class":760,"line":1019},[2685],{"type":37,"tag":758,"props":2686,"children":2687},{"emptyLinePlaceholder":32},[2688],{"type":43,"value":2597},{"type":37,"tag":758,"props":2690,"children":2691},{"class":760,"line":1057},[2692,2697,2701,2706,2710,2714],{"type":37,"tag":758,"props":2693,"children":2694},{"style":777},[2695],{"type":43,"value":2696},"tokenizer ",{"type":37,"tag":758,"props":2698,"children":2699},{"style":835},[2700],{"type":43,"value":854},{"type":37,"tag":758,"props":2702,"children":2703},{"style":777},[2704],{"type":43,"value":2705}," LlamaTokenizer(",{"type":37,"tag":758,"props":2707,"children":2708},{"style":846},[2709],{"type":43,"value":23},{"type":37,"tag":758,"props":2711,"children":2712},{"style":835},[2713],{"type":43,"value":854},{"type":37,"tag":758,"props":2715,"children":2716},{"style":777},[2717],{"type":43,"value":2718},"llm)\n",{"type":37,"tag":758,"props":2720,"children":2721},{"class":760,"line":1095},[2722],{"type":37,"tag":758,"props":2723,"children":2724},{"emptyLinePlaceholder":32},[2725],{"type":43,"value":2597},{"type":37,"tag":758,"props":2727,"children":2729},{"class":760,"line":2728},13,[2730,2735,2739],{"type":37,"tag":758,"props":2731,"children":2732},{"style":1296},[2733],{"type":43,"value":2734},"TEXT",{"type":37,"tag":758,"props":2736,"children":2737},{"style":835},[2738],{"type":43,"value":854},{"type":37,"tag":758,"props":2740,"children":2741},{"style":797},[2742],{"type":43,"value":2743},"\"Âú®ÈÇ£‰∏™Â∑≤Ë¢´ÂøòÂç¥ÁöÑÊó•Â≠êÈáåÔºåÂÆÉÁöÑ‰∏ñÁïåÈ¢†Ë¶Ü‰∫Ü„ÄÇÊ≥•ÂúüÈ£ûËµ∞ÔºåÂá∫Áé∞‰∫Ü‰∏ÄÊù°ÂèàÊ∑±ÂèàÂÆΩÁöÑÂ≥°Ë∞∑ÔºåÁÑ∂ÂêéÊ≥•ÂúüÂèàËΩ∞ÈöÜÈöÜÂú∞È£ûÂõûÊù•ÔºåÂ≥°Ë∞∑Ê∂àÂ§±‰∫ÜÔºåÂú®ÂéüÊù•Â≥°Ë∞∑ÁöÑÂ∞ΩÂ§¥Âá∫Áé∞‰∫Ü‰∏ÄÂ∫ßÈªëËâ≤ÁöÑÂ≠§Â≥∞„ÄÇÂÖ∂ÂÆûÔºåÂú®ËøôÁâáÂπøÈòîÁöÑÁñÜÂüü‰∏äÔºåËøôÁßç‰∫ãÂ∏∏Â∏∏ÂèëÁîüÔºåÊ≥•ÂúüÈ£ûËµ∞ÂèàÈ£ûÂõûÔºåÂ≥°Ë∞∑Âá∫Áé∞ÂèàÊ∂àÂ§±ÔºåÁÑ∂ÂêéÊòØÂ≠§Â≥∞Èôç‰∏¥ÔºåÂ•ΩÂÉèÊòØÁªôÊØèÊ¨°ÁÅæÂèòÊâì‰∏ä‰∏Ä‰∏™ÈÜíÁõÆÁöÑÊ†áËÆ∞„ÄÇË§êËöÅÂíåÂá†Áôæ‰∏™ÂêåÊóèÂ∏¶ÁùÄÂπ∏Â≠òÁöÑËöÅÂêéÂêëÂ§™Èò≥ËêΩ‰∏ãÁöÑÊñπÂêëËµ∞‰∫Ü‰∏ÄÊÆµË∑ØÔºåÂª∫Á´ã‰∫ÜÊñ∞ÁöÑÂ∏ùÂõΩ„ÄÇ\"\n",{"type":37,"tag":758,"props":2745,"children":2747},{"class":760,"line":2746},14,[2748,2753,2757,2762,2766],{"type":37,"tag":758,"props":2749,"children":2750},{"style":777},[2751],{"type":43,"value":2752},"tokens ",{"type":37,"tag":758,"props":2754,"children":2755},{"style":835},[2756],{"type":43,"value":854},{"type":37,"tag":758,"props":2758,"children":2759},{"style":777},[2760],{"type":43,"value":2761}," tokenizer.encode(",{"type":37,"tag":758,"props":2763,"children":2764},{"style":1296},[2765],{"type":43,"value":2734},{"type":37,"tag":758,"props":2767,"children":2768},{"style":777},[2769],{"type":43,"value":864},{"type":37,"tag":212,"props":2771,"children":2773},{"code":2772},"print(str(tokens[:4]) + \" ...\")\n",[2774],{"type":37,"tag":160,"props":2775,"children":2776},{"__ignoreMap":8},[2777],{"type":43,"value":2772},{"type":37,"tag":68,"props":2779,"children":2780},{},[2781],{"type":37,"tag":46,"props":2782,"children":2783},{},[2784,2789],{"type":37,"tag":758,"props":2785,"children":2786},{},[2787],{"type":43,"value":2788},"1, 30505, 32380, 36812",{"type":43,"value":2790}," ...",{"type":37,"tag":212,"props":2792,"children":2794},{"code":2793},"for token in tokens:\n    text = tokenizer.decode([token])\n    print(text, end=\" \")\n",[2795],{"type":37,"tag":160,"props":2796,"children":2797},{"__ignoreMap":8},[2798],{"type":43,"value":2793},{"type":37,"tag":68,"props":2800,"children":2801},{},[2802],{"type":37,"tag":46,"props":2803,"children":2804},{},[2805],{"type":43,"value":2806},"Âú® ÈÇ£‰∏™ Â∑≤Ë¢´ Âøò Âç¥ ÁöÑÊó•Â≠ê Èáå Ôºå ÂÆÉÁöÑ ‰∏ñÁïå È¢†Ë¶Ü ‰∫Ü „ÄÇ Ê≥• Âúü È£û Ëµ∞ Ôºå Âá∫Áé∞‰∫Ü ‰∏ÄÊù° Âèà Ê∑± Âèà ÂÆΩ ÁöÑ Â≥°Ë∞∑ Ôºå ÁÑ∂Âêé Ê≥• Âúü Âèà ËΩ∞ ÈöÜ ÈöÜ Âú∞ È£û ÂõûÊù• Ôºå Â≥°Ë∞∑ Ê∂àÂ§± ‰∫Ü Ôºå Âú® ÂéüÊù• Â≥°Ë∞∑ ÁöÑ Â∞ΩÂ§¥ Âá∫Áé∞‰∫Ü ‰∏ÄÂ∫ß ÈªëËâ≤ ÁöÑ Â≠§ Â≥∞ „ÄÇ ÂÖ∂ÂÆû Ôºå Âú®Ëøô Áâá ÂπøÈòî ÁöÑ ÁñÜ Âüü ‰∏ä Ôºå ËøôÁßç‰∫ã Â∏∏Â∏∏ ÂèëÁîü Ôºå Ê≥• Âúü È£û Ëµ∞ Âèà È£û Âõû Ôºå Â≥°Ë∞∑ Âá∫Áé∞ Âèà Ê∂àÂ§± Ôºå ÁÑ∂Âêé ÊòØ Â≠§ Â≥∞ Èôç‰∏¥ Ôºå Â•ΩÂÉèÊòØ Áªô ÊØèÊ¨° ÁÅæ Âèò Êâì ‰∏ä ‰∏Ä‰∏™ ÈÜíÁõÆ ÁöÑ Ê†áËÆ∞ „ÄÇ Ë§ê ËöÅ Âíå Âá†Áôæ ‰∏™ Âêå Êóè Â∏¶ÁùÄ Âπ∏ Â≠ò ÁöÑ ËöÅ Âêé Âêë Â§™Èò≥ ËêΩ ‰∏ãÁöÑ ÊñπÂêë Ëµ∞‰∫Ü ‰∏ÄÊÆµ Ë∑Ø Ôºå Âª∫Á´ã‰∫Ü Êñ∞ÁöÑ Â∏ùÂõΩ „ÄÇ",{"type":37,"tag":212,"props":2808,"children":2810},{"code":2809,"language":751,"meta":8,"className":752,"style":8},"english_text = \"This is an example of tokenization using a large language model.\"\nenglish_tokens = tokenizer.encode(english_text)\nprint(str(english_tokens[:4]) + \" ...\")\n\nfor token in english_tokens:\n    text = tokenizer.decode([token])\n    print(f\"'{text}'\", end=\" \")\n",[2811],{"type":37,"tag":160,"props":2812,"children":2813},{"__ignoreMap":8},[2814,2831,2848,2894,2901,2924,2941],{"type":37,"tag":758,"props":2815,"children":2816},{"class":760,"line":761},[2817,2822,2826],{"type":37,"tag":758,"props":2818,"children":2819},{"style":777},[2820],{"type":43,"value":2821},"english_text ",{"type":37,"tag":758,"props":2823,"children":2824},{"style":835},[2825],{"type":43,"value":854},{"type":37,"tag":758,"props":2827,"children":2828},{"style":797},[2829],{"type":43,"value":2830}," \"This is an example of tokenization using a large language model.\"\n",{"type":37,"tag":758,"props":2832,"children":2833},{"class":760,"line":502},[2834,2839,2843],{"type":37,"tag":758,"props":2835,"children":2836},{"style":777},[2837],{"type":43,"value":2838},"english_tokens ",{"type":37,"tag":758,"props":2840,"children":2841},{"style":835},[2842],{"type":43,"value":854},{"type":37,"tag":758,"props":2844,"children":2845},{"style":777},[2846],{"type":43,"value":2847}," tokenizer.encode(english_text)\n",{"type":37,"tag":758,"props":2849,"children":2850},{"class":760,"line":803},[2851,2857,2861,2865,2870,2875,2880,2885,2890],{"type":37,"tag":758,"props":2852,"children":2854},{"style":2853},"--shiki-default:#005CC5;--shiki-dark:#79B8FF;--shiki-sepia:#66D9EF",[2855],{"type":43,"value":2856},"print",{"type":37,"tag":758,"props":2858,"children":2859},{"style":777},[2860],{"type":43,"value":780},{"type":37,"tag":758,"props":2862,"children":2863},{"style":829},[2864],{"type":43,"value":832},{"type":37,"tag":758,"props":2866,"children":2867},{"style":777},[2868],{"type":43,"value":2869},"(english_tokens[:",{"type":37,"tag":758,"props":2871,"children":2872},{"style":1296},[2873],{"type":43,"value":2874},"4",{"type":37,"tag":758,"props":2876,"children":2877},{"style":777},[2878],{"type":43,"value":2879},"]) ",{"type":37,"tag":758,"props":2881,"children":2882},{"style":835},[2883],{"type":43,"value":2884},"+",{"type":37,"tag":758,"props":2886,"children":2887},{"style":797},[2888],{"type":43,"value":2889}," \" ...\"",{"type":37,"tag":758,"props":2891,"children":2892},{"style":777},[2893],{"type":43,"value":864},{"type":37,"tag":758,"props":2895,"children":2896},{"class":760,"line":812},[2897],{"type":37,"tag":758,"props":2898,"children":2899},{"emptyLinePlaceholder":32},[2900],{"type":43,"value":2597},{"type":37,"tag":758,"props":2902,"children":2903},{"class":760,"line":820},[2904,2909,2914,2919],{"type":37,"tag":758,"props":2905,"children":2906},{"style":835},[2907],{"type":43,"value":2908},"for",{"type":37,"tag":758,"props":2910,"children":2911},{"style":777},[2912],{"type":43,"value":2913}," token ",{"type":37,"tag":758,"props":2915,"children":2916},{"style":835},[2917],{"type":43,"value":2918},"in",{"type":37,"tag":758,"props":2920,"children":2921},{"style":777},[2922],{"type":43,"value":2923}," english_tokens:\n",{"type":37,"tag":758,"props":2925,"children":2926},{"class":760,"line":867},[2927,2932,2936],{"type":37,"tag":758,"props":2928,"children":2929},{"style":777},[2930],{"type":43,"value":2931},"    text ",{"type":37,"tag":758,"props":2933,"children":2934},{"style":835},[2935],{"type":43,"value":854},{"type":37,"tag":758,"props":2937,"children":2938},{"style":777},[2939],{"type":43,"value":2940}," tokenizer.decode([token])\n",{"type":37,"tag":758,"props":2942,"children":2943},{"class":760,"line":905},[2944,2949,2953,2958,2963,2968,2972,2977,2982,2987,2992,2996,3001],{"type":37,"tag":758,"props":2945,"children":2946},{"style":2853},[2947],{"type":43,"value":2948},"    print",{"type":37,"tag":758,"props":2950,"children":2951},{"style":777},[2952],{"type":43,"value":780},{"type":37,"tag":758,"props":2954,"children":2955},{"style":765},[2956],{"type":43,"value":2957},"f",{"type":37,"tag":758,"props":2959,"children":2960},{"style":797},[2961],{"type":43,"value":2962},"\"'",{"type":37,"tag":758,"props":2964,"children":2965},{"style":1296},[2966],{"type":43,"value":2967},"{",{"type":37,"tag":758,"props":2969,"children":2970},{"style":777},[2971],{"type":43,"value":43},{"type":37,"tag":758,"props":2973,"children":2974},{"style":1296},[2975],{"type":43,"value":2976},"}",{"type":37,"tag":758,"props":2978,"children":2979},{"style":797},[2980],{"type":43,"value":2981},"'\"",{"type":37,"tag":758,"props":2983,"children":2984},{"style":777},[2985],{"type":43,"value":2986},", ",{"type":37,"tag":758,"props":2988,"children":2989},{"style":846},[2990],{"type":43,"value":2991},"end",{"type":37,"tag":758,"props":2993,"children":2994},{"style":835},[2995],{"type":43,"value":854},{"type":37,"tag":758,"props":2997,"children":2998},{"style":797},[2999],{"type":43,"value":3000},"\" \"",{"type":37,"tag":758,"props":3002,"children":3003},{"style":777},[3004],{"type":43,"value":864},{"type":37,"tag":68,"props":3006,"children":3007},{},[3008],{"type":37,"tag":46,"props":3009,"children":3010},{},[3011,3016],{"type":37,"tag":758,"props":3012,"children":3013},{},[3014],{"type":43,"value":3015},"1, 4013, 338, 385",{"type":43,"value":2790},{"type":37,"tag":68,"props":3018,"children":3019},{},[3020],{"type":37,"tag":46,"props":3021,"children":3022},{},[3023],{"type":43,"value":3024},"'' 'This' ' is' ' an' ' example' ' of' ' token' 'ization' ' using' ' a' ' large' ' language' ' model' '.'",{"type":37,"tag":46,"props":3026,"children":3027},{},[3028],{"type":43,"value":3029},"Here are some key differences between English and Chinese that have implications for how the language is tokenized by large language models:",{"type":37,"tag":640,"props":3031,"children":3032},{},[3033,3038,3043,3048,3053,3058,3063],{"type":37,"tag":644,"props":3034,"children":3035},{},[3036],{"type":43,"value":3037},"Chinese does not use spaces between words like English does",{"type":37,"tag":644,"props":3039,"children":3040},{},[3041],{"type":43,"value":3042},"Chinese words are typically formed from 2 or more characters",{"type":37,"tag":644,"props":3044,"children":3045},{},[3046],{"type":43,"value":3047},"Chinese verbs are not conjugated and do not have different tenses",{"type":37,"tag":644,"props":3049,"children":3050},{},[3051],{"type":43,"value":3052},"Chinese words don't have singular and plural variants",{"type":37,"tag":644,"props":3054,"children":3055},{},[3056],{"type":43,"value":3057},"Chinese grammar is very simple and is similar to English",{"type":37,"tag":644,"props":3059,"children":3060},{},[3061],{"type":43,"value":3062},"Chinese characters do not have capitization like ASCII characters",{"type":37,"tag":644,"props":3064,"children":3065},{},[3066],{"type":43,"value":3067},"The token represented by the number 1 encodes a starting token",{"type":37,"tag":38,"props":3069,"children":3071},{"id":3070},"imagining-scenes-from-three-body-problem-with-stable-diffusion",[3072],{"type":43,"value":3073},"Imagining scenes from Three-Body Problem with Stable Diffusion",{"type":37,"tag":46,"props":3075,"children":3076},{},[3077],{"type":43,"value":3078},"Here are some images I generated using Stable Diffusion with InvokeAI that depict scenes from the Three-Body Problem book. These scenes portray solutions to the Three-Body Problem that players in the Three-Body game devised. The first is a Confucian system of etiquette for predicting the movement of the three suns. The second is a human-powered computer that Qin Shi Huang used to try to predict the movement of the three suns.",{"type":37,"tag":68,"props":3080,"children":3081},{},[3082],{"type":37,"tag":46,"props":3083,"children":3084},{},[3085],{"type":43,"value":3086},"Prompt: Ceremonies and etiquette system related to the sun and multiple celestial++ bodies Confucius artistic style",{"type":37,"tag":3088,"props":3089,"children":3090},"client-only",{},[3091],{"type":37,"tag":3092,"props":3093,"children":3096},"carousel",{":count":3094,"dir":3095},"8","confucius",[],{"type":37,"tag":68,"props":3098,"children":3099},{},[3100],{"type":37,"tag":46,"props":3101,"children":3102},{},[3103],{"type":43,"value":3104},"array of chinese++ warriors++ on a electronics+ circuit+ board qing+ dynasty style art logic puzzle",{"type":37,"tag":3088,"props":3106,"children":3107},{},[3108],{"type":37,"tag":3092,"props":3109,"children":3112},{":count":3110,"dir":3111},"5","computer",[],{"type":37,"tag":46,"props":3114,"children":3115},{},[3116],{"type":43,"value":3117},"Congrats to the InvokeAI team on the 3.0 release. It has been awesome to use and the current docker compose setup is a huge improvement on the 2.x version.",{"type":37,"tag":38,"props":3119,"children":3121},{"id":3120},"n-body-simulations-cuda-and-threejs",[3122],{"type":43,"value":3123},"n-body simulations, CUDA and Three.js",{"type":37,"tag":46,"props":3125,"children":3126},{},[3127],{"type":43,"value":3128},"The nbody problem has no closed-form analytical solution, but it is possible to do a basic simulation of the three-body problem on consumer hardware and open source software, like NVIDIA and CUDA.",{"type":37,"tag":698,"props":3130,"children":3132},{"id":3131},"three-body-cuda-simulation",[3133],{"type":43,"value":3134},"Three-Body CUDA simulation",{"type":37,"tag":46,"props":3136,"children":3137},{},[3138],{"type":43,"value":3139},"I wrote a simple program with the help of ChatGPT for running nbody problem simulations. The program uses CuPy, a Python library that exposes APIs for doing matrix multiplication to predict the position of three bodies using Euclidian Integration. Here's the script:",{"type":37,"tag":212,"props":3141,"children":3145},{"code":3142,"language":3143,"meta":8,"className":3144,"style":8},"import numpy as np\nimport cupy as cp\nimport time\nimport json\n\n# Simulation parameters\nNUM_PARTICLES = 3\nDIMENSIONS = 3 # 3D space\nNUM_STEPS = 30\nDT = 0.1\n\n# Generate initial positions and velocities\nnp_positions = np.random.randn(NUM_PARTICLES, DIMENSIONS)\nnp_velocities = np.random.randn(NUM_PARTICLES, DIMENSIONS)\n\ncp_positions = cp.array(np_positions)\ncp_velocities = cp.array(np_velocities)\n\nnp_ticks = np.expand_dims(np_positions, axis=0)\ncp_ticks = cp.array(np_ticks)\n\n# nbody simulation loop\nstart_time = time.time()\nfor step in range(NUM_STEPS):\n\n    # this gets pairwise differences\n    diff = cp_positions[:, None, :] - cp_positions[None, :, :]\n    distances = cp.sqrt(cp.sum(diff**2, axis=2))\n\n    # avoid division by zero\n    epsilon = 1e-5\n    inv_distances = 1.0 / cp.maximum(distances, epsilon)\n\n    # calculate forces\n    cp_forces = cp.sum((diff.T * inv_distances**3).T, axis=1)\n\n    # update velocities and positions\n    cp_velocities += DT * cp_forces\n    cp_positions += DT * cp_velocities\n    cp_ticks = cp.append(cp_ticks, cp.expand_dims(cp_positions, 0), 0)\n\nsim_time = time.time() - start_time\nprint(\"Simulation time:\", sim_time)\n\n\nclass NumpyArrayEncoder(json.JSONEncoder):\n    def default(self, obj):\n        if isinstance(obj, np.ndarray):\n            return obj.tolist()\n        return json.JSONEncoder.default(self, obj)\n\n\nnp_ticks = cp_ticks.get()\n\n\n# this is data we can work with in python and write to a file\nwith open(\"ticks.json\", \"w\") as f:\n    f.write(json.dumps(np_ticks, cls=NumpyArrayEncoder))\n","py","language-py shiki shiki-themes github-light github-dark monokai",[3146],{"type":37,"tag":160,"props":3147,"children":3148},{"__ignoreMap":8},[3149,3171,3192,3204,3215,3222,3231,3248,3270,3287,3304,3311,3319,3352,3384,3392,3410,3428,3436,3471,3489,3497,3506,3524,3558,3566,3575,3622,3671,3679,3688,3706,3734,3742,3751,3810,3818,3827,3856,3882,3917,3925,3952,3974,3982,3990,4025,4062,4081,4095,4119,4127,4135,4152,4160,4168,4177,4223],{"type":37,"tag":758,"props":3150,"children":3151},{"class":760,"line":761},[3152,3156,3161,3166],{"type":37,"tag":758,"props":3153,"children":3154},{"style":835},[3155],{"type":43,"value":2550},{"type":37,"tag":758,"props":3157,"children":3158},{"style":777},[3159],{"type":43,"value":3160}," numpy ",{"type":37,"tag":758,"props":3162,"children":3163},{"style":835},[3164],{"type":43,"value":3165},"as",{"type":37,"tag":758,"props":3167,"children":3168},{"style":777},[3169],{"type":43,"value":3170}," np\n",{"type":37,"tag":758,"props":3172,"children":3173},{"class":760,"line":502},[3174,3178,3183,3187],{"type":37,"tag":758,"props":3175,"children":3176},{"style":835},[3177],{"type":43,"value":2550},{"type":37,"tag":758,"props":3179,"children":3180},{"style":777},[3181],{"type":43,"value":3182}," cupy ",{"type":37,"tag":758,"props":3184,"children":3185},{"style":835},[3186],{"type":43,"value":3165},{"type":37,"tag":758,"props":3188,"children":3189},{"style":777},[3190],{"type":43,"value":3191}," cp\n",{"type":37,"tag":758,"props":3193,"children":3194},{"class":760,"line":803},[3195,3199],{"type":37,"tag":758,"props":3196,"children":3197},{"style":835},[3198],{"type":43,"value":2550},{"type":37,"tag":758,"props":3200,"children":3201},{"style":777},[3202],{"type":43,"value":3203}," time\n",{"type":37,"tag":758,"props":3205,"children":3206},{"class":760,"line":812},[3207,3211],{"type":37,"tag":758,"props":3208,"children":3209},{"style":835},[3210],{"type":43,"value":2550},{"type":37,"tag":758,"props":3212,"children":3213},{"style":777},[3214],{"type":43,"value":2555},{"type":37,"tag":758,"props":3216,"children":3217},{"class":760,"line":820},[3218],{"type":37,"tag":758,"props":3219,"children":3220},{"emptyLinePlaceholder":32},[3221],{"type":43,"value":2597},{"type":37,"tag":758,"props":3223,"children":3224},{"class":760,"line":867},[3225],{"type":37,"tag":758,"props":3226,"children":3228},{"style":3227},"--shiki-default:#6A737D;--shiki-dark:#6A737D;--shiki-sepia:#88846F",[3229],{"type":43,"value":3230},"# Simulation parameters\n",{"type":37,"tag":758,"props":3232,"children":3233},{"class":760,"line":905},[3234,3239,3243],{"type":37,"tag":758,"props":3235,"children":3236},{"style":1296},[3237],{"type":43,"value":3238},"NUM_PARTICLES",{"type":37,"tag":758,"props":3240,"children":3241},{"style":835},[3242],{"type":43,"value":838},{"type":37,"tag":758,"props":3244,"children":3245},{"style":1296},[3246],{"type":43,"value":3247}," 3\n",{"type":37,"tag":758,"props":3249,"children":3250},{"class":760,"line":943},[3251,3256,3260,3265],{"type":37,"tag":758,"props":3252,"children":3253},{"style":1296},[3254],{"type":43,"value":3255},"DIMENSIONS",{"type":37,"tag":758,"props":3257,"children":3258},{"style":835},[3259],{"type":43,"value":838},{"type":37,"tag":758,"props":3261,"children":3262},{"style":1296},[3263],{"type":43,"value":3264}," 3",{"type":37,"tag":758,"props":3266,"children":3267},{"style":3227},[3268],{"type":43,"value":3269}," # 3D space\n",{"type":37,"tag":758,"props":3271,"children":3272},{"class":760,"line":981},[3273,3278,3282],{"type":37,"tag":758,"props":3274,"children":3275},{"style":1296},[3276],{"type":43,"value":3277},"NUM_STEPS",{"type":37,"tag":758,"props":3279,"children":3280},{"style":835},[3281],{"type":43,"value":838},{"type":37,"tag":758,"props":3283,"children":3284},{"style":1296},[3285],{"type":43,"value":3286}," 30\n",{"type":37,"tag":758,"props":3288,"children":3289},{"class":760,"line":1019},[3290,3295,3299],{"type":37,"tag":758,"props":3291,"children":3292},{"style":1296},[3293],{"type":43,"value":3294},"DT",{"type":37,"tag":758,"props":3296,"children":3297},{"style":835},[3298],{"type":43,"value":838},{"type":37,"tag":758,"props":3300,"children":3301},{"style":1296},[3302],{"type":43,"value":3303}," 0.1\n",{"type":37,"tag":758,"props":3305,"children":3306},{"class":760,"line":1057},[3307],{"type":37,"tag":758,"props":3308,"children":3309},{"emptyLinePlaceholder":32},[3310],{"type":43,"value":2597},{"type":37,"tag":758,"props":3312,"children":3313},{"class":760,"line":1095},[3314],{"type":37,"tag":758,"props":3315,"children":3316},{"style":3227},[3317],{"type":43,"value":3318},"# Generate initial positions and velocities\n",{"type":37,"tag":758,"props":3320,"children":3321},{"class":760,"line":2728},[3322,3327,3331,3336,3340,3344,3348],{"type":37,"tag":758,"props":3323,"children":3324},{"style":777},[3325],{"type":43,"value":3326},"np_positions ",{"type":37,"tag":758,"props":3328,"children":3329},{"style":835},[3330],{"type":43,"value":854},{"type":37,"tag":758,"props":3332,"children":3333},{"style":777},[3334],{"type":43,"value":3335}," np.random.randn(",{"type":37,"tag":758,"props":3337,"children":3338},{"style":1296},[3339],{"type":43,"value":3238},{"type":37,"tag":758,"props":3341,"children":3342},{"style":777},[3343],{"type":43,"value":2986},{"type":37,"tag":758,"props":3345,"children":3346},{"style":1296},[3347],{"type":43,"value":3255},{"type":37,"tag":758,"props":3349,"children":3350},{"style":777},[3351],{"type":43,"value":864},{"type":37,"tag":758,"props":3353,"children":3354},{"class":760,"line":2746},[3355,3360,3364,3368,3372,3376,3380],{"type":37,"tag":758,"props":3356,"children":3357},{"style":777},[3358],{"type":43,"value":3359},"np_velocities ",{"type":37,"tag":758,"props":3361,"children":3362},{"style":835},[3363],{"type":43,"value":854},{"type":37,"tag":758,"props":3365,"children":3366},{"style":777},[3367],{"type":43,"value":3335},{"type":37,"tag":758,"props":3369,"children":3370},{"style":1296},[3371],{"type":43,"value":3238},{"type":37,"tag":758,"props":3373,"children":3374},{"style":777},[3375],{"type":43,"value":2986},{"type":37,"tag":758,"props":3377,"children":3378},{"style":1296},[3379],{"type":43,"value":3255},{"type":37,"tag":758,"props":3381,"children":3382},{"style":777},[3383],{"type":43,"value":864},{"type":37,"tag":758,"props":3385,"children":3387},{"class":760,"line":3386},15,[3388],{"type":37,"tag":758,"props":3389,"children":3390},{"emptyLinePlaceholder":32},[3391],{"type":43,"value":2597},{"type":37,"tag":758,"props":3393,"children":3395},{"class":760,"line":3394},16,[3396,3401,3405],{"type":37,"tag":758,"props":3397,"children":3398},{"style":777},[3399],{"type":43,"value":3400},"cp_positions ",{"type":37,"tag":758,"props":3402,"children":3403},{"style":835},[3404],{"type":43,"value":854},{"type":37,"tag":758,"props":3406,"children":3407},{"style":777},[3408],{"type":43,"value":3409}," cp.array(np_positions)\n",{"type":37,"tag":758,"props":3411,"children":3413},{"class":760,"line":3412},17,[3414,3419,3423],{"type":37,"tag":758,"props":3415,"children":3416},{"style":777},[3417],{"type":43,"value":3418},"cp_velocities ",{"type":37,"tag":758,"props":3420,"children":3421},{"style":835},[3422],{"type":43,"value":854},{"type":37,"tag":758,"props":3424,"children":3425},{"style":777},[3426],{"type":43,"value":3427}," cp.array(np_velocities)\n",{"type":37,"tag":758,"props":3429,"children":3431},{"class":760,"line":3430},18,[3432],{"type":37,"tag":758,"props":3433,"children":3434},{"emptyLinePlaceholder":32},[3435],{"type":43,"value":2597},{"type":37,"tag":758,"props":3437,"children":3439},{"class":760,"line":3438},19,[3440,3445,3449,3454,3459,3463,3467],{"type":37,"tag":758,"props":3441,"children":3442},{"style":777},[3443],{"type":43,"value":3444},"np_ticks ",{"type":37,"tag":758,"props":3446,"children":3447},{"style":835},[3448],{"type":43,"value":854},{"type":37,"tag":758,"props":3450,"children":3451},{"style":777},[3452],{"type":43,"value":3453}," np.expand_dims(np_positions, ",{"type":37,"tag":758,"props":3455,"children":3456},{"style":846},[3457],{"type":43,"value":3458},"axis",{"type":37,"tag":758,"props":3460,"children":3461},{"style":835},[3462],{"type":43,"value":854},{"type":37,"tag":758,"props":3464,"children":3465},{"style":1296},[3466],{"type":43,"value":2280},{"type":37,"tag":758,"props":3468,"children":3469},{"style":777},[3470],{"type":43,"value":864},{"type":37,"tag":758,"props":3472,"children":3474},{"class":760,"line":3473},20,[3475,3480,3484],{"type":37,"tag":758,"props":3476,"children":3477},{"style":777},[3478],{"type":43,"value":3479},"cp_ticks ",{"type":37,"tag":758,"props":3481,"children":3482},{"style":835},[3483],{"type":43,"value":854},{"type":37,"tag":758,"props":3485,"children":3486},{"style":777},[3487],{"type":43,"value":3488}," cp.array(np_ticks)\n",{"type":37,"tag":758,"props":3490,"children":3492},{"class":760,"line":3491},21,[3493],{"type":37,"tag":758,"props":3494,"children":3495},{"emptyLinePlaceholder":32},[3496],{"type":43,"value":2597},{"type":37,"tag":758,"props":3498,"children":3500},{"class":760,"line":3499},22,[3501],{"type":37,"tag":758,"props":3502,"children":3503},{"style":3227},[3504],{"type":43,"value":3505},"# nbody simulation loop\n",{"type":37,"tag":758,"props":3507,"children":3509},{"class":760,"line":3508},23,[3510,3515,3519],{"type":37,"tag":758,"props":3511,"children":3512},{"style":777},[3513],{"type":43,"value":3514},"start_time ",{"type":37,"tag":758,"props":3516,"children":3517},{"style":835},[3518],{"type":43,"value":854},{"type":37,"tag":758,"props":3520,"children":3521},{"style":777},[3522],{"type":43,"value":3523}," time.time()\n",{"type":37,"tag":758,"props":3525,"children":3527},{"class":760,"line":3526},24,[3528,3532,3537,3541,3546,3550,3554],{"type":37,"tag":758,"props":3529,"children":3530},{"style":835},[3531],{"type":43,"value":2908},{"type":37,"tag":758,"props":3533,"children":3534},{"style":777},[3535],{"type":43,"value":3536}," step ",{"type":37,"tag":758,"props":3538,"children":3539},{"style":835},[3540],{"type":43,"value":2918},{"type":37,"tag":758,"props":3542,"children":3543},{"style":2853},[3544],{"type":43,"value":3545}," range",{"type":37,"tag":758,"props":3547,"children":3548},{"style":777},[3549],{"type":43,"value":780},{"type":37,"tag":758,"props":3551,"children":3552},{"style":1296},[3553],{"type":43,"value":3277},{"type":37,"tag":758,"props":3555,"children":3556},{"style":777},[3557],{"type":43,"value":791},{"type":37,"tag":758,"props":3559,"children":3561},{"class":760,"line":3560},25,[3562],{"type":37,"tag":758,"props":3563,"children":3564},{"emptyLinePlaceholder":32},[3565],{"type":43,"value":2597},{"type":37,"tag":758,"props":3567,"children":3569},{"class":760,"line":3568},26,[3570],{"type":37,"tag":758,"props":3571,"children":3572},{"style":3227},[3573],{"type":43,"value":3574},"    # this gets pairwise differences\n",{"type":37,"tag":758,"props":3576,"children":3578},{"class":760,"line":3577},27,[3579,3584,3588,3593,3598,3603,3608,3613,3617],{"type":37,"tag":758,"props":3580,"children":3581},{"style":777},[3582],{"type":43,"value":3583},"    diff ",{"type":37,"tag":758,"props":3585,"children":3586},{"style":835},[3587],{"type":43,"value":854},{"type":37,"tag":758,"props":3589,"children":3590},{"style":777},[3591],{"type":43,"value":3592}," cp_positions[:, ",{"type":37,"tag":758,"props":3594,"children":3595},{"style":1296},[3596],{"type":43,"value":3597},"None",{"type":37,"tag":758,"props":3599,"children":3600},{"style":777},[3601],{"type":43,"value":3602},", :] ",{"type":37,"tag":758,"props":3604,"children":3605},{"style":835},[3606],{"type":43,"value":3607},"-",{"type":37,"tag":758,"props":3609,"children":3610},{"style":777},[3611],{"type":43,"value":3612}," cp_positions[",{"type":37,"tag":758,"props":3614,"children":3615},{"style":1296},[3616],{"type":43,"value":3597},{"type":37,"tag":758,"props":3618,"children":3619},{"style":777},[3620],{"type":43,"value":3621},", :, :]\n",{"type":37,"tag":758,"props":3623,"children":3625},{"class":760,"line":3624},28,[3626,3631,3635,3640,3645,3650,3654,3658,3662,3666],{"type":37,"tag":758,"props":3627,"children":3628},{"style":777},[3629],{"type":43,"value":3630},"    distances ",{"type":37,"tag":758,"props":3632,"children":3633},{"style":835},[3634],{"type":43,"value":854},{"type":37,"tag":758,"props":3636,"children":3637},{"style":777},[3638],{"type":43,"value":3639}," cp.sqrt(cp.sum(diff",{"type":37,"tag":758,"props":3641,"children":3642},{"style":835},[3643],{"type":43,"value":3644},"**",{"type":37,"tag":758,"props":3646,"children":3647},{"style":1296},[3648],{"type":43,"value":3649},"2",{"type":37,"tag":758,"props":3651,"children":3652},{"style":777},[3653],{"type":43,"value":2986},{"type":37,"tag":758,"props":3655,"children":3656},{"style":846},[3657],{"type":43,"value":3458},{"type":37,"tag":758,"props":3659,"children":3660},{"style":835},[3661],{"type":43,"value":854},{"type":37,"tag":758,"props":3663,"children":3664},{"style":1296},[3665],{"type":43,"value":3649},{"type":37,"tag":758,"props":3667,"children":3668},{"style":777},[3669],{"type":43,"value":3670},"))\n",{"type":37,"tag":758,"props":3672,"children":3674},{"class":760,"line":3673},29,[3675],{"type":37,"tag":758,"props":3676,"children":3677},{"emptyLinePlaceholder":32},[3678],{"type":43,"value":2597},{"type":37,"tag":758,"props":3680,"children":3682},{"class":760,"line":3681},30,[3683],{"type":37,"tag":758,"props":3684,"children":3685},{"style":3227},[3686],{"type":43,"value":3687},"    # avoid division by zero\n",{"type":37,"tag":758,"props":3689,"children":3691},{"class":760,"line":3690},31,[3692,3697,3701],{"type":37,"tag":758,"props":3693,"children":3694},{"style":777},[3695],{"type":43,"value":3696},"    epsilon ",{"type":37,"tag":758,"props":3698,"children":3699},{"style":835},[3700],{"type":43,"value":854},{"type":37,"tag":758,"props":3702,"children":3703},{"style":1296},[3704],{"type":43,"value":3705}," 1e-5\n",{"type":37,"tag":758,"props":3707,"children":3709},{"class":760,"line":3708},32,[3710,3715,3719,3724,3729],{"type":37,"tag":758,"props":3711,"children":3712},{"style":777},[3713],{"type":43,"value":3714},"    inv_distances ",{"type":37,"tag":758,"props":3716,"children":3717},{"style":835},[3718],{"type":43,"value":854},{"type":37,"tag":758,"props":3720,"children":3721},{"style":1296},[3722],{"type":43,"value":3723}," 1.0",{"type":37,"tag":758,"props":3725,"children":3726},{"style":835},[3727],{"type":43,"value":3728}," /",{"type":37,"tag":758,"props":3730,"children":3731},{"style":777},[3732],{"type":43,"value":3733}," cp.maximum(distances, epsilon)\n",{"type":37,"tag":758,"props":3735,"children":3737},{"class":760,"line":3736},33,[3738],{"type":37,"tag":758,"props":3739,"children":3740},{"emptyLinePlaceholder":32},[3741],{"type":43,"value":2597},{"type":37,"tag":758,"props":3743,"children":3745},{"class":760,"line":3744},34,[3746],{"type":37,"tag":758,"props":3747,"children":3748},{"style":3227},[3749],{"type":43,"value":3750},"    # calculate forces\n",{"type":37,"tag":758,"props":3752,"children":3754},{"class":760,"line":3753},35,[3755,3760,3764,3769,3774,3779,3783,3788,3793,3797,3801,3806],{"type":37,"tag":758,"props":3756,"children":3757},{"style":777},[3758],{"type":43,"value":3759},"    cp_forces ",{"type":37,"tag":758,"props":3761,"children":3762},{"style":835},[3763],{"type":43,"value":854},{"type":37,"tag":758,"props":3765,"children":3766},{"style":777},[3767],{"type":43,"value":3768}," cp.sum((diff.T ",{"type":37,"tag":758,"props":3770,"children":3771},{"style":835},[3772],{"type":43,"value":3773},"*",{"type":37,"tag":758,"props":3775,"children":3776},{"style":777},[3777],{"type":43,"value":3778}," inv_distances",{"type":37,"tag":758,"props":3780,"children":3781},{"style":835},[3782],{"type":43,"value":3644},{"type":37,"tag":758,"props":3784,"children":3785},{"style":1296},[3786],{"type":43,"value":3787},"3",{"type":37,"tag":758,"props":3789,"children":3790},{"style":777},[3791],{"type":43,"value":3792},").T, ",{"type":37,"tag":758,"props":3794,"children":3795},{"style":846},[3796],{"type":43,"value":3458},{"type":37,"tag":758,"props":3798,"children":3799},{"style":835},[3800],{"type":43,"value":854},{"type":37,"tag":758,"props":3802,"children":3803},{"style":1296},[3804],{"type":43,"value":3805},"1",{"type":37,"tag":758,"props":3807,"children":3808},{"style":777},[3809],{"type":43,"value":864},{"type":37,"tag":758,"props":3811,"children":3813},{"class":760,"line":3812},36,[3814],{"type":37,"tag":758,"props":3815,"children":3816},{"emptyLinePlaceholder":32},[3817],{"type":43,"value":2597},{"type":37,"tag":758,"props":3819,"children":3821},{"class":760,"line":3820},37,[3822],{"type":37,"tag":758,"props":3823,"children":3824},{"style":3227},[3825],{"type":43,"value":3826},"    # update velocities and positions\n",{"type":37,"tag":758,"props":3828,"children":3830},{"class":760,"line":3829},38,[3831,3836,3841,3846,3851],{"type":37,"tag":758,"props":3832,"children":3833},{"style":777},[3834],{"type":43,"value":3835},"    cp_velocities ",{"type":37,"tag":758,"props":3837,"children":3838},{"style":835},[3839],{"type":43,"value":3840},"+=",{"type":37,"tag":758,"props":3842,"children":3843},{"style":1296},[3844],{"type":43,"value":3845}," DT",{"type":37,"tag":758,"props":3847,"children":3848},{"style":835},[3849],{"type":43,"value":3850}," *",{"type":37,"tag":758,"props":3852,"children":3853},{"style":777},[3854],{"type":43,"value":3855}," cp_forces\n",{"type":37,"tag":758,"props":3857,"children":3859},{"class":760,"line":3858},39,[3860,3865,3869,3873,3877],{"type":37,"tag":758,"props":3861,"children":3862},{"style":777},[3863],{"type":43,"value":3864},"    cp_positions ",{"type":37,"tag":758,"props":3866,"children":3867},{"style":835},[3868],{"type":43,"value":3840},{"type":37,"tag":758,"props":3870,"children":3871},{"style":1296},[3872],{"type":43,"value":3845},{"type":37,"tag":758,"props":3874,"children":3875},{"style":835},[3876],{"type":43,"value":3850},{"type":37,"tag":758,"props":3878,"children":3879},{"style":777},[3880],{"type":43,"value":3881}," cp_velocities\n",{"type":37,"tag":758,"props":3883,"children":3885},{"class":760,"line":3884},40,[3886,3891,3895,3900,3904,3909,3913],{"type":37,"tag":758,"props":3887,"children":3888},{"style":777},[3889],{"type":43,"value":3890},"    cp_ticks ",{"type":37,"tag":758,"props":3892,"children":3893},{"style":835},[3894],{"type":43,"value":854},{"type":37,"tag":758,"props":3896,"children":3897},{"style":777},[3898],{"type":43,"value":3899}," cp.append(cp_ticks, cp.expand_dims(cp_positions, ",{"type":37,"tag":758,"props":3901,"children":3902},{"style":1296},[3903],{"type":43,"value":2280},{"type":37,"tag":758,"props":3905,"children":3906},{"style":777},[3907],{"type":43,"value":3908},"), ",{"type":37,"tag":758,"props":3910,"children":3911},{"style":1296},[3912],{"type":43,"value":2280},{"type":37,"tag":758,"props":3914,"children":3915},{"style":777},[3916],{"type":43,"value":864},{"type":37,"tag":758,"props":3918,"children":3920},{"class":760,"line":3919},41,[3921],{"type":37,"tag":758,"props":3922,"children":3923},{"emptyLinePlaceholder":32},[3924],{"type":43,"value":2597},{"type":37,"tag":758,"props":3926,"children":3928},{"class":760,"line":3927},42,[3929,3934,3938,3943,3947],{"type":37,"tag":758,"props":3930,"children":3931},{"style":777},[3932],{"type":43,"value":3933},"sim_time ",{"type":37,"tag":758,"props":3935,"children":3936},{"style":835},[3937],{"type":43,"value":854},{"type":37,"tag":758,"props":3939,"children":3940},{"style":777},[3941],{"type":43,"value":3942}," time.time() ",{"type":37,"tag":758,"props":3944,"children":3945},{"style":835},[3946],{"type":43,"value":3607},{"type":37,"tag":758,"props":3948,"children":3949},{"style":777},[3950],{"type":43,"value":3951}," start_time\n",{"type":37,"tag":758,"props":3953,"children":3955},{"class":760,"line":3954},43,[3956,3960,3964,3969],{"type":37,"tag":758,"props":3957,"children":3958},{"style":2853},[3959],{"type":43,"value":2856},{"type":37,"tag":758,"props":3961,"children":3962},{"style":777},[3963],{"type":43,"value":780},{"type":37,"tag":758,"props":3965,"children":3966},{"style":797},[3967],{"type":43,"value":3968},"\"Simulation time:\"",{"type":37,"tag":758,"props":3970,"children":3971},{"style":777},[3972],{"type":43,"value":3973},", sim_time)\n",{"type":37,"tag":758,"props":3975,"children":3977},{"class":760,"line":3976},44,[3978],{"type":37,"tag":758,"props":3979,"children":3980},{"emptyLinePlaceholder":32},[3981],{"type":43,"value":2597},{"type":37,"tag":758,"props":3983,"children":3985},{"class":760,"line":3984},45,[3986],{"type":37,"tag":758,"props":3987,"children":3988},{"emptyLinePlaceholder":32},[3989],{"type":43,"value":2597},{"type":37,"tag":758,"props":3991,"children":3993},{"class":760,"line":3992},46,[3994,3998,4003,4007,4012,4016,4021],{"type":37,"tag":758,"props":3995,"children":3996},{"style":765},[3997],{"type":43,"value":768},{"type":37,"tag":758,"props":3999,"children":4000},{"style":771},[4001],{"type":43,"value":4002}," NumpyArrayEncoder",{"type":37,"tag":758,"props":4004,"children":4005},{"style":777},[4006],{"type":43,"value":780},{"type":37,"tag":758,"props":4008,"children":4009},{"style":783},[4010],{"type":43,"value":4011},"json",{"type":37,"tag":758,"props":4013,"children":4014},{"style":777},[4015],{"type":43,"value":61},{"type":37,"tag":758,"props":4017,"children":4018},{"style":783},[4019],{"type":43,"value":4020},"JSONEncoder",{"type":37,"tag":758,"props":4022,"children":4023},{"style":777},[4024],{"type":43,"value":791},{"type":37,"tag":758,"props":4026,"children":4028},{"class":760,"line":4027},47,[4029,4034,4039,4043,4049,4053,4058],{"type":37,"tag":758,"props":4030,"children":4031},{"style":765},[4032],{"type":43,"value":4033},"    def",{"type":37,"tag":758,"props":4035,"children":4036},{"style":1768},[4037],{"type":43,"value":4038}," default",{"type":37,"tag":758,"props":4040,"children":4041},{"style":777},[4042],{"type":43,"value":780},{"type":37,"tag":758,"props":4044,"children":4046},{"style":4045},"--shiki-default:#24292E;--shiki-dark:#E1E4E8;--shiki-sepia:#FD971F;--shiki-default-font-style:inherit;--shiki-dark-font-style:inherit;--shiki-sepia-font-style:italic",[4047],{"type":43,"value":4048},"self",{"type":37,"tag":758,"props":4050,"children":4051},{"style":777},[4052],{"type":43,"value":2986},{"type":37,"tag":758,"props":4054,"children":4055},{"style":4045},[4056],{"type":43,"value":4057},"obj",{"type":37,"tag":758,"props":4059,"children":4060},{"style":777},[4061],{"type":43,"value":791},{"type":37,"tag":758,"props":4063,"children":4065},{"class":760,"line":4064},48,[4066,4071,4076],{"type":37,"tag":758,"props":4067,"children":4068},{"style":835},[4069],{"type":43,"value":4070},"        if",{"type":37,"tag":758,"props":4072,"children":4073},{"style":2853},[4074],{"type":43,"value":4075}," isinstance",{"type":37,"tag":758,"props":4077,"children":4078},{"style":777},[4079],{"type":43,"value":4080},"(obj, np.ndarray):\n",{"type":37,"tag":758,"props":4082,"children":4084},{"class":760,"line":4083},49,[4085,4090],{"type":37,"tag":758,"props":4086,"children":4087},{"style":835},[4088],{"type":43,"value":4089},"            return",{"type":37,"tag":758,"props":4091,"children":4092},{"style":777},[4093],{"type":43,"value":4094}," obj.tolist()\n",{"type":37,"tag":758,"props":4096,"children":4098},{"class":760,"line":4097},50,[4099,4104,4109,4114],{"type":37,"tag":758,"props":4100,"children":4101},{"style":835},[4102],{"type":43,"value":4103},"        return",{"type":37,"tag":758,"props":4105,"children":4106},{"style":777},[4107],{"type":43,"value":4108}," json.JSONEncoder.default(",{"type":37,"tag":758,"props":4110,"children":4112},{"style":4111},"--shiki-default:#005CC5;--shiki-dark:#79B8FF;--shiki-sepia:#FD971F",[4113],{"type":43,"value":4048},{"type":37,"tag":758,"props":4115,"children":4116},{"style":777},[4117],{"type":43,"value":4118},", obj)\n",{"type":37,"tag":758,"props":4120,"children":4122},{"class":760,"line":4121},51,[4123],{"type":37,"tag":758,"props":4124,"children":4125},{"emptyLinePlaceholder":32},[4126],{"type":43,"value":2597},{"type":37,"tag":758,"props":4128,"children":4130},{"class":760,"line":4129},52,[4131],{"type":37,"tag":758,"props":4132,"children":4133},{"emptyLinePlaceholder":32},[4134],{"type":43,"value":2597},{"type":37,"tag":758,"props":4136,"children":4138},{"class":760,"line":4137},53,[4139,4143,4147],{"type":37,"tag":758,"props":4140,"children":4141},{"style":777},[4142],{"type":43,"value":3444},{"type":37,"tag":758,"props":4144,"children":4145},{"style":835},[4146],{"type":43,"value":854},{"type":37,"tag":758,"props":4148,"children":4149},{"style":777},[4150],{"type":43,"value":4151}," cp_ticks.get()\n",{"type":37,"tag":758,"props":4153,"children":4155},{"class":760,"line":4154},54,[4156],{"type":37,"tag":758,"props":4157,"children":4158},{"emptyLinePlaceholder":32},[4159],{"type":43,"value":2597},{"type":37,"tag":758,"props":4161,"children":4163},{"class":760,"line":4162},55,[4164],{"type":37,"tag":758,"props":4165,"children":4166},{"emptyLinePlaceholder":32},[4167],{"type":43,"value":2597},{"type":37,"tag":758,"props":4169,"children":4171},{"class":760,"line":4170},56,[4172],{"type":37,"tag":758,"props":4173,"children":4174},{"style":3227},[4175],{"type":43,"value":4176},"# this is data we can work with in python and write to a file\n",{"type":37,"tag":758,"props":4178,"children":4180},{"class":760,"line":4179},57,[4181,4186,4191,4195,4200,4204,4209,4214,4218],{"type":37,"tag":758,"props":4182,"children":4183},{"style":835},[4184],{"type":43,"value":4185},"with",{"type":37,"tag":758,"props":4187,"children":4188},{"style":2853},[4189],{"type":43,"value":4190}," open",{"type":37,"tag":758,"props":4192,"children":4193},{"style":777},[4194],{"type":43,"value":780},{"type":37,"tag":758,"props":4196,"children":4197},{"style":797},[4198],{"type":43,"value":4199},"\"ticks.json\"",{"type":37,"tag":758,"props":4201,"children":4202},{"style":777},[4203],{"type":43,"value":2986},{"type":37,"tag":758,"props":4205,"children":4206},{"style":797},[4207],{"type":43,"value":4208},"\"w\"",{"type":37,"tag":758,"props":4210,"children":4211},{"style":777},[4212],{"type":43,"value":4213},") ",{"type":37,"tag":758,"props":4215,"children":4216},{"style":835},[4217],{"type":43,"value":3165},{"type":37,"tag":758,"props":4219,"children":4220},{"style":777},[4221],{"type":43,"value":4222}," f:\n",{"type":37,"tag":758,"props":4224,"children":4226},{"class":760,"line":4225},58,[4227,4232,4237,4241],{"type":37,"tag":758,"props":4228,"children":4229},{"style":777},[4230],{"type":43,"value":4231},"    f.write(json.dumps(np_ticks, ",{"type":37,"tag":758,"props":4233,"children":4234},{"style":846},[4235],{"type":43,"value":4236},"cls",{"type":37,"tag":758,"props":4238,"children":4239},{"style":835},[4240],{"type":43,"value":854},{"type":37,"tag":758,"props":4242,"children":4243},{"style":777},[4244],{"type":43,"value":4245},"NumpyArrayEncoder))\n",{"type":37,"tag":46,"props":4247,"children":4248},{},[4249],{"type":43,"value":4250},"To better understand the matrix math here I walked through a simple example of what each step does:",{"type":37,"tag":212,"props":4252,"children":4254},{"code":4253,"language":3143,"meta":8,"className":3144,"style":8},"# particle coordinates (x,y,z) in 3D space\npositions = cp.array([[1,2.5,3], [4,5,6], [7,8,9]])\n",[4255],{"type":37,"tag":160,"props":4256,"children":4257},{"__ignoreMap":8},[4258,4266],{"type":37,"tag":758,"props":4259,"children":4260},{"class":760,"line":761},[4261],{"type":37,"tag":758,"props":4262,"children":4263},{"style":3227},[4264],{"type":43,"value":4265},"# particle coordinates (x,y,z) in 3D space\n",{"type":37,"tag":758,"props":4267,"children":4268},{"class":760,"line":502},[4269,4274,4278,4283,4287,4292,4297,4301,4305,4310,4314,4318,4322,4326,4331,4335,4340,4344,4348,4352,4357],{"type":37,"tag":758,"props":4270,"children":4271},{"style":777},[4272],{"type":43,"value":4273},"positions ",{"type":37,"tag":758,"props":4275,"children":4276},{"style":835},[4277],{"type":43,"value":854},{"type":37,"tag":758,"props":4279,"children":4280},{"style":777},[4281],{"type":43,"value":4282}," cp.array([[",{"type":37,"tag":758,"props":4284,"children":4285},{"style":1296},[4286],{"type":43,"value":3805},{"type":37,"tag":758,"props":4288,"children":4289},{"style":777},[4290],{"type":43,"value":4291},",",{"type":37,"tag":758,"props":4293,"children":4294},{"style":1296},[4295],{"type":43,"value":4296},"2.5",{"type":37,"tag":758,"props":4298,"children":4299},{"style":777},[4300],{"type":43,"value":4291},{"type":37,"tag":758,"props":4302,"children":4303},{"style":1296},[4304],{"type":43,"value":3787},{"type":37,"tag":758,"props":4306,"children":4307},{"style":777},[4308],{"type":43,"value":4309},"], [",{"type":37,"tag":758,"props":4311,"children":4312},{"style":1296},[4313],{"type":43,"value":2874},{"type":37,"tag":758,"props":4315,"children":4316},{"style":777},[4317],{"type":43,"value":4291},{"type":37,"tag":758,"props":4319,"children":4320},{"style":1296},[4321],{"type":43,"value":3110},{"type":37,"tag":758,"props":4323,"children":4324},{"style":777},[4325],{"type":43,"value":4291},{"type":37,"tag":758,"props":4327,"children":4328},{"style":1296},[4329],{"type":43,"value":4330},"6",{"type":37,"tag":758,"props":4332,"children":4333},{"style":777},[4334],{"type":43,"value":4309},{"type":37,"tag":758,"props":4336,"children":4337},{"style":1296},[4338],{"type":43,"value":4339},"7",{"type":37,"tag":758,"props":4341,"children":4342},{"style":777},[4343],{"type":43,"value":4291},{"type":37,"tag":758,"props":4345,"children":4346},{"style":1296},[4347],{"type":43,"value":3094},{"type":37,"tag":758,"props":4349,"children":4350},{"style":777},[4351],{"type":43,"value":4291},{"type":37,"tag":758,"props":4353,"children":4354},{"style":1296},[4355],{"type":43,"value":4356},"9",{"type":37,"tag":758,"props":4358,"children":4359},{"style":777},[4360],{"type":43,"value":4361},"]])\n",{"type":37,"tag":46,"props":4363,"children":4364},{},[4365],{"type":43,"value":4366},"The first operation creates an array for pairwise distances for each dimension:",{"type":37,"tag":212,"props":4368,"children":4370},{"code":4369,"language":751,"meta":8,"className":752,"style":8},"diff = positions[None, :, :] - positions[:, None, :]\nprint(diff)\n\narray([[[ 0. ,  0. ,  0. ],\n        [ 3. ,  2.5,  3. ],\n        [ 6. ,  5.5,  6. ]],\n\n       [[-3. , -2.5, -3. ],\n        [ 0. ,  0. ,  0. ],\n        [ 3. ,  3. ,  3. ]],\n\n       [[-6. , -5.5, -6. ],\n        [-3. , -3. , -3. ],\n        [ 0. ,  0. ,  0. ]]])\n",[4371],{"type":37,"tag":160,"props":4372,"children":4373},{"__ignoreMap":8},[4374,4418,4430,4437,4471,4504,4537,4544,4589,4620,4651,4658,4701,4745],{"type":37,"tag":758,"props":4375,"children":4376},{"class":760,"line":761},[4377,4382,4386,4391,4395,4400,4404,4409,4413],{"type":37,"tag":758,"props":4378,"children":4379},{"style":777},[4380],{"type":43,"value":4381},"diff ",{"type":37,"tag":758,"props":4383,"children":4384},{"style":835},[4385],{"type":43,"value":854},{"type":37,"tag":758,"props":4387,"children":4388},{"style":777},[4389],{"type":43,"value":4390}," positions[",{"type":37,"tag":758,"props":4392,"children":4393},{"style":1296},[4394],{"type":43,"value":3597},{"type":37,"tag":758,"props":4396,"children":4397},{"style":777},[4398],{"type":43,"value":4399},", :, :] ",{"type":37,"tag":758,"props":4401,"children":4402},{"style":835},[4403],{"type":43,"value":3607},{"type":37,"tag":758,"props":4405,"children":4406},{"style":777},[4407],{"type":43,"value":4408}," positions[:, ",{"type":37,"tag":758,"props":4410,"children":4411},{"style":1296},[4412],{"type":43,"value":3597},{"type":37,"tag":758,"props":4414,"children":4415},{"style":777},[4416],{"type":43,"value":4417},", :]\n",{"type":37,"tag":758,"props":4419,"children":4420},{"class":760,"line":502},[4421,4425],{"type":37,"tag":758,"props":4422,"children":4423},{"style":2853},[4424],{"type":43,"value":2856},{"type":37,"tag":758,"props":4426,"children":4427},{"style":777},[4428],{"type":43,"value":4429},"(diff)\n",{"type":37,"tag":758,"props":4431,"children":4432},{"class":760,"line":803},[4433],{"type":37,"tag":758,"props":4434,"children":4435},{"emptyLinePlaceholder":32},[4436],{"type":43,"value":2597},{"type":37,"tag":758,"props":4438,"children":4439},{"class":760,"line":812},[4440,4445,4449,4454,4458,4462,4466],{"type":37,"tag":758,"props":4441,"children":4442},{"style":777},[4443],{"type":43,"value":4444},"array([[[ ",{"type":37,"tag":758,"props":4446,"children":4447},{"style":1296},[4448],{"type":43,"value":2280},{"type":37,"tag":758,"props":4450,"children":4451},{"style":777},[4452],{"type":43,"value":4453},". ,  ",{"type":37,"tag":758,"props":4455,"children":4456},{"style":1296},[4457],{"type":43,"value":2280},{"type":37,"tag":758,"props":4459,"children":4460},{"style":777},[4461],{"type":43,"value":4453},{"type":37,"tag":758,"props":4463,"children":4464},{"style":1296},[4465],{"type":43,"value":2280},{"type":37,"tag":758,"props":4467,"children":4468},{"style":777},[4469],{"type":43,"value":4470},". ],\n",{"type":37,"tag":758,"props":4472,"children":4473},{"class":760,"line":820},[4474,4479,4483,4487,4491,4496,4500],{"type":37,"tag":758,"props":4475,"children":4476},{"style":777},[4477],{"type":43,"value":4478},"        [ ",{"type":37,"tag":758,"props":4480,"children":4481},{"style":1296},[4482],{"type":43,"value":3787},{"type":37,"tag":758,"props":4484,"children":4485},{"style":777},[4486],{"type":43,"value":4453},{"type":37,"tag":758,"props":4488,"children":4489},{"style":1296},[4490],{"type":43,"value":4296},{"type":37,"tag":758,"props":4492,"children":4493},{"style":777},[4494],{"type":43,"value":4495},",  ",{"type":37,"tag":758,"props":4497,"children":4498},{"style":1296},[4499],{"type":43,"value":3787},{"type":37,"tag":758,"props":4501,"children":4502},{"style":777},[4503],{"type":43,"value":4470},{"type":37,"tag":758,"props":4505,"children":4506},{"class":760,"line":867},[4507,4511,4515,4519,4524,4528,4532],{"type":37,"tag":758,"props":4508,"children":4509},{"style":777},[4510],{"type":43,"value":4478},{"type":37,"tag":758,"props":4512,"children":4513},{"style":1296},[4514],{"type":43,"value":4330},{"type":37,"tag":758,"props":4516,"children":4517},{"style":777},[4518],{"type":43,"value":4453},{"type":37,"tag":758,"props":4520,"children":4521},{"style":1296},[4522],{"type":43,"value":4523},"5.5",{"type":37,"tag":758,"props":4525,"children":4526},{"style":777},[4527],{"type":43,"value":4495},{"type":37,"tag":758,"props":4529,"children":4530},{"style":1296},[4531],{"type":43,"value":4330},{"type":37,"tag":758,"props":4533,"children":4534},{"style":777},[4535],{"type":43,"value":4536},". ]],\n",{"type":37,"tag":758,"props":4538,"children":4539},{"class":760,"line":905},[4540],{"type":37,"tag":758,"props":4541,"children":4542},{"emptyLinePlaceholder":32},[4543],{"type":43,"value":2597},{"type":37,"tag":758,"props":4545,"children":4546},{"class":760,"line":943},[4547,4552,4556,4560,4565,4569,4573,4577,4581,4585],{"type":37,"tag":758,"props":4548,"children":4549},{"style":777},[4550],{"type":43,"value":4551},"       [[",{"type":37,"tag":758,"props":4553,"children":4554},{"style":835},[4555],{"type":43,"value":3607},{"type":37,"tag":758,"props":4557,"children":4558},{"style":1296},[4559],{"type":43,"value":3787},{"type":37,"tag":758,"props":4561,"children":4562},{"style":777},[4563],{"type":43,"value":4564},". , ",{"type":37,"tag":758,"props":4566,"children":4567},{"style":835},[4568],{"type":43,"value":3607},{"type":37,"tag":758,"props":4570,"children":4571},{"style":1296},[4572],{"type":43,"value":4296},{"type":37,"tag":758,"props":4574,"children":4575},{"style":777},[4576],{"type":43,"value":2986},{"type":37,"tag":758,"props":4578,"children":4579},{"style":835},[4580],{"type":43,"value":3607},{"type":37,"tag":758,"props":4582,"children":4583},{"style":1296},[4584],{"type":43,"value":3787},{"type":37,"tag":758,"props":4586,"children":4587},{"style":777},[4588],{"type":43,"value":4470},{"type":37,"tag":758,"props":4590,"children":4591},{"class":760,"line":981},[4592,4596,4600,4604,4608,4612,4616],{"type":37,"tag":758,"props":4593,"children":4594},{"style":777},[4595],{"type":43,"value":4478},{"type":37,"tag":758,"props":4597,"children":4598},{"style":1296},[4599],{"type":43,"value":2280},{"type":37,"tag":758,"props":4601,"children":4602},{"style":777},[4603],{"type":43,"value":4453},{"type":37,"tag":758,"props":4605,"children":4606},{"style":1296},[4607],{"type":43,"value":2280},{"type":37,"tag":758,"props":4609,"children":4610},{"style":777},[4611],{"type":43,"value":4453},{"type":37,"tag":758,"props":4613,"children":4614},{"style":1296},[4615],{"type":43,"value":2280},{"type":37,"tag":758,"props":4617,"children":4618},{"style":777},[4619],{"type":43,"value":4470},{"type":37,"tag":758,"props":4621,"children":4622},{"class":760,"line":1019},[4623,4627,4631,4635,4639,4643,4647],{"type":37,"tag":758,"props":4624,"children":4625},{"style":777},[4626],{"type":43,"value":4478},{"type":37,"tag":758,"props":4628,"children":4629},{"style":1296},[4630],{"type":43,"value":3787},{"type":37,"tag":758,"props":4632,"children":4633},{"style":777},[4634],{"type":43,"value":4453},{"type":37,"tag":758,"props":4636,"children":4637},{"style":1296},[4638],{"type":43,"value":3787},{"type":37,"tag":758,"props":4640,"children":4641},{"style":777},[4642],{"type":43,"value":4453},{"type":37,"tag":758,"props":4644,"children":4645},{"style":1296},[4646],{"type":43,"value":3787},{"type":37,"tag":758,"props":4648,"children":4649},{"style":777},[4650],{"type":43,"value":4536},{"type":37,"tag":758,"props":4652,"children":4653},{"class":760,"line":1057},[4654],{"type":37,"tag":758,"props":4655,"children":4656},{"emptyLinePlaceholder":32},[4657],{"type":43,"value":2597},{"type":37,"tag":758,"props":4659,"children":4660},{"class":760,"line":1095},[4661,4665,4669,4673,4677,4681,4685,4689,4693,4697],{"type":37,"tag":758,"props":4662,"children":4663},{"style":777},[4664],{"type":43,"value":4551},{"type":37,"tag":758,"props":4666,"children":4667},{"style":835},[4668],{"type":43,"value":3607},{"type":37,"tag":758,"props":4670,"children":4671},{"style":1296},[4672],{"type":43,"value":4330},{"type":37,"tag":758,"props":4674,"children":4675},{"style":777},[4676],{"type":43,"value":4564},{"type":37,"tag":758,"props":4678,"children":4679},{"style":835},[4680],{"type":43,"value":3607},{"type":37,"tag":758,"props":4682,"children":4683},{"style":1296},[4684],{"type":43,"value":4523},{"type":37,"tag":758,"props":4686,"children":4687},{"style":777},[4688],{"type":43,"value":2986},{"type":37,"tag":758,"props":4690,"children":4691},{"style":835},[4692],{"type":43,"value":3607},{"type":37,"tag":758,"props":4694,"children":4695},{"style":1296},[4696],{"type":43,"value":4330},{"type":37,"tag":758,"props":4698,"children":4699},{"style":777},[4700],{"type":43,"value":4470},{"type":37,"tag":758,"props":4702,"children":4703},{"class":760,"line":2728},[4704,4709,4713,4717,4721,4725,4729,4733,4737,4741],{"type":37,"tag":758,"props":4705,"children":4706},{"style":777},[4707],{"type":43,"value":4708},"        [",{"type":37,"tag":758,"props":4710,"children":4711},{"style":835},[4712],{"type":43,"value":3607},{"type":37,"tag":758,"props":4714,"children":4715},{"style":1296},[4716],{"type":43,"value":3787},{"type":37,"tag":758,"props":4718,"children":4719},{"style":777},[4720],{"type":43,"value":4564},{"type":37,"tag":758,"props":4722,"children":4723},{"style":835},[4724],{"type":43,"value":3607},{"type":37,"tag":758,"props":4726,"children":4727},{"style":1296},[4728],{"type":43,"value":3787},{"type":37,"tag":758,"props":4730,"children":4731},{"style":777},[4732],{"type":43,"value":4564},{"type":37,"tag":758,"props":4734,"children":4735},{"style":835},[4736],{"type":43,"value":3607},{"type":37,"tag":758,"props":4738,"children":4739},{"style":1296},[4740],{"type":43,"value":3787},{"type":37,"tag":758,"props":4742,"children":4743},{"style":777},[4744],{"type":43,"value":4470},{"type":37,"tag":758,"props":4746,"children":4747},{"class":760,"line":2746},[4748,4752,4756,4760,4764,4768,4772],{"type":37,"tag":758,"props":4749,"children":4750},{"style":777},[4751],{"type":43,"value":4478},{"type":37,"tag":758,"props":4753,"children":4754},{"style":1296},[4755],{"type":43,"value":2280},{"type":37,"tag":758,"props":4757,"children":4758},{"style":777},[4759],{"type":43,"value":4453},{"type":37,"tag":758,"props":4761,"children":4762},{"style":1296},[4763],{"type":43,"value":2280},{"type":37,"tag":758,"props":4765,"children":4766},{"style":777},[4767],{"type":43,"value":4453},{"type":37,"tag":758,"props":4769,"children":4770},{"style":1296},[4771],{"type":43,"value":2280},{"type":37,"tag":758,"props":4773,"children":4774},{"style":777},[4775],{"type":43,"value":4776},". ]]])\n",{"type":37,"tag":46,"props":4778,"children":4779},{},[4780,4782,4787,4788,4794,4796,4802],{"type":43,"value":4781},"The rows of zeros correspond to a particle's ",{"type":37,"tag":160,"props":4783,"children":4785},{"className":4784},[],[4786],{"type":43,"value":31},{"type":43,"value":2986},{"type":37,"tag":160,"props":4789,"children":4791},{"className":4790},[],[4792],{"type":43,"value":4793},"y",{"type":43,"value":4795}," and ",{"type":37,"tag":160,"props":4797,"children":4799},{"className":4798},[],[4800],{"type":43,"value":4801},"z",{"type":43,"value":4803}," distances to itself, which are all zero by axioms of Euclidian vector spaces.",{"type":37,"tag":46,"props":4805,"children":4806},{},[4807],{"type":43,"value":4808},"The next operation calculates the distance between each particle:",{"type":37,"tag":212,"props":4810,"children":4812},{"code":4811,"language":751,"meta":8,"className":752,"style":8},"distances = cp.sqrt(cp.sum(diff**2, axis=2))\nprint(distances)\n\narray([[ 0.        ,  4.9244289 , 10.11187421],\n       [ 4.9244289 ,  0.        ,  5.19615242],\n       [10.11187421,  5.19615242,  0.        ]])\n",[4813],{"type":37,"tag":160,"props":4814,"children":4815},{"__ignoreMap":8},[4816,4860,4872,4879,4916,4950],{"type":37,"tag":758,"props":4817,"children":4818},{"class":760,"line":761},[4819,4824,4828,4832,4836,4840,4844,4848,4852,4856],{"type":37,"tag":758,"props":4820,"children":4821},{"style":777},[4822],{"type":43,"value":4823},"distances ",{"type":37,"tag":758,"props":4825,"children":4826},{"style":835},[4827],{"type":43,"value":854},{"type":37,"tag":758,"props":4829,"children":4830},{"style":777},[4831],{"type":43,"value":3639},{"type":37,"tag":758,"props":4833,"children":4834},{"style":835},[4835],{"type":43,"value":3644},{"type":37,"tag":758,"props":4837,"children":4838},{"style":1296},[4839],{"type":43,"value":3649},{"type":37,"tag":758,"props":4841,"children":4842},{"style":777},[4843],{"type":43,"value":2986},{"type":37,"tag":758,"props":4845,"children":4846},{"style":846},[4847],{"type":43,"value":3458},{"type":37,"tag":758,"props":4849,"children":4850},{"style":835},[4851],{"type":43,"value":854},{"type":37,"tag":758,"props":4853,"children":4854},{"style":1296},[4855],{"type":43,"value":3649},{"type":37,"tag":758,"props":4857,"children":4858},{"style":777},[4859],{"type":43,"value":3670},{"type":37,"tag":758,"props":4861,"children":4862},{"class":760,"line":502},[4863,4867],{"type":37,"tag":758,"props":4864,"children":4865},{"style":2853},[4866],{"type":43,"value":2856},{"type":37,"tag":758,"props":4868,"children":4869},{"style":777},[4870],{"type":43,"value":4871},"(distances)\n",{"type":37,"tag":758,"props":4873,"children":4874},{"class":760,"line":803},[4875],{"type":37,"tag":758,"props":4876,"children":4877},{"emptyLinePlaceholder":32},[4878],{"type":43,"value":2597},{"type":37,"tag":758,"props":4880,"children":4881},{"class":760,"line":812},[4882,4887,4891,4896,4901,4906,4911],{"type":37,"tag":758,"props":4883,"children":4884},{"style":777},[4885],{"type":43,"value":4886},"array([[ ",{"type":37,"tag":758,"props":4888,"children":4889},{"style":1296},[4890],{"type":43,"value":2280},{"type":37,"tag":758,"props":4892,"children":4893},{"style":777},[4894],{"type":43,"value":4895},".        ,  ",{"type":37,"tag":758,"props":4897,"children":4898},{"style":1296},[4899],{"type":43,"value":4900},"4.9244289",{"type":37,"tag":758,"props":4902,"children":4903},{"style":777},[4904],{"type":43,"value":4905}," , ",{"type":37,"tag":758,"props":4907,"children":4908},{"style":1296},[4909],{"type":43,"value":4910},"10.11187421",{"type":37,"tag":758,"props":4912,"children":4913},{"style":777},[4914],{"type":43,"value":4915},"],\n",{"type":37,"tag":758,"props":4917,"children":4918},{"class":760,"line":820},[4919,4924,4928,4933,4937,4941,4946],{"type":37,"tag":758,"props":4920,"children":4921},{"style":777},[4922],{"type":43,"value":4923},"       [ ",{"type":37,"tag":758,"props":4925,"children":4926},{"style":1296},[4927],{"type":43,"value":4900},{"type":37,"tag":758,"props":4929,"children":4930},{"style":777},[4931],{"type":43,"value":4932}," ,  ",{"type":37,"tag":758,"props":4934,"children":4935},{"style":1296},[4936],{"type":43,"value":2280},{"type":37,"tag":758,"props":4938,"children":4939},{"style":777},[4940],{"type":43,"value":4895},{"type":37,"tag":758,"props":4942,"children":4943},{"style":1296},[4944],{"type":43,"value":4945},"5.19615242",{"type":37,"tag":758,"props":4947,"children":4948},{"style":777},[4949],{"type":43,"value":4915},{"type":37,"tag":758,"props":4951,"children":4952},{"class":760,"line":867},[4953,4958,4962,4966,4970,4974,4978],{"type":37,"tag":758,"props":4954,"children":4955},{"style":777},[4956],{"type":43,"value":4957},"       [",{"type":37,"tag":758,"props":4959,"children":4960},{"style":1296},[4961],{"type":43,"value":4910},{"type":37,"tag":758,"props":4963,"children":4964},{"style":777},[4965],{"type":43,"value":4495},{"type":37,"tag":758,"props":4967,"children":4968},{"style":1296},[4969],{"type":43,"value":4945},{"type":37,"tag":758,"props":4971,"children":4972},{"style":777},[4973],{"type":43,"value":4495},{"type":37,"tag":758,"props":4975,"children":4976},{"style":1296},[4977],{"type":43,"value":2280},{"type":37,"tag":758,"props":4979,"children":4980},{"style":777},[4981],{"type":43,"value":4982},".        ]])\n",{"type":37,"tag":46,"props":4984,"children":4985},{},[4986,4988,4994],{"type":43,"value":4987},"The diagonal or zeros represents that fact that a particle ",{"type":37,"tag":160,"props":4989,"children":4991},{"className":4990},[],[4992],{"type":43,"value":4993},"n",{"type":43,"value":4995}," has a distance of zero to iself.",{"type":37,"tag":46,"props":4997,"children":4998},{},[4999,5001,5007],{"type":43,"value":5000},"The next step calculates inverse distances and uses a small ",{"type":37,"tag":160,"props":5002,"children":5004},{"className":5003},[],[5005],{"type":43,"value":5006},"epsilon",{"type":43,"value":5008}," value to avoid division by 0:",{"type":37,"tag":212,"props":5010,"children":5012},{"code":5011,"language":751,"meta":8,"className":752,"style":8},"epsilon = 1e-5\ninv_distances = 1.0 / cp.maximum(distances, epsilon)\nprint(inv_distances)\n\narray([[1.00000000e+05, 2.03069233e-01, 9.88936353e-02],\n       [2.03069233e-01, 1.00000000e+05, 1.92450090e-01],\n       [9.88936353e-02, 1.92450090e-01, 1.00000000e+05]])\n",[5013],{"type":37,"tag":160,"props":5014,"children":5015},{"__ignoreMap":8},[5016,5032,5056,5068,5075,5110,5142],{"type":37,"tag":758,"props":5017,"children":5018},{"class":760,"line":761},[5019,5024,5028],{"type":37,"tag":758,"props":5020,"children":5021},{"style":777},[5022],{"type":43,"value":5023},"epsilon ",{"type":37,"tag":758,"props":5025,"children":5026},{"style":835},[5027],{"type":43,"value":854},{"type":37,"tag":758,"props":5029,"children":5030},{"style":1296},[5031],{"type":43,"value":3705},{"type":37,"tag":758,"props":5033,"children":5034},{"class":760,"line":502},[5035,5040,5044,5048,5052],{"type":37,"tag":758,"props":5036,"children":5037},{"style":777},[5038],{"type":43,"value":5039},"inv_distances ",{"type":37,"tag":758,"props":5041,"children":5042},{"style":835},[5043],{"type":43,"value":854},{"type":37,"tag":758,"props":5045,"children":5046},{"style":1296},[5047],{"type":43,"value":3723},{"type":37,"tag":758,"props":5049,"children":5050},{"style":835},[5051],{"type":43,"value":3728},{"type":37,"tag":758,"props":5053,"children":5054},{"style":777},[5055],{"type":43,"value":3733},{"type":37,"tag":758,"props":5057,"children":5058},{"class":760,"line":803},[5059,5063],{"type":37,"tag":758,"props":5060,"children":5061},{"style":2853},[5062],{"type":43,"value":2856},{"type":37,"tag":758,"props":5064,"children":5065},{"style":777},[5066],{"type":43,"value":5067},"(inv_distances)\n",{"type":37,"tag":758,"props":5069,"children":5070},{"class":760,"line":812},[5071],{"type":37,"tag":758,"props":5072,"children":5073},{"emptyLinePlaceholder":32},[5074],{"type":43,"value":2597},{"type":37,"tag":758,"props":5076,"children":5077},{"class":760,"line":820},[5078,5083,5088,5092,5097,5101,5106],{"type":37,"tag":758,"props":5079,"children":5080},{"style":777},[5081],{"type":43,"value":5082},"array([[",{"type":37,"tag":758,"props":5084,"children":5085},{"style":1296},[5086],{"type":43,"value":5087},"1.00000000e+05",{"type":37,"tag":758,"props":5089,"children":5090},{"style":777},[5091],{"type":43,"value":2986},{"type":37,"tag":758,"props":5093,"children":5094},{"style":1296},[5095],{"type":43,"value":5096},"2.03069233e-01",{"type":37,"tag":758,"props":5098,"children":5099},{"style":777},[5100],{"type":43,"value":2986},{"type":37,"tag":758,"props":5102,"children":5103},{"style":1296},[5104],{"type":43,"value":5105},"9.88936353e-02",{"type":37,"tag":758,"props":5107,"children":5108},{"style":777},[5109],{"type":43,"value":4915},{"type":37,"tag":758,"props":5111,"children":5112},{"class":760,"line":867},[5113,5117,5121,5125,5129,5133,5138],{"type":37,"tag":758,"props":5114,"children":5115},{"style":777},[5116],{"type":43,"value":4957},{"type":37,"tag":758,"props":5118,"children":5119},{"style":1296},[5120],{"type":43,"value":5096},{"type":37,"tag":758,"props":5122,"children":5123},{"style":777},[5124],{"type":43,"value":2986},{"type":37,"tag":758,"props":5126,"children":5127},{"style":1296},[5128],{"type":43,"value":5087},{"type":37,"tag":758,"props":5130,"children":5131},{"style":777},[5132],{"type":43,"value":2986},{"type":37,"tag":758,"props":5134,"children":5135},{"style":1296},[5136],{"type":43,"value":5137},"1.92450090e-01",{"type":37,"tag":758,"props":5139,"children":5140},{"style":777},[5141],{"type":43,"value":4915},{"type":37,"tag":758,"props":5143,"children":5144},{"class":760,"line":905},[5145,5149,5153,5157,5161,5165,5169],{"type":37,"tag":758,"props":5146,"children":5147},{"style":777},[5148],{"type":43,"value":4957},{"type":37,"tag":758,"props":5150,"children":5151},{"style":1296},[5152],{"type":43,"value":5105},{"type":37,"tag":758,"props":5154,"children":5155},{"style":777},[5156],{"type":43,"value":2986},{"type":37,"tag":758,"props":5158,"children":5159},{"style":1296},[5160],{"type":43,"value":5137},{"type":37,"tag":758,"props":5162,"children":5163},{"style":777},[5164],{"type":43,"value":2986},{"type":37,"tag":758,"props":5166,"children":5167},{"style":1296},[5168],{"type":43,"value":5087},{"type":37,"tag":758,"props":5170,"children":5171},{"style":777},[5172],{"type":43,"value":4361},{"type":37,"tag":46,"props":5174,"children":5175},{},[5176],{"type":43,"value":5177},"The next step is the most elegant part of the simulation and really flexes the GPU's parallel compute capabilities:",{"type":37,"tag":212,"props":5179,"children":5181},{"code":5180,"language":751,"meta":8,"className":752,"style":8},"cp_forces = cp.sum((diff.T * inv_distances**3).T, axis=1)\n",[5182],{"type":37,"tag":160,"props":5183,"children":5184},{"__ignoreMap":8},[5185],{"type":37,"tag":758,"props":5186,"children":5187},{"class":760,"line":761},[5188,5193,5197,5201,5205,5209,5213,5217,5221,5225,5229,5233],{"type":37,"tag":758,"props":5189,"children":5190},{"style":777},[5191],{"type":43,"value":5192},"cp_forces ",{"type":37,"tag":758,"props":5194,"children":5195},{"style":835},[5196],{"type":43,"value":854},{"type":37,"tag":758,"props":5198,"children":5199},{"style":777},[5200],{"type":43,"value":3768},{"type":37,"tag":758,"props":5202,"children":5203},{"style":835},[5204],{"type":43,"value":3773},{"type":37,"tag":758,"props":5206,"children":5207},{"style":777},[5208],{"type":43,"value":3778},{"type":37,"tag":758,"props":5210,"children":5211},{"style":835},[5212],{"type":43,"value":3644},{"type":37,"tag":758,"props":5214,"children":5215},{"style":1296},[5216],{"type":43,"value":3787},{"type":37,"tag":758,"props":5218,"children":5219},{"style":777},[5220],{"type":43,"value":3792},{"type":37,"tag":758,"props":5222,"children":5223},{"style":846},[5224],{"type":43,"value":3458},{"type":37,"tag":758,"props":5226,"children":5227},{"style":835},[5228],{"type":43,"value":854},{"type":37,"tag":758,"props":5230,"children":5231},{"style":1296},[5232],{"type":43,"value":3805},{"type":37,"tag":758,"props":5234,"children":5235},{"style":777},[5236],{"type":43,"value":864},{"type":37,"tag":46,"props":5238,"children":5239},{},[5240,5242,5248],{"type":43,"value":5241},"The ",{"type":37,"tag":160,"props":5243,"children":5245},{"className":5244},[],[5246],{"type":43,"value":5247},".T",{"type":43,"value":5249}," operation transposes a matrix, multiplies by the cube of inverse distances, then transposes the matrix again before summing along the first axis. Transposing a matrix basically swaps rows and columns.",{"type":37,"tag":46,"props":5251,"children":5252},{},[5253],{"type":43,"value":5254},"The next two steps are also pretty elegant:",{"type":37,"tag":212,"props":5256,"children":5258},{"code":5257,"language":751,"meta":8,"className":752,"style":8},"# update velocities and positions\ncp_velocities += DT * cp_forces\ncp_positions += DT * cp_velocities\n",[5259],{"type":37,"tag":160,"props":5260,"children":5261},{"__ignoreMap":8},[5262,5270,5293],{"type":37,"tag":758,"props":5263,"children":5264},{"class":760,"line":761},[5265],{"type":37,"tag":758,"props":5266,"children":5267},{"style":3227},[5268],{"type":43,"value":5269},"# update velocities and positions\n",{"type":37,"tag":758,"props":5271,"children":5272},{"class":760,"line":502},[5273,5277,5281,5285,5289],{"type":37,"tag":758,"props":5274,"children":5275},{"style":777},[5276],{"type":43,"value":3418},{"type":37,"tag":758,"props":5278,"children":5279},{"style":835},[5280],{"type":43,"value":3840},{"type":37,"tag":758,"props":5282,"children":5283},{"style":1296},[5284],{"type":43,"value":3845},{"type":37,"tag":758,"props":5286,"children":5287},{"style":835},[5288],{"type":43,"value":3850},{"type":37,"tag":758,"props":5290,"children":5291},{"style":777},[5292],{"type":43,"value":3855},{"type":37,"tag":758,"props":5294,"children":5295},{"class":760,"line":803},[5296,5300,5304,5308,5312],{"type":37,"tag":758,"props":5297,"children":5298},{"style":777},[5299],{"type":43,"value":3400},{"type":37,"tag":758,"props":5301,"children":5302},{"style":835},[5303],{"type":43,"value":3840},{"type":37,"tag":758,"props":5305,"children":5306},{"style":1296},[5307],{"type":43,"value":3845},{"type":37,"tag":758,"props":5309,"children":5310},{"style":835},[5311],{"type":43,"value":3850},{"type":37,"tag":758,"props":5313,"children":5314},{"style":777},[5315],{"type":43,"value":3881},{"type":37,"tag":46,"props":5317,"children":5318},{},[5319,5321,5326],{"type":43,"value":5320},"In the last step I append the updated positions to an array that holds every \"tick\" (the positions of each particle between each time interval, ",{"type":37,"tag":160,"props":5322,"children":5324},{"className":5323},[],[5325],{"type":43,"value":3294},{"type":43,"value":5327}," - \"delta time\")",{"type":37,"tag":46,"props":5329,"children":5330},{},[5331],{"type":43,"value":5332},"Here's the formula for the mathematical equation used to calculate the force on any given body in an n-body system:",{"type":37,"tag":2274,"props":5334,"children":5337},{"src":5335,"width":2276,"height":5336},"https://briancaffey.github.io/three-body-problem/iframe/formula.html",110,[],{"type":37,"tag":46,"props":5339,"children":5340},{},[5341],{"type":43,"value":5342},"To test that the simulation was working correctly I used ChatGPT again to construct a 3D scene in Blender with a Python script:",{"type":37,"tag":46,"props":5344,"children":5345},{},[5346],{"type":37,"tag":172,"props":5347,"children":5350},{"alt":5348,"src":5349},"Blender Animation","/static/three-body-problem/blender.png",[],{"type":37,"tag":698,"props":5352,"children":5354},{"id":5353},"threejs",[5355],{"type":43,"value":5356},"Three.js",{"type":37,"tag":46,"props":5358,"children":5359},{},[5360],{"type":43,"value":5361},"Imagine that we are working for a Chinese startup called the Qin Dynasty. The founder, Qin Shi Huang, is a brutal tyrant with an obsessive fear of assassination. Let's put on our product hat for a minute and think about how we can impress him with a clean solution to the three-body problem. A recent attempt involved building a 30,000-person analog computer that was destroyed in tri-solar syzygy. Failing to accurately predict the movement of the suns could mean execution by live-burial, a fiery death or worse. Using CUDA and Blender is a good MVP but doesn't make for the best technical demo since it involves so many different steps: running the simulation in CUDA, exporting data to JSON, loading data into a visualuzation and then finally rendering a video of the simulation. With a popular Javascript library called Three.js we can run an interactive three-body problem simulation in real-time right in the browser. Here's the three-body simulation I also co-authored with ChatGPT-4 using Three.js:",{"type":37,"tag":2274,"props":5363,"children":5366},{"src":5364,"width":2276,"height":5365},"https://briancaffey.github.io/three-body-problem/three/",350,[],{"type":37,"tag":38,"props":5368,"children":5370},{"id":5369},"screen-adaptations-the-gaming-industry-and-the-ccp",[5371],{"type":43,"value":5372},"Screen adaptations, the gaming industry and the CCP",{"type":37,"tag":46,"props":5374,"children":5375},{},[5376],{"type":43,"value":5377},"Dream of the Red Chamber is one of China's Four Great Classical Novels and is often seen as the pinacle of Chinese fiction. It was written in the mid 18th century and first published in 1791. It is a long saga that totals 960,000 characters in length, on similar scale to the length of the Three-Body Problem trilogy. Sun Wen, a Qing dynasty artist, spent 36 years of his life doing a series of 230 paintings depicting scenes from the Dream of the Red Chamber: dream sequences, demons, goddesses, nuns, nobles, beggars, raging fires, landscapes, interiors, wildlife, gardens, temples, funerals, battles, processions, banquets, trials, operas, marriages.",{"type":37,"tag":46,"props":5379,"children":5380},{},[5381],{"type":37,"tag":172,"props":5382,"children":5385},{"alt":5383,"src":5384},"Sun Wen paintings sample","/static/three-body-problem/dorc.png",[],{"type":37,"tag":46,"props":5387,"children":5388},{},[5389],{"type":43,"value":5390},"Following in this tradition of celebrating great literature, Tencent Video and China Central Television produced a 30-episode adaptation of the Three-Body Problem that was released in Feburary 2023. It is a surprisingly faithful reproduction of the book that is worth checking out. The portrayal of Shi Qiang (Da Shi) was easily my favorite part of the series. I was also impressed by how the Three-Body VR game scenes were done with computer graphics. It got me thinking about how China is represented in some of the worlds most popular video games.",{"type":37,"tag":46,"props":5392,"children":5393},{},[5394],{"type":37,"tag":172,"props":5395,"children":5398},{"alt":5396,"src":5397},"games","/static/three-body-problem/game.png",[],{"type":37,"tag":46,"props":5400,"children":5401},{},[5402],{"type":43,"value":5403},"This is Rocket League, a competitive vehicular soccer game where players, like in the Three-Body game, must master the laws of gravity. The Chinese-themed Forbiden Temple arena shown here is one of many virtual international venues in the game. Epic Games (creator of Fortnite) bought Rocket League in 2019 for an estimated $250 to $300 million.",{"type":37,"tag":46,"props":5405,"children":5406},{},[5407],{"type":43,"value":5408},"Like Rocket League, Overwatch is a highly-competitive eSport on a global scale. It features a large roster of 38 players from all over the world. Dr. Mei-Ling Zhou (Âë®ÁæéÁÅµ) is a Chinese climatologist who uses ice both to attack opponents and to defend herself. Mei became controversial in China due to her adoption as a symbolic figure in the 2019 Hong Kong protests.",{"type":37,"tag":46,"props":5410,"children":5411},{},[5412],{"type":43,"value":5413},"Three college friends combined their interest in anime, comics and games (ACG) and literature to publish one of the most successful games created by a Chinese company and arguably one of China's most important cultural exports: Genshin Impact. miHoYo, the Shanghai-based company that develops Genshin Impact, grossed $4 billion of revenue globally in the game's first year setting a new record in the gaming industry. Like other companies of its size, miHoYo has a party committee under the Chinese Communist Party that influences the company's operations.",{"type":37,"tag":38,"props":5415,"children":5417},{"id":5416},"ai-and-layoffs-in-the-tech-industry",[5418],{"type":43,"value":5419},"AI and layoffs in the tech industry",{"type":37,"tag":46,"props":5421,"children":5422},{},[5423,5425,5432],{"type":43,"value":5424},"I have a positive attitude toward AI and its ability to supercharge the creative work we do, but I also think that replacing humans and AI-related layoffs should should be a part of the conversation. I wasn't impacted by the recent round of layoffs at my company, and I'm grateful to have the opportunity to work with a talented team on interesting problems in the health tech industry. I do have some solid references for folks in DevOps, product and backend and frontend engineering, and I‚Äôm happy to ",{"type":37,"tag":52,"props":5426,"children":5429},{"href":5427,"rel":5428},"https://www.linkedin.com/in/brian-caffey-06b22a18/",[56],[5430],{"type":43,"value":5431},"connect and share via LinkedIn",{"type":43,"value":61},{"type":37,"tag":46,"props":5434,"children":5435},{},[5436],{"type":43,"value":5437},"Layoffs in both China and the U.S. have been pummled the tech sector over the last two years. New graduates in China are also facing a difficult job market. There are some popular expressions that paint a picture of the job market in China:",{"type":37,"tag":640,"props":5439,"children":5440},{},[5441,5446,5451,5463,5477],{"type":37,"tag":644,"props":5442,"children":5443},{},[5444],{"type":43,"value":5445},"Ë∫∫Âπ≥ Lying flat: avoiding relentless work",{"type":37,"tag":644,"props":5447,"children":5448},{},[5449],{"type":43,"value":5450},"‰πù‰πùÂÖ≠ 996 Work culture: describes working from 9AM to 9PM, 6 days a week, a common work schedule for many Chinese employees",{"type":37,"tag":644,"props":5452,"children":5453},{},[5454,5456],{"type":43,"value":5455},"ÂÖ®ËÅåÂÑøÂ•≥ Full-time Children: ",{"type":37,"tag":52,"props":5457,"children":5460},{"href":5458,"rel":5459},"https://www.cnn.com/2023/07/26/economy/china-youth-unemployment-intl-hnk/index.html",[56],[5461],{"type":43,"value":5462},"Young Chinese are getting paid to be ‚Äòfull-time children‚Äô as jobs become harder to find",{"type":37,"tag":644,"props":5464,"children":5465},{},[5466,5468,5475],{"type":43,"value":5467},"35Â≤ÅËØÖÂíí The curse of 35: ",{"type":37,"tag":52,"props":5469,"children":5472},{"href":5470,"rel":5471},"https://www.marketplace.org/shows/marketplace-tech/chinas-tech-workers-ageism-the-curse-of-35/",[56],[5473],{"type":43,"value":5474},"Ageism in China‚Äôs tech sector has workers fearing the ‚Äúcurse of 35‚Äù",{"type":43,"value":5476},". Shout out to my fellow Year of the Dragon 35 year olds! üê≤",{"type":37,"tag":644,"props":5478,"children":5479},{},[5480,5482],{"type":43,"value":5481},"ÂêÉËã¶ Eat Bitterness: ",{"type":37,"tag":52,"props":5483,"children":5486},{"href":5484,"rel":5485},"https://www.nytimes.com/2023/05/30/business/china-youth-unemployment.html",[56],[5487],{"type":43,"value":5488},"China‚Äôs Young People Can‚Äôt Find Jobs. Xi Jinping Says to ‚ÄòEat Bitterness.‚Äô",{"type":37,"tag":46,"props":5490,"children":5491},{},[5492,5494,5501],{"type":43,"value":5493},"It is an exciting time for AI. Elon Musk and Kaifu Lee have both recently released open-source large language models: Grok and Yi. Sam Altman was fired as CEO of OpenAI, then came back. Stable Diffusion just released a text to video model. AGI might already be here. In the U.S., we are going into our first presidential election cycle with AI fully turned on. Here's a ",{"type":37,"tag":52,"props":5495,"children":5498},{"href":5496,"rel":5497},"https://www.amazon.com/Three-Body-Problem-Cixin-Liu/dp/0765382032",[56],[5499],{"type":43,"value":5500},"link to The Three-Body Problem book on Amazon",{"type":43,"value":5502},". Thanks for reading and Happy Thanksgiving!",{"type":37,"tag":46,"props":5504,"children":5505},{},[5506],{"type":37,"tag":172,"props":5507,"children":5510},{"alt":5508,"src":5509},"Happy Thanksgiving","/static/three-body-problem/thanksgiving.png",[],{"type":37,"tag":2080,"props":5512,"children":5513},{},[5514],{"type":43,"value":2084},{"title":8,"searchDepth":502,"depth":502,"links":5516},[5517,5518,5521,5522,5525,5526,5530,5531],{"id":2198,"depth":502,"text":2201},{"id":2290,"depth":502,"text":2293,"children":5519},[5520],{"id":2362,"depth":803,"text":2365},{"id":2395,"depth":502,"text":2398},{"id":2455,"depth":502,"text":2458,"children":5523},[5524],{"id":2527,"depth":803,"text":2530},{"id":3070,"depth":502,"text":3073},{"id":3120,"depth":502,"text":3123,"children":5527},[5528,5529],{"id":3131,"depth":803,"text":3134},{"id":5353,"depth":803,"text":5356},{"id":5369,"depth":502,"text":5372},{"id":5416,"depth":502,"text":5419},"content:2023:08:27:python-vue-chinese-llama-2-and-the-three-body-problem.md","2023/08/27/python-vue-chinese-llama-2-and-the-three-body-problem.md","2023/08/27/python-vue-chinese-llama-2-and-the-three-body-problem",1723329673065]