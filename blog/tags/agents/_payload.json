[{"data":1,"prerenderedAt":5535},["ShallowReactive",2],{"/blog/tags/agents/":3},[4,3624,4055],{"_path":5,"_dir":6,"_draft":7,"_partial":7,"_locale":8,"title":9,"description":10,"date":11,"image":12,"tags":13,"draft":7,"external":20,"comments":24,"body":25,"_type":3618,"_id":3619,"_source":3620,"_file":3621,"_stem":3622,"_extension":3623},"/2025/05/27/mediation-simulator-project-for-nvidia-agent-intelligence-toolkit","27",false,"","Mediation Simulator: My submission for the NVIDIA Agent Intelligence Toolkit Hackathon","Mediation Simulator is an AI application designed to help legal students and professionals build dispute resolution skills through simulated mediation sessions","2025-05-27","/static/mediation-simulator/mediation_simulator_title_image.png",[14,15,16,17,18,19],"nvidia","ai","agents","llm","nim","mediation",[21],{"link":22,"site":23},"https://x.com/briancaffey/status/1926036369597510117","x",true,{"type":26,"children":27,"toc":3599},"root",[28,37,51,66,70,77,82,87,122,129,134,168,173,188,197,212,220,226,231,307,313,318,435,448,453,461,467,472,477,484,497,503,508,513,1961,1973,1981,1986,1994,1999,2007,2015,2020,2028,2033,2041,2046,2795,2808,2816,2821,2982,2990,2995,3003,3008,3082,3087,3095,3100,3105,3110,3505,3510,3518,3523,3528,3533,3566,3571,3577,3582,3588,3593],{"type":29,"tag":30,"props":31,"children":33},"element","h1",{"id":32},"building-mediation-simulator-for-the-nvidia-agent-intelligence-toolkit-hackathon",[34],{"type":35,"value":36},"text","Building Mediation Simulator for the NVIDIA Agent Intelligence Toolkit Hackathon!",{"type":29,"tag":38,"props":39,"children":40},"p",{},[41,43,49],{"type":35,"value":42},"I'm excited to share a project I've been building for the NVIDIA Agent Intelligence Toolkit Hackathon: ",{"type":29,"tag":44,"props":45,"children":46},"strong",{},[47],{"type":35,"value":48},"Mediation Simulator",{"type":35,"value":50},"! The NVIDIA Agent Intelligence Toolkit (or AgentIQ Toolkit, as it's often called) is a powerful open-source library designed for connecting, evaluating, and accelerating teams of AI agents. My goal? To see if I could leverage this toolkit to build AI agent teams capable of simulating the entire, complex process of a law school mediation competition.",{"type":29,"tag":38,"props":52,"children":53},{},[54,56,64],{"type":35,"value":55},"Check out my ",{"type":29,"tag":57,"props":58,"children":61},"a",{"href":22,"rel":59},[60],"nofollow",[62],{"type":35,"value":63},"ùïè Post",{"type":35,"value":65}," that introduces the project:",{"type":29,"tag":67,"props":68,"children":69},"mediation-simulator-tweet",{},[],{"type":29,"tag":71,"props":72,"children":74},"h2",{"id":73},"what-is-mediation-simulator-and-why-mediation",[75],{"type":35,"value":76},"What is Mediation Simulator? And Why Mediation?",{"type":29,"tag":38,"props":78,"children":79},{},[80],{"type":35,"value":81},"At its core, Mediation Simulator is my attempt to model the nuanced, semi-structured, three-way conversations that happen in mediation. Law school mediation tournaments are events where students practice negotiation and dispute resolution skills. This seemed like a really interesting challenge! How do you get language models to effectively navigate such a dynamic environment?",{"type":29,"tag":38,"props":83,"children":84},{},[85],{"type":35,"value":86},"Mediation competitions also present some unique data challenges that are perfect for AI:",{"type":29,"tag":88,"props":89,"children":90},"ul",{},[91,102,112],{"type":29,"tag":92,"props":93,"children":94},"li",{},[95,100],{"type":29,"tag":44,"props":96,"children":97},{},[98],{"type":35,"value":99},"Layered Information:",{"type":35,"value":101}," There are \"common facts\" known to everyone, and \"confidential facts\" privy only to one party (and sometimes shared strategically with the mediator or the other side).",{"type":29,"tag":92,"props":103,"children":104},{},[105,110],{"type":29,"tag":44,"props":106,"children":107},{},[108],{"type":35,"value":109},"Dynamic Conversations:",{"type":35,"value":111}," The main discussion involves all three parties (mediator and two disputants), but it also features \"caucuses\"‚Äîprivate, two-way conversations between the mediator and one party.",{"type":29,"tag":92,"props":113,"children":114},{},[115,120],{"type":29,"tag":44,"props":116,"children":117},{},[118],{"type":35,"value":119},"Creative Scenarios:",{"type":35,"value":121}," The cases are entirely fictional, often involving made-up companies, fictional countries, and even fictional currencies! This is a deliberate choice to help students avoid real-world biases. And guess what? AI is really good at generating fake data!",{"type":29,"tag":123,"props":124,"children":126},"h3",{"id":125},"what-i-built",[127],{"type":35,"value":128},"What I built",{"type":29,"tag":38,"props":130,"children":131},{},[132],{"type":35,"value":133},"Mediation Simulator consists of three main components:",{"type":29,"tag":135,"props":136,"children":137},"ol",{},[138,148,158],{"type":29,"tag":92,"props":139,"children":140},{},[141,146],{"type":29,"tag":44,"props":142,"children":143},{},[144],{"type":35,"value":145},"Case Generation Workflow",{"type":35,"value":147},": A CLI tool that uses LLMs to generate realistic mediation case scenarios, complete with common facts, confidential information for each party, and supporting documents. This workflow creates the foundation for all mediation simulations. The data for the case scenarios is saved in both YAML files and in my Redis database. I'll talk about why I did chose to store data in local files and on Redis later in this article.",{"type":29,"tag":92,"props":149,"children":150},{},[151,156],{"type":29,"tag":44,"props":152,"children":153},{},[154],{"type":35,"value":155},"Automated Mediation Workflow",{"type":35,"value":157},": Another CLI tool that orchestrates a full mediation session between three AI agents (mediator, requesting party, and responding party). This workflow simulates the entire mediation process, from opening statements through negotiation to conclusion, with the AI agents engaging in realistic dialogue based on their roles and the case information. A clerk agent helps to guide the converstaion, controlling who the next speaker should be based on a summary of what has already been said by different parties.",{"type":29,"tag":92,"props":159,"children":160},{},[161,166],{"type":29,"tag":44,"props":162,"children":163},{},[164],{"type":35,"value":165},"Interactive Mediation API",{"type":35,"value":167},": A REST API that allows a human user to participate in a mediation session by taking on the role of either the requesting or responding party. The API manages the session state and coordinates the interaction between the human participant and the AI mediator and opposing party. The conversation history for the mediation session is stored in Redis using a memory backend that I implemented with NVIDIA Agent Intelligence Toolkit.",{"type":29,"tag":38,"props":169,"children":170},{},[171],{"type":35,"value":172},"To make the results of these workflows easily viewable, I also built two web interfaces:",{"type":29,"tag":88,"props":174,"children":175},{},[176],{"type":29,"tag":92,"props":177,"children":178},{},[179,181,186],{"type":35,"value":180},"A ",{"type":29,"tag":44,"props":182,"children":183},{},[184],{"type":35,"value":185},"Viewer Interface",{"type":35,"value":187}," that displays the full three-party dialogue from automated mediation sessions, making it easy to review and analyze the AI agents' interactions.",{"type":29,"tag":38,"props":189,"children":190},{},[191],{"type":29,"tag":192,"props":193,"children":196},"img",{"alt":194,"src":195},"Mediation Simulator Viewer","/static/mediation-simulator/mediation_simulator_viewer.png",[],{"type":29,"tag":88,"props":198,"children":199},{},[200],{"type":29,"tag":92,"props":201,"children":202},{},[203,205,210],{"type":35,"value":204},"An ",{"type":29,"tag":44,"props":206,"children":207},{},[208],{"type":35,"value":209},"Interactive Interface",{"type":35,"value":211}," that provides a chat-like experience for human participants in the interactive mediation mode, with real-time updates and a clean, intuitive design.",{"type":29,"tag":38,"props":213,"children":214},{},[215],{"type":29,"tag":192,"props":216,"children":219},{"alt":217,"src":218},"Mediation Simulator Interactive","/static/mediation-simulator/interactive_mediation_screenshot.png",[],{"type":29,"tag":123,"props":221,"children":223},{"id":222},"the-genesis-from-idea-to-data",[224],{"type":35,"value":225},"The Genesis: From Idea to Data",{"type":29,"tag":38,"props":227,"children":228},{},[229],{"type":35,"value":230},"The first major hurdle was generating the foundational case data. Here's how that unfolded:",{"type":29,"tag":135,"props":232,"children":233},{},[234,244,254,264,297],{"type":29,"tag":92,"props":235,"children":236},{},[237,242],{"type":29,"tag":44,"props":238,"children":239},{},[240],{"type":35,"value":241},"Deep Dive Research:",{"type":35,"value":243}," I started by brainstorming with an LLM (OpenAI's o3, in this case) to get a comprehensive understanding of law school mediation competitions. I wanted to know everything: the rules, structure, participants, judging criteria and different types of cases.",{"type":29,"tag":92,"props":245,"children":246},{},[247,252],{"type":29,"tag":44,"props":248,"children":249},{},[250],{"type":35,"value":251},"Prompt Engineering for Cases:",{"type":35,"value":253}," With that knowledge, I tasked another LLM (GPT-4o) with generating prompts to be used for creating diverse and realistic (albeit fictional) mediation case scenarios.",{"type":29,"tag":92,"props":255,"children":256},{},[257,262],{"type":29,"tag":44,"props":258,"children":259},{},[260],{"type":35,"value":261},"Case Generation:",{"type":35,"value":263}," Using these prompts, I generated sets of distinct cases facts and related documents.",{"type":29,"tag":92,"props":265,"children":266},{},[267,272,274],{"type":29,"tag":44,"props":268,"children":269},{},[270],{"type":35,"value":271},"Structuring with LangGraph:",{"type":35,"value":273}," To manage the data for each case, I used LangGraph. I designed a state object to encapsulate all crucial elements:\n",{"type":29,"tag":88,"props":275,"children":276},{},[277,282,287],{"type":29,"tag":92,"props":278,"children":279},{},[280],{"type":35,"value":281},"Common facts.",{"type":29,"tag":92,"props":283,"children":284},{},[285],{"type":35,"value":286},"Confidential facts for both the requesting and responding parties.",{"type":29,"tag":92,"props":288,"children":289},{},[290,295],{"type":29,"tag":44,"props":291,"children":292},{},[293],{"type":35,"value":294},"Related Documents!",{"type":35,"value":296}," This was my own little twist. I wanted to test RAG (Retrieval Augmented Generation) integration within the agentic workflow. Could parties use tools to search for information in these documents to bolster their arguments during mediation? Ultimately I couldn't really get this to work. I'll share more on why later in this article.",{"type":29,"tag":92,"props":298,"children":299},{},[300,305],{"type":29,"tag":44,"props":301,"children":302},{},[303],{"type":35,"value":304},"Data Persistence:",{"type":35,"value":306}," With the data structured, I saved it in accessible formats: the LangGraph state was serialized to YAML, and the case details (like facts and documents) were stored in Markdown files. I also stored same LangGraph state to Redis using a simple JSON string.",{"type":29,"tag":123,"props":308,"children":310},{"id":309},"orchestrating-the-simulation",[311],{"type":35,"value":312},"Orchestrating the Simulation",{"type":29,"tag":38,"props":314,"children":315},{},[316],{"type":35,"value":317},"With the case data ready, the next step was to build out the mediation simulation itself:",{"type":29,"tag":135,"props":319,"children":320},{},[321,359,406,416],{"type":29,"tag":92,"props":322,"children":323},{},[324,329,331],{"type":29,"tag":44,"props":325,"children":326},{},[327],{"type":35,"value":328},"Defining the Flow:",{"type":35,"value":330}," I broke down the mediation process into its typical phases:\n",{"type":29,"tag":88,"props":332,"children":333},{},[334,339,344,349,354],{"type":29,"tag":92,"props":335,"children":336},{},[337],{"type":35,"value":338},"Opening Statements",{"type":29,"tag":92,"props":340,"children":341},{},[342],{"type":35,"value":343},"Information Gathering",{"type":29,"tag":92,"props":345,"children":346},{},[347],{"type":35,"value":348},"Caucuses (for each party)",{"type":29,"tag":92,"props":350,"children":351},{},[352],{"type":35,"value":353},"Negotiation",{"type":29,"tag":92,"props":355,"children":356},{},[357],{"type":35,"value":358},"Conclusion",{"type":29,"tag":92,"props":360,"children":361},{},[362,367,369],{"type":29,"tag":44,"props":363,"children":364},{},[365],{"type":35,"value":366},"Assembling the Agent Team:",{"type":35,"value":368}," I set up a LangGraph graph consisting of:\n",{"type":29,"tag":88,"props":370,"children":371},{},[372,383,395],{"type":29,"tag":92,"props":373,"children":374},{},[375,376,381],{"type":35,"value":180},{"type":29,"tag":44,"props":377,"children":378},{},[379],{"type":35,"value":380},"Mediator",{"type":35,"value":382}," agent",{"type":29,"tag":92,"props":384,"children":385},{},[386,388,393],{"type":35,"value":387},"Two ",{"type":29,"tag":44,"props":389,"children":390},{},[391],{"type":35,"value":392},"Party",{"type":35,"value":394}," agents (Requesting and Responding parties)",{"type":29,"tag":92,"props":396,"children":397},{},[398,399,404],{"type":35,"value":180},{"type":29,"tag":44,"props":400,"children":401},{},[402],{"type":35,"value":403},"Clerk",{"type":35,"value":405}," agent, whose job is to help manage the conversation flow and transition the simulation between the different phases.",{"type":29,"tag":92,"props":407,"children":408},{},[409,414],{"type":29,"tag":44,"props":410,"children":411},{},[412],{"type":35,"value":413},"Dynamic Prompting:",{"type":35,"value":415}," The prompts for the mediator and the parties (both when initiating a statement and when responding) change significantly based on the current phase of the mediation. Critically, these prompts also dynamically include a summary log of what has already been said, providing context.",{"type":29,"tag":92,"props":417,"children":418},{},[419,424,426,433],{"type":29,"tag":44,"props":420,"children":421},{},[422],{"type":35,"value":423},"Message Logging:",{"type":35,"value":425}," Each time a party speaks, I store the message using my Redis backend and also store additional metadata in the ",{"type":29,"tag":427,"props":428,"children":430},"code",{"className":429},[],[431],{"type":35,"value":432},"additional_kwargs",{"type":35,"value":434}," section of each message, such as the speaker, the current phase of mediation and a summary of the message (the summary is generated by another LLM call that just summarizes the response.)",{"type":29,"tag":38,"props":436,"children":437},{},[438,440,446],{"type":35,"value":439},"Getting to a functional mediation workflow was crucial! It allowed me to see the actual dialogue unfold and immediately highlighted areas for improvement. For instance, I realized that prompts needed to guide parties to ask one clear question at a time, directed at a specific participant, rather than posing multiple questions to several people at once. This really helps keep the simulated conversation straightforward and more realistic. I also had to instruct the LLM to use the names of the differnt parties, and I had to provide the names of the parties to the prompt. Without this instruction the LLM would give responses like this: \"Hello ",{"type":29,"tag":441,"props":442,"children":443},"span",{},[444],{"type":35,"value":445},"Requesting Party Name",{"type":35,"value":447},", thank you for sharing your opinion.\"",{"type":29,"tag":38,"props":449,"children":450},{},[451],{"type":35,"value":452},"Here's a look at the main workflow generated from the LangGraph code:",{"type":29,"tag":38,"props":454,"children":455},{},[456],{"type":29,"tag":192,"props":457,"children":460},{"alt":458,"src":459},"Mediation Simulator Workflow with LangGraph","/static/mediation-simulator/mediation_workflow.png",[],{"type":29,"tag":123,"props":462,"children":464},{"id":463},"bringing-it-to-life-the-vibe-coding-web-viewer",[465],{"type":35,"value":466},"Bringing it to Life: The \"Vibe Coding\" Web Viewer!",{"type":29,"tag":38,"props":468,"children":469},{},[470],{"type":35,"value":471},"Reading through raw Markdown files or terminal output to follow a complex, multi-turn mediation isn't ideal. I needed a better way to visualize the results! And this is where a bit of \"vibe coding\" came in incredibly handy.",{"type":29,"tag":38,"props":473,"children":474},{},[475],{"type":35,"value":476},"I prompted an LLM to generate a single HTML page using Vue.js and Tailwind CSS. My requirements were simple: list all generated mediation cases, and when a case is selected, display the full dialogue. The amazing part? I never actually looked at the generated code in detail! I was able to make incremental improvements by simply describing changes or new features I wanted, and the LLM iterated until it was almost exactly what I envisioned. This was super easy and fast! I also made a page that lists all of the different mediation sessions with cover images that I generated with the NVIDIA Flux.1 Dev NIM:",{"type":29,"tag":38,"props":478,"children":479},{},[480],{"type":29,"tag":192,"props":481,"children":483},{"alt":194,"src":482},"/static/mediation-simulator/viewer.png",[],{"type":29,"tag":38,"props":485,"children":486},{},[487,489,495],{"type":35,"value":488},"Having this simple web interface has been a game-changer for reviewing simulations. Plus, keeping it in my project repository means I can easily host it on GitHub Pages at ",{"type":29,"tag":427,"props":490,"children":492},{"className":491},[],[493],{"type":35,"value":494},"briancaffey.github.io/mediation-simulator",{"type":35,"value":496}," to share the results of my project. It's just so much better than staring at text files, and took just a few minutes to put together.",{"type":29,"tag":71,"props":498,"children":500},{"id":499},"a-deeper-look-into-the-nvidia-agent-intelligence-toolkit",[501],{"type":35,"value":502},"A deeper look into the NVIDIA Agent Intelligence Toolkit",{"type":29,"tag":38,"props":504,"children":505},{},[506],{"type":35,"value":507},"Now, I know what some developers think about LLM frameworks like LangChain/LangGraph, LlamaIndex, and CrewAI‚Äîthere's often a bit of \"framework fatigue.\" But hear me out! The NVIDIA Agent Intelligence Toolkit brings all of these Frameworks together in a manageable way and it makes it really easy to not only write an agentic program, but it also makes it really easy to read other programs written with the framework.",{"type":29,"tag":38,"props":509,"children":510},{},[511],{"type":35,"value":512},"The key to understanding the AIQ Toolkit is the config files. These are YAML files that neatly list out all of the dependencies of your agentic application. Let's take a look at the config file I made for mediation simulator. It's a long file, so I'll share it and then break down the important sections:",{"type":29,"tag":514,"props":515,"children":519},"pre",{"code":516,"language":517,"meta":8,"className":518,"style":8},"general:\n  use_uvloop: true\n  front_end:\n    _type: fastapi\n    cors:\n      allow_origins: ['*']\n      allow_methods:\n        - GET\n        - POST\n        - OPTIONS\n    endpoints:\n      - path: /case/{case_id}\n        method: GET\n        description: Gets the mediation case for the given case ID.\n        function_name: get_mediation_case\n      - path: /case/{case_id}/session/{session_id}\n        method: GET\n        description: Gets the mediation session data for the given case ID and session ID.\n        function_name: get_mediation_session\n      - path: /case/{case_id}/session/{session_id}/send\n        method: POST\n        description: Sends a message to the mediation session for the given case ID and session ID.\n        function_name: send_message_to_mediation_session\n  telemetry:\n    enabled: false\n    tracing:\n      phoenix:\n        _type: phoenix\n        endpoint: http://localhost:6006/v1/traces\n        project: default\n\nretrievers:\n  milvus_retriever:\n    _type: milvus_retriever\n    uri: \"http://localhost:19530\"\n    embedding_model: \"nv-embedqa-e5-v5\"\n    collection_name: \"aiq_case_documents\"\n    vector_field: \"embedding\"\n    search_params:\n      metric_type: \"IP\" # works best with nv-embedqa-e5-v5\n\nllms:\n  nim_llm:\n    _type: nim\n    base_url: http://192.168.5.96:1234/v1\n    model_name: qwen3-8b\n    max_tokens: 10000\n    temperature: 0.7\n  mediation_llm:\n    _type: nim\n    base_url: http://192.168.5.96:1234/v1\n    model_name: qwen3-8b\n    max_tokens: 10000\n    temperature: 0.7\n\nmemory:\n  redis_memory:\n    _type: redis_memory\n    connection_url: redis://localhost:6379/0\n\nfunctions:\n  case_document_rag:\n    _type: case_document_rag\n    retriever: milvus_retriever\n    llm_name: nim_llm\n    collection_name: \"mediation_simulator_case_documents\"\n    top_k: 5\n  case_query_agent:\n    _type: case_query_agent\n    llm_name: nim_llm\n    tool_names:\n      - case_document_rag\n    verbose: true\n    max_iterations: 5\n\n  # server route functions\n  get_mediation_case:\n    _type: server/get_mediation_case\n  get_mediation_session:\n    _type: server/get_mediation_session\n  send_message_to_mediation_session:\n    _type: mediation\n\nembedders:\n  nv-embedqa-e5-v5:\n    _type: nim\n    base_url: http://192.168.5.96:8000/v1\n    model_name: nvidia/nv-embedqa-e5-v5\n\nworkflow:\n  _type: mediation\n  llm: mediation_llm\n  data_dir: ./data\n","yaml","language-yaml shiki shiki-themes github-light github-dark monokai",[520],{"type":29,"tag":427,"props":521,"children":522},{"__ignoreMap":8},[523,540,560,573,592,605,629,642,656,669,682,695,718,735,753,771,792,808,825,842,863,879,896,913,926,944,957,970,988,1006,1024,1033,1046,1059,1076,1094,1112,1130,1148,1161,1185,1193,1206,1219,1236,1254,1272,1290,1308,1321,1337,1353,1369,1385,1401,1409,1422,1435,1452,1470,1478,1491,1504,1521,1538,1556,1573,1591,1604,1621,1637,1650,1662,1679,1696,1704,1713,1726,1743,1756,1773,1786,1803,1811,1824,1837,1853,1870,1887,1895,1908,1925,1943],{"type":29,"tag":441,"props":524,"children":527},{"class":525,"line":526},"line",1,[528,534],{"type":29,"tag":441,"props":529,"children":531},{"style":530},"--shiki-default:#22863A;--shiki-dark:#85E89D;--shiki-sepia:#F92672",[532],{"type":35,"value":533},"general",{"type":29,"tag":441,"props":535,"children":537},{"style":536},"--shiki-default:#24292E;--shiki-dark:#E1E4E8;--shiki-sepia:#F8F8F2",[538],{"type":35,"value":539},":\n",{"type":29,"tag":441,"props":541,"children":543},{"class":525,"line":542},2,[544,549,554],{"type":29,"tag":441,"props":545,"children":546},{"style":530},[547],{"type":35,"value":548},"  use_uvloop",{"type":29,"tag":441,"props":550,"children":551},{"style":536},[552],{"type":35,"value":553},": ",{"type":29,"tag":441,"props":555,"children":557},{"style":556},"--shiki-default:#005CC5;--shiki-dark:#79B8FF;--shiki-sepia:#AE81FF",[558],{"type":35,"value":559},"true\n",{"type":29,"tag":441,"props":561,"children":563},{"class":525,"line":562},3,[564,569],{"type":29,"tag":441,"props":565,"children":566},{"style":530},[567],{"type":35,"value":568},"  front_end",{"type":29,"tag":441,"props":570,"children":571},{"style":536},[572],{"type":35,"value":539},{"type":29,"tag":441,"props":574,"children":576},{"class":525,"line":575},4,[577,582,586],{"type":29,"tag":441,"props":578,"children":579},{"style":530},[580],{"type":35,"value":581},"    _type",{"type":29,"tag":441,"props":583,"children":584},{"style":536},[585],{"type":35,"value":553},{"type":29,"tag":441,"props":587,"children":589},{"style":588},"--shiki-default:#032F62;--shiki-dark:#9ECBFF;--shiki-sepia:#E6DB74",[590],{"type":35,"value":591},"fastapi\n",{"type":29,"tag":441,"props":593,"children":595},{"class":525,"line":594},5,[596,601],{"type":29,"tag":441,"props":597,"children":598},{"style":530},[599],{"type":35,"value":600},"    cors",{"type":29,"tag":441,"props":602,"children":603},{"style":536},[604],{"type":35,"value":539},{"type":29,"tag":441,"props":606,"children":608},{"class":525,"line":607},6,[609,614,619,624],{"type":29,"tag":441,"props":610,"children":611},{"style":530},[612],{"type":35,"value":613},"      allow_origins",{"type":29,"tag":441,"props":615,"children":616},{"style":536},[617],{"type":35,"value":618},": [",{"type":29,"tag":441,"props":620,"children":621},{"style":588},[622],{"type":35,"value":623},"'*'",{"type":29,"tag":441,"props":625,"children":626},{"style":536},[627],{"type":35,"value":628},"]\n",{"type":29,"tag":441,"props":630,"children":632},{"class":525,"line":631},7,[633,638],{"type":29,"tag":441,"props":634,"children":635},{"style":530},[636],{"type":35,"value":637},"      allow_methods",{"type":29,"tag":441,"props":639,"children":640},{"style":536},[641],{"type":35,"value":539},{"type":29,"tag":441,"props":643,"children":645},{"class":525,"line":644},8,[646,651],{"type":29,"tag":441,"props":647,"children":648},{"style":536},[649],{"type":35,"value":650},"        - ",{"type":29,"tag":441,"props":652,"children":653},{"style":588},[654],{"type":35,"value":655},"GET\n",{"type":29,"tag":441,"props":657,"children":659},{"class":525,"line":658},9,[660,664],{"type":29,"tag":441,"props":661,"children":662},{"style":536},[663],{"type":35,"value":650},{"type":29,"tag":441,"props":665,"children":666},{"style":588},[667],{"type":35,"value":668},"POST\n",{"type":29,"tag":441,"props":670,"children":672},{"class":525,"line":671},10,[673,677],{"type":29,"tag":441,"props":674,"children":675},{"style":536},[676],{"type":35,"value":650},{"type":29,"tag":441,"props":678,"children":679},{"style":588},[680],{"type":35,"value":681},"OPTIONS\n",{"type":29,"tag":441,"props":683,"children":685},{"class":525,"line":684},11,[686,691],{"type":29,"tag":441,"props":687,"children":688},{"style":530},[689],{"type":35,"value":690},"    endpoints",{"type":29,"tag":441,"props":692,"children":693},{"style":536},[694],{"type":35,"value":539},{"type":29,"tag":441,"props":696,"children":698},{"class":525,"line":697},12,[699,704,709,713],{"type":29,"tag":441,"props":700,"children":701},{"style":536},[702],{"type":35,"value":703},"      - ",{"type":29,"tag":441,"props":705,"children":706},{"style":530},[707],{"type":35,"value":708},"path",{"type":29,"tag":441,"props":710,"children":711},{"style":536},[712],{"type":35,"value":553},{"type":29,"tag":441,"props":714,"children":715},{"style":588},[716],{"type":35,"value":717},"/case/{case_id}\n",{"type":29,"tag":441,"props":719,"children":721},{"class":525,"line":720},13,[722,727,731],{"type":29,"tag":441,"props":723,"children":724},{"style":530},[725],{"type":35,"value":726},"        method",{"type":29,"tag":441,"props":728,"children":729},{"style":536},[730],{"type":35,"value":553},{"type":29,"tag":441,"props":732,"children":733},{"style":588},[734],{"type":35,"value":655},{"type":29,"tag":441,"props":736,"children":738},{"class":525,"line":737},14,[739,744,748],{"type":29,"tag":441,"props":740,"children":741},{"style":530},[742],{"type":35,"value":743},"        description",{"type":29,"tag":441,"props":745,"children":746},{"style":536},[747],{"type":35,"value":553},{"type":29,"tag":441,"props":749,"children":750},{"style":588},[751],{"type":35,"value":752},"Gets the mediation case for the given case ID.\n",{"type":29,"tag":441,"props":754,"children":756},{"class":525,"line":755},15,[757,762,766],{"type":29,"tag":441,"props":758,"children":759},{"style":530},[760],{"type":35,"value":761},"        function_name",{"type":29,"tag":441,"props":763,"children":764},{"style":536},[765],{"type":35,"value":553},{"type":29,"tag":441,"props":767,"children":768},{"style":588},[769],{"type":35,"value":770},"get_mediation_case\n",{"type":29,"tag":441,"props":772,"children":774},{"class":525,"line":773},16,[775,779,783,787],{"type":29,"tag":441,"props":776,"children":777},{"style":536},[778],{"type":35,"value":703},{"type":29,"tag":441,"props":780,"children":781},{"style":530},[782],{"type":35,"value":708},{"type":29,"tag":441,"props":784,"children":785},{"style":536},[786],{"type":35,"value":553},{"type":29,"tag":441,"props":788,"children":789},{"style":588},[790],{"type":35,"value":791},"/case/{case_id}/session/{session_id}\n",{"type":29,"tag":441,"props":793,"children":795},{"class":525,"line":794},17,[796,800,804],{"type":29,"tag":441,"props":797,"children":798},{"style":530},[799],{"type":35,"value":726},{"type":29,"tag":441,"props":801,"children":802},{"style":536},[803],{"type":35,"value":553},{"type":29,"tag":441,"props":805,"children":806},{"style":588},[807],{"type":35,"value":655},{"type":29,"tag":441,"props":809,"children":811},{"class":525,"line":810},18,[812,816,820],{"type":29,"tag":441,"props":813,"children":814},{"style":530},[815],{"type":35,"value":743},{"type":29,"tag":441,"props":817,"children":818},{"style":536},[819],{"type":35,"value":553},{"type":29,"tag":441,"props":821,"children":822},{"style":588},[823],{"type":35,"value":824},"Gets the mediation session data for the given case ID and session ID.\n",{"type":29,"tag":441,"props":826,"children":828},{"class":525,"line":827},19,[829,833,837],{"type":29,"tag":441,"props":830,"children":831},{"style":530},[832],{"type":35,"value":761},{"type":29,"tag":441,"props":834,"children":835},{"style":536},[836],{"type":35,"value":553},{"type":29,"tag":441,"props":838,"children":839},{"style":588},[840],{"type":35,"value":841},"get_mediation_session\n",{"type":29,"tag":441,"props":843,"children":845},{"class":525,"line":844},20,[846,850,854,858],{"type":29,"tag":441,"props":847,"children":848},{"style":536},[849],{"type":35,"value":703},{"type":29,"tag":441,"props":851,"children":852},{"style":530},[853],{"type":35,"value":708},{"type":29,"tag":441,"props":855,"children":856},{"style":536},[857],{"type":35,"value":553},{"type":29,"tag":441,"props":859,"children":860},{"style":588},[861],{"type":35,"value":862},"/case/{case_id}/session/{session_id}/send\n",{"type":29,"tag":441,"props":864,"children":866},{"class":525,"line":865},21,[867,871,875],{"type":29,"tag":441,"props":868,"children":869},{"style":530},[870],{"type":35,"value":726},{"type":29,"tag":441,"props":872,"children":873},{"style":536},[874],{"type":35,"value":553},{"type":29,"tag":441,"props":876,"children":877},{"style":588},[878],{"type":35,"value":668},{"type":29,"tag":441,"props":880,"children":882},{"class":525,"line":881},22,[883,887,891],{"type":29,"tag":441,"props":884,"children":885},{"style":530},[886],{"type":35,"value":743},{"type":29,"tag":441,"props":888,"children":889},{"style":536},[890],{"type":35,"value":553},{"type":29,"tag":441,"props":892,"children":893},{"style":588},[894],{"type":35,"value":895},"Sends a message to the mediation session for the given case ID and session ID.\n",{"type":29,"tag":441,"props":897,"children":899},{"class":525,"line":898},23,[900,904,908],{"type":29,"tag":441,"props":901,"children":902},{"style":530},[903],{"type":35,"value":761},{"type":29,"tag":441,"props":905,"children":906},{"style":536},[907],{"type":35,"value":553},{"type":29,"tag":441,"props":909,"children":910},{"style":588},[911],{"type":35,"value":912},"send_message_to_mediation_session\n",{"type":29,"tag":441,"props":914,"children":916},{"class":525,"line":915},24,[917,922],{"type":29,"tag":441,"props":918,"children":919},{"style":530},[920],{"type":35,"value":921},"  telemetry",{"type":29,"tag":441,"props":923,"children":924},{"style":536},[925],{"type":35,"value":539},{"type":29,"tag":441,"props":927,"children":929},{"class":525,"line":928},25,[930,935,939],{"type":29,"tag":441,"props":931,"children":932},{"style":530},[933],{"type":35,"value":934},"    enabled",{"type":29,"tag":441,"props":936,"children":937},{"style":536},[938],{"type":35,"value":553},{"type":29,"tag":441,"props":940,"children":941},{"style":556},[942],{"type":35,"value":943},"false\n",{"type":29,"tag":441,"props":945,"children":947},{"class":525,"line":946},26,[948,953],{"type":29,"tag":441,"props":949,"children":950},{"style":530},[951],{"type":35,"value":952},"    tracing",{"type":29,"tag":441,"props":954,"children":955},{"style":536},[956],{"type":35,"value":539},{"type":29,"tag":441,"props":958,"children":960},{"class":525,"line":959},27,[961,966],{"type":29,"tag":441,"props":962,"children":963},{"style":530},[964],{"type":35,"value":965},"      phoenix",{"type":29,"tag":441,"props":967,"children":968},{"style":536},[969],{"type":35,"value":539},{"type":29,"tag":441,"props":971,"children":973},{"class":525,"line":972},28,[974,979,983],{"type":29,"tag":441,"props":975,"children":976},{"style":530},[977],{"type":35,"value":978},"        _type",{"type":29,"tag":441,"props":980,"children":981},{"style":536},[982],{"type":35,"value":553},{"type":29,"tag":441,"props":984,"children":985},{"style":588},[986],{"type":35,"value":987},"phoenix\n",{"type":29,"tag":441,"props":989,"children":991},{"class":525,"line":990},29,[992,997,1001],{"type":29,"tag":441,"props":993,"children":994},{"style":530},[995],{"type":35,"value":996},"        endpoint",{"type":29,"tag":441,"props":998,"children":999},{"style":536},[1000],{"type":35,"value":553},{"type":29,"tag":441,"props":1002,"children":1003},{"style":588},[1004],{"type":35,"value":1005},"http://localhost:6006/v1/traces\n",{"type":29,"tag":441,"props":1007,"children":1009},{"class":525,"line":1008},30,[1010,1015,1019],{"type":29,"tag":441,"props":1011,"children":1012},{"style":530},[1013],{"type":35,"value":1014},"        project",{"type":29,"tag":441,"props":1016,"children":1017},{"style":536},[1018],{"type":35,"value":553},{"type":29,"tag":441,"props":1020,"children":1021},{"style":588},[1022],{"type":35,"value":1023},"default\n",{"type":29,"tag":441,"props":1025,"children":1027},{"class":525,"line":1026},31,[1028],{"type":29,"tag":441,"props":1029,"children":1030},{"emptyLinePlaceholder":24},[1031],{"type":35,"value":1032},"\n",{"type":29,"tag":441,"props":1034,"children":1036},{"class":525,"line":1035},32,[1037,1042],{"type":29,"tag":441,"props":1038,"children":1039},{"style":530},[1040],{"type":35,"value":1041},"retrievers",{"type":29,"tag":441,"props":1043,"children":1044},{"style":536},[1045],{"type":35,"value":539},{"type":29,"tag":441,"props":1047,"children":1049},{"class":525,"line":1048},33,[1050,1055],{"type":29,"tag":441,"props":1051,"children":1052},{"style":530},[1053],{"type":35,"value":1054},"  milvus_retriever",{"type":29,"tag":441,"props":1056,"children":1057},{"style":536},[1058],{"type":35,"value":539},{"type":29,"tag":441,"props":1060,"children":1062},{"class":525,"line":1061},34,[1063,1067,1071],{"type":29,"tag":441,"props":1064,"children":1065},{"style":530},[1066],{"type":35,"value":581},{"type":29,"tag":441,"props":1068,"children":1069},{"style":536},[1070],{"type":35,"value":553},{"type":29,"tag":441,"props":1072,"children":1073},{"style":588},[1074],{"type":35,"value":1075},"milvus_retriever\n",{"type":29,"tag":441,"props":1077,"children":1079},{"class":525,"line":1078},35,[1080,1085,1089],{"type":29,"tag":441,"props":1081,"children":1082},{"style":530},[1083],{"type":35,"value":1084},"    uri",{"type":29,"tag":441,"props":1086,"children":1087},{"style":536},[1088],{"type":35,"value":553},{"type":29,"tag":441,"props":1090,"children":1091},{"style":588},[1092],{"type":35,"value":1093},"\"http://localhost:19530\"\n",{"type":29,"tag":441,"props":1095,"children":1097},{"class":525,"line":1096},36,[1098,1103,1107],{"type":29,"tag":441,"props":1099,"children":1100},{"style":530},[1101],{"type":35,"value":1102},"    embedding_model",{"type":29,"tag":441,"props":1104,"children":1105},{"style":536},[1106],{"type":35,"value":553},{"type":29,"tag":441,"props":1108,"children":1109},{"style":588},[1110],{"type":35,"value":1111},"\"nv-embedqa-e5-v5\"\n",{"type":29,"tag":441,"props":1113,"children":1115},{"class":525,"line":1114},37,[1116,1121,1125],{"type":29,"tag":441,"props":1117,"children":1118},{"style":530},[1119],{"type":35,"value":1120},"    collection_name",{"type":29,"tag":441,"props":1122,"children":1123},{"style":536},[1124],{"type":35,"value":553},{"type":29,"tag":441,"props":1126,"children":1127},{"style":588},[1128],{"type":35,"value":1129},"\"aiq_case_documents\"\n",{"type":29,"tag":441,"props":1131,"children":1133},{"class":525,"line":1132},38,[1134,1139,1143],{"type":29,"tag":441,"props":1135,"children":1136},{"style":530},[1137],{"type":35,"value":1138},"    vector_field",{"type":29,"tag":441,"props":1140,"children":1141},{"style":536},[1142],{"type":35,"value":553},{"type":29,"tag":441,"props":1144,"children":1145},{"style":588},[1146],{"type":35,"value":1147},"\"embedding\"\n",{"type":29,"tag":441,"props":1149,"children":1151},{"class":525,"line":1150},39,[1152,1157],{"type":29,"tag":441,"props":1153,"children":1154},{"style":530},[1155],{"type":35,"value":1156},"    search_params",{"type":29,"tag":441,"props":1158,"children":1159},{"style":536},[1160],{"type":35,"value":539},{"type":29,"tag":441,"props":1162,"children":1164},{"class":525,"line":1163},40,[1165,1170,1174,1179],{"type":29,"tag":441,"props":1166,"children":1167},{"style":530},[1168],{"type":35,"value":1169},"      metric_type",{"type":29,"tag":441,"props":1171,"children":1172},{"style":536},[1173],{"type":35,"value":553},{"type":29,"tag":441,"props":1175,"children":1176},{"style":588},[1177],{"type":35,"value":1178},"\"IP\"",{"type":29,"tag":441,"props":1180,"children":1182},{"style":1181},"--shiki-default:#6A737D;--shiki-dark:#6A737D;--shiki-sepia:#88846F",[1183],{"type":35,"value":1184}," # works best with nv-embedqa-e5-v5\n",{"type":29,"tag":441,"props":1186,"children":1188},{"class":525,"line":1187},41,[1189],{"type":29,"tag":441,"props":1190,"children":1191},{"emptyLinePlaceholder":24},[1192],{"type":35,"value":1032},{"type":29,"tag":441,"props":1194,"children":1196},{"class":525,"line":1195},42,[1197,1202],{"type":29,"tag":441,"props":1198,"children":1199},{"style":530},[1200],{"type":35,"value":1201},"llms",{"type":29,"tag":441,"props":1203,"children":1204},{"style":536},[1205],{"type":35,"value":539},{"type":29,"tag":441,"props":1207,"children":1209},{"class":525,"line":1208},43,[1210,1215],{"type":29,"tag":441,"props":1211,"children":1212},{"style":530},[1213],{"type":35,"value":1214},"  nim_llm",{"type":29,"tag":441,"props":1216,"children":1217},{"style":536},[1218],{"type":35,"value":539},{"type":29,"tag":441,"props":1220,"children":1222},{"class":525,"line":1221},44,[1223,1227,1231],{"type":29,"tag":441,"props":1224,"children":1225},{"style":530},[1226],{"type":35,"value":581},{"type":29,"tag":441,"props":1228,"children":1229},{"style":536},[1230],{"type":35,"value":553},{"type":29,"tag":441,"props":1232,"children":1233},{"style":588},[1234],{"type":35,"value":1235},"nim\n",{"type":29,"tag":441,"props":1237,"children":1239},{"class":525,"line":1238},45,[1240,1245,1249],{"type":29,"tag":441,"props":1241,"children":1242},{"style":530},[1243],{"type":35,"value":1244},"    base_url",{"type":29,"tag":441,"props":1246,"children":1247},{"style":536},[1248],{"type":35,"value":553},{"type":29,"tag":441,"props":1250,"children":1251},{"style":588},[1252],{"type":35,"value":1253},"http://192.168.5.96:1234/v1\n",{"type":29,"tag":441,"props":1255,"children":1257},{"class":525,"line":1256},46,[1258,1263,1267],{"type":29,"tag":441,"props":1259,"children":1260},{"style":530},[1261],{"type":35,"value":1262},"    model_name",{"type":29,"tag":441,"props":1264,"children":1265},{"style":536},[1266],{"type":35,"value":553},{"type":29,"tag":441,"props":1268,"children":1269},{"style":588},[1270],{"type":35,"value":1271},"qwen3-8b\n",{"type":29,"tag":441,"props":1273,"children":1275},{"class":525,"line":1274},47,[1276,1281,1285],{"type":29,"tag":441,"props":1277,"children":1278},{"style":530},[1279],{"type":35,"value":1280},"    max_tokens",{"type":29,"tag":441,"props":1282,"children":1283},{"style":536},[1284],{"type":35,"value":553},{"type":29,"tag":441,"props":1286,"children":1287},{"style":556},[1288],{"type":35,"value":1289},"10000\n",{"type":29,"tag":441,"props":1291,"children":1293},{"class":525,"line":1292},48,[1294,1299,1303],{"type":29,"tag":441,"props":1295,"children":1296},{"style":530},[1297],{"type":35,"value":1298},"    temperature",{"type":29,"tag":441,"props":1300,"children":1301},{"style":536},[1302],{"type":35,"value":553},{"type":29,"tag":441,"props":1304,"children":1305},{"style":556},[1306],{"type":35,"value":1307},"0.7\n",{"type":29,"tag":441,"props":1309,"children":1311},{"class":525,"line":1310},49,[1312,1317],{"type":29,"tag":441,"props":1313,"children":1314},{"style":530},[1315],{"type":35,"value":1316},"  mediation_llm",{"type":29,"tag":441,"props":1318,"children":1319},{"style":536},[1320],{"type":35,"value":539},{"type":29,"tag":441,"props":1322,"children":1324},{"class":525,"line":1323},50,[1325,1329,1333],{"type":29,"tag":441,"props":1326,"children":1327},{"style":530},[1328],{"type":35,"value":581},{"type":29,"tag":441,"props":1330,"children":1331},{"style":536},[1332],{"type":35,"value":553},{"type":29,"tag":441,"props":1334,"children":1335},{"style":588},[1336],{"type":35,"value":1235},{"type":29,"tag":441,"props":1338,"children":1340},{"class":525,"line":1339},51,[1341,1345,1349],{"type":29,"tag":441,"props":1342,"children":1343},{"style":530},[1344],{"type":35,"value":1244},{"type":29,"tag":441,"props":1346,"children":1347},{"style":536},[1348],{"type":35,"value":553},{"type":29,"tag":441,"props":1350,"children":1351},{"style":588},[1352],{"type":35,"value":1253},{"type":29,"tag":441,"props":1354,"children":1356},{"class":525,"line":1355},52,[1357,1361,1365],{"type":29,"tag":441,"props":1358,"children":1359},{"style":530},[1360],{"type":35,"value":1262},{"type":29,"tag":441,"props":1362,"children":1363},{"style":536},[1364],{"type":35,"value":553},{"type":29,"tag":441,"props":1366,"children":1367},{"style":588},[1368],{"type":35,"value":1271},{"type":29,"tag":441,"props":1370,"children":1372},{"class":525,"line":1371},53,[1373,1377,1381],{"type":29,"tag":441,"props":1374,"children":1375},{"style":530},[1376],{"type":35,"value":1280},{"type":29,"tag":441,"props":1378,"children":1379},{"style":536},[1380],{"type":35,"value":553},{"type":29,"tag":441,"props":1382,"children":1383},{"style":556},[1384],{"type":35,"value":1289},{"type":29,"tag":441,"props":1386,"children":1388},{"class":525,"line":1387},54,[1389,1393,1397],{"type":29,"tag":441,"props":1390,"children":1391},{"style":530},[1392],{"type":35,"value":1298},{"type":29,"tag":441,"props":1394,"children":1395},{"style":536},[1396],{"type":35,"value":553},{"type":29,"tag":441,"props":1398,"children":1399},{"style":556},[1400],{"type":35,"value":1307},{"type":29,"tag":441,"props":1402,"children":1404},{"class":525,"line":1403},55,[1405],{"type":29,"tag":441,"props":1406,"children":1407},{"emptyLinePlaceholder":24},[1408],{"type":35,"value":1032},{"type":29,"tag":441,"props":1410,"children":1412},{"class":525,"line":1411},56,[1413,1418],{"type":29,"tag":441,"props":1414,"children":1415},{"style":530},[1416],{"type":35,"value":1417},"memory",{"type":29,"tag":441,"props":1419,"children":1420},{"style":536},[1421],{"type":35,"value":539},{"type":29,"tag":441,"props":1423,"children":1425},{"class":525,"line":1424},57,[1426,1431],{"type":29,"tag":441,"props":1427,"children":1428},{"style":530},[1429],{"type":35,"value":1430},"  redis_memory",{"type":29,"tag":441,"props":1432,"children":1433},{"style":536},[1434],{"type":35,"value":539},{"type":29,"tag":441,"props":1436,"children":1438},{"class":525,"line":1437},58,[1439,1443,1447],{"type":29,"tag":441,"props":1440,"children":1441},{"style":530},[1442],{"type":35,"value":581},{"type":29,"tag":441,"props":1444,"children":1445},{"style":536},[1446],{"type":35,"value":553},{"type":29,"tag":441,"props":1448,"children":1449},{"style":588},[1450],{"type":35,"value":1451},"redis_memory\n",{"type":29,"tag":441,"props":1453,"children":1455},{"class":525,"line":1454},59,[1456,1461,1465],{"type":29,"tag":441,"props":1457,"children":1458},{"style":530},[1459],{"type":35,"value":1460},"    connection_url",{"type":29,"tag":441,"props":1462,"children":1463},{"style":536},[1464],{"type":35,"value":553},{"type":29,"tag":441,"props":1466,"children":1467},{"style":588},[1468],{"type":35,"value":1469},"redis://localhost:6379/0\n",{"type":29,"tag":441,"props":1471,"children":1473},{"class":525,"line":1472},60,[1474],{"type":29,"tag":441,"props":1475,"children":1476},{"emptyLinePlaceholder":24},[1477],{"type":35,"value":1032},{"type":29,"tag":441,"props":1479,"children":1481},{"class":525,"line":1480},61,[1482,1487],{"type":29,"tag":441,"props":1483,"children":1484},{"style":530},[1485],{"type":35,"value":1486},"functions",{"type":29,"tag":441,"props":1488,"children":1489},{"style":536},[1490],{"type":35,"value":539},{"type":29,"tag":441,"props":1492,"children":1494},{"class":525,"line":1493},62,[1495,1500],{"type":29,"tag":441,"props":1496,"children":1497},{"style":530},[1498],{"type":35,"value":1499},"  case_document_rag",{"type":29,"tag":441,"props":1501,"children":1502},{"style":536},[1503],{"type":35,"value":539},{"type":29,"tag":441,"props":1505,"children":1507},{"class":525,"line":1506},63,[1508,1512,1516],{"type":29,"tag":441,"props":1509,"children":1510},{"style":530},[1511],{"type":35,"value":581},{"type":29,"tag":441,"props":1513,"children":1514},{"style":536},[1515],{"type":35,"value":553},{"type":29,"tag":441,"props":1517,"children":1518},{"style":588},[1519],{"type":35,"value":1520},"case_document_rag\n",{"type":29,"tag":441,"props":1522,"children":1524},{"class":525,"line":1523},64,[1525,1530,1534],{"type":29,"tag":441,"props":1526,"children":1527},{"style":530},[1528],{"type":35,"value":1529},"    retriever",{"type":29,"tag":441,"props":1531,"children":1532},{"style":536},[1533],{"type":35,"value":553},{"type":29,"tag":441,"props":1535,"children":1536},{"style":588},[1537],{"type":35,"value":1075},{"type":29,"tag":441,"props":1539,"children":1541},{"class":525,"line":1540},65,[1542,1547,1551],{"type":29,"tag":441,"props":1543,"children":1544},{"style":530},[1545],{"type":35,"value":1546},"    llm_name",{"type":29,"tag":441,"props":1548,"children":1549},{"style":536},[1550],{"type":35,"value":553},{"type":29,"tag":441,"props":1552,"children":1553},{"style":588},[1554],{"type":35,"value":1555},"nim_llm\n",{"type":29,"tag":441,"props":1557,"children":1559},{"class":525,"line":1558},66,[1560,1564,1568],{"type":29,"tag":441,"props":1561,"children":1562},{"style":530},[1563],{"type":35,"value":1120},{"type":29,"tag":441,"props":1565,"children":1566},{"style":536},[1567],{"type":35,"value":553},{"type":29,"tag":441,"props":1569,"children":1570},{"style":588},[1571],{"type":35,"value":1572},"\"mediation_simulator_case_documents\"\n",{"type":29,"tag":441,"props":1574,"children":1576},{"class":525,"line":1575},67,[1577,1582,1586],{"type":29,"tag":441,"props":1578,"children":1579},{"style":530},[1580],{"type":35,"value":1581},"    top_k",{"type":29,"tag":441,"props":1583,"children":1584},{"style":536},[1585],{"type":35,"value":553},{"type":29,"tag":441,"props":1587,"children":1588},{"style":556},[1589],{"type":35,"value":1590},"5\n",{"type":29,"tag":441,"props":1592,"children":1594},{"class":525,"line":1593},68,[1595,1600],{"type":29,"tag":441,"props":1596,"children":1597},{"style":530},[1598],{"type":35,"value":1599},"  case_query_agent",{"type":29,"tag":441,"props":1601,"children":1602},{"style":536},[1603],{"type":35,"value":539},{"type":29,"tag":441,"props":1605,"children":1607},{"class":525,"line":1606},69,[1608,1612,1616],{"type":29,"tag":441,"props":1609,"children":1610},{"style":530},[1611],{"type":35,"value":581},{"type":29,"tag":441,"props":1613,"children":1614},{"style":536},[1615],{"type":35,"value":553},{"type":29,"tag":441,"props":1617,"children":1618},{"style":588},[1619],{"type":35,"value":1620},"case_query_agent\n",{"type":29,"tag":441,"props":1622,"children":1624},{"class":525,"line":1623},70,[1625,1629,1633],{"type":29,"tag":441,"props":1626,"children":1627},{"style":530},[1628],{"type":35,"value":1546},{"type":29,"tag":441,"props":1630,"children":1631},{"style":536},[1632],{"type":35,"value":553},{"type":29,"tag":441,"props":1634,"children":1635},{"style":588},[1636],{"type":35,"value":1555},{"type":29,"tag":441,"props":1638,"children":1640},{"class":525,"line":1639},71,[1641,1646],{"type":29,"tag":441,"props":1642,"children":1643},{"style":530},[1644],{"type":35,"value":1645},"    tool_names",{"type":29,"tag":441,"props":1647,"children":1648},{"style":536},[1649],{"type":35,"value":539},{"type":29,"tag":441,"props":1651,"children":1653},{"class":525,"line":1652},72,[1654,1658],{"type":29,"tag":441,"props":1655,"children":1656},{"style":536},[1657],{"type":35,"value":703},{"type":29,"tag":441,"props":1659,"children":1660},{"style":588},[1661],{"type":35,"value":1520},{"type":29,"tag":441,"props":1663,"children":1665},{"class":525,"line":1664},73,[1666,1671,1675],{"type":29,"tag":441,"props":1667,"children":1668},{"style":530},[1669],{"type":35,"value":1670},"    verbose",{"type":29,"tag":441,"props":1672,"children":1673},{"style":536},[1674],{"type":35,"value":553},{"type":29,"tag":441,"props":1676,"children":1677},{"style":556},[1678],{"type":35,"value":559},{"type":29,"tag":441,"props":1680,"children":1682},{"class":525,"line":1681},74,[1683,1688,1692],{"type":29,"tag":441,"props":1684,"children":1685},{"style":530},[1686],{"type":35,"value":1687},"    max_iterations",{"type":29,"tag":441,"props":1689,"children":1690},{"style":536},[1691],{"type":35,"value":553},{"type":29,"tag":441,"props":1693,"children":1694},{"style":556},[1695],{"type":35,"value":1590},{"type":29,"tag":441,"props":1697,"children":1699},{"class":525,"line":1698},75,[1700],{"type":29,"tag":441,"props":1701,"children":1702},{"emptyLinePlaceholder":24},[1703],{"type":35,"value":1032},{"type":29,"tag":441,"props":1705,"children":1707},{"class":525,"line":1706},76,[1708],{"type":29,"tag":441,"props":1709,"children":1710},{"style":1181},[1711],{"type":35,"value":1712},"  # server route functions\n",{"type":29,"tag":441,"props":1714,"children":1716},{"class":525,"line":1715},77,[1717,1722],{"type":29,"tag":441,"props":1718,"children":1719},{"style":530},[1720],{"type":35,"value":1721},"  get_mediation_case",{"type":29,"tag":441,"props":1723,"children":1724},{"style":536},[1725],{"type":35,"value":539},{"type":29,"tag":441,"props":1727,"children":1729},{"class":525,"line":1728},78,[1730,1734,1738],{"type":29,"tag":441,"props":1731,"children":1732},{"style":530},[1733],{"type":35,"value":581},{"type":29,"tag":441,"props":1735,"children":1736},{"style":536},[1737],{"type":35,"value":553},{"type":29,"tag":441,"props":1739,"children":1740},{"style":588},[1741],{"type":35,"value":1742},"server/get_mediation_case\n",{"type":29,"tag":441,"props":1744,"children":1746},{"class":525,"line":1745},79,[1747,1752],{"type":29,"tag":441,"props":1748,"children":1749},{"style":530},[1750],{"type":35,"value":1751},"  get_mediation_session",{"type":29,"tag":441,"props":1753,"children":1754},{"style":536},[1755],{"type":35,"value":539},{"type":29,"tag":441,"props":1757,"children":1759},{"class":525,"line":1758},80,[1760,1764,1768],{"type":29,"tag":441,"props":1761,"children":1762},{"style":530},[1763],{"type":35,"value":581},{"type":29,"tag":441,"props":1765,"children":1766},{"style":536},[1767],{"type":35,"value":553},{"type":29,"tag":441,"props":1769,"children":1770},{"style":588},[1771],{"type":35,"value":1772},"server/get_mediation_session\n",{"type":29,"tag":441,"props":1774,"children":1776},{"class":525,"line":1775},81,[1777,1782],{"type":29,"tag":441,"props":1778,"children":1779},{"style":530},[1780],{"type":35,"value":1781},"  send_message_to_mediation_session",{"type":29,"tag":441,"props":1783,"children":1784},{"style":536},[1785],{"type":35,"value":539},{"type":29,"tag":441,"props":1787,"children":1789},{"class":525,"line":1788},82,[1790,1794,1798],{"type":29,"tag":441,"props":1791,"children":1792},{"style":530},[1793],{"type":35,"value":581},{"type":29,"tag":441,"props":1795,"children":1796},{"style":536},[1797],{"type":35,"value":553},{"type":29,"tag":441,"props":1799,"children":1800},{"style":588},[1801],{"type":35,"value":1802},"mediation\n",{"type":29,"tag":441,"props":1804,"children":1806},{"class":525,"line":1805},83,[1807],{"type":29,"tag":441,"props":1808,"children":1809},{"emptyLinePlaceholder":24},[1810],{"type":35,"value":1032},{"type":29,"tag":441,"props":1812,"children":1814},{"class":525,"line":1813},84,[1815,1820],{"type":29,"tag":441,"props":1816,"children":1817},{"style":530},[1818],{"type":35,"value":1819},"embedders",{"type":29,"tag":441,"props":1821,"children":1822},{"style":536},[1823],{"type":35,"value":539},{"type":29,"tag":441,"props":1825,"children":1827},{"class":525,"line":1826},85,[1828,1833],{"type":29,"tag":441,"props":1829,"children":1830},{"style":530},[1831],{"type":35,"value":1832},"  nv-embedqa-e5-v5",{"type":29,"tag":441,"props":1834,"children":1835},{"style":536},[1836],{"type":35,"value":539},{"type":29,"tag":441,"props":1838,"children":1840},{"class":525,"line":1839},86,[1841,1845,1849],{"type":29,"tag":441,"props":1842,"children":1843},{"style":530},[1844],{"type":35,"value":581},{"type":29,"tag":441,"props":1846,"children":1847},{"style":536},[1848],{"type":35,"value":553},{"type":29,"tag":441,"props":1850,"children":1851},{"style":588},[1852],{"type":35,"value":1235},{"type":29,"tag":441,"props":1854,"children":1856},{"class":525,"line":1855},87,[1857,1861,1865],{"type":29,"tag":441,"props":1858,"children":1859},{"style":530},[1860],{"type":35,"value":1244},{"type":29,"tag":441,"props":1862,"children":1863},{"style":536},[1864],{"type":35,"value":553},{"type":29,"tag":441,"props":1866,"children":1867},{"style":588},[1868],{"type":35,"value":1869},"http://192.168.5.96:8000/v1\n",{"type":29,"tag":441,"props":1871,"children":1873},{"class":525,"line":1872},88,[1874,1878,1882],{"type":29,"tag":441,"props":1875,"children":1876},{"style":530},[1877],{"type":35,"value":1262},{"type":29,"tag":441,"props":1879,"children":1880},{"style":536},[1881],{"type":35,"value":553},{"type":29,"tag":441,"props":1883,"children":1884},{"style":588},[1885],{"type":35,"value":1886},"nvidia/nv-embedqa-e5-v5\n",{"type":29,"tag":441,"props":1888,"children":1890},{"class":525,"line":1889},89,[1891],{"type":29,"tag":441,"props":1892,"children":1893},{"emptyLinePlaceholder":24},[1894],{"type":35,"value":1032},{"type":29,"tag":441,"props":1896,"children":1898},{"class":525,"line":1897},90,[1899,1904],{"type":29,"tag":441,"props":1900,"children":1901},{"style":530},[1902],{"type":35,"value":1903},"workflow",{"type":29,"tag":441,"props":1905,"children":1906},{"style":536},[1907],{"type":35,"value":539},{"type":29,"tag":441,"props":1909,"children":1911},{"class":525,"line":1910},91,[1912,1917,1921],{"type":29,"tag":441,"props":1913,"children":1914},{"style":530},[1915],{"type":35,"value":1916},"  _type",{"type":29,"tag":441,"props":1918,"children":1919},{"style":536},[1920],{"type":35,"value":553},{"type":29,"tag":441,"props":1922,"children":1923},{"style":588},[1924],{"type":35,"value":1802},{"type":29,"tag":441,"props":1926,"children":1928},{"class":525,"line":1927},92,[1929,1934,1938],{"type":29,"tag":441,"props":1930,"children":1931},{"style":530},[1932],{"type":35,"value":1933},"  llm",{"type":29,"tag":441,"props":1935,"children":1936},{"style":536},[1937],{"type":35,"value":553},{"type":29,"tag":441,"props":1939,"children":1940},{"style":588},[1941],{"type":35,"value":1942},"mediation_llm\n",{"type":29,"tag":441,"props":1944,"children":1946},{"class":525,"line":1945},93,[1947,1952,1956],{"type":29,"tag":441,"props":1948,"children":1949},{"style":530},[1950],{"type":35,"value":1951},"  data_dir",{"type":29,"tag":441,"props":1953,"children":1954},{"style":536},[1955],{"type":35,"value":553},{"type":29,"tag":441,"props":1957,"children":1958},{"style":588},[1959],{"type":35,"value":1960},"./data\n",{"type":29,"tag":38,"props":1962,"children":1963},{},[1964,1966,1971],{"type":35,"value":1965},"Let's start at the top with ",{"type":29,"tag":427,"props":1967,"children":1969},{"className":1968},[],[1970],{"type":35,"value":533},{"type":35,"value":1972}," key",{"type":29,"tag":123,"props":1974,"children":1975},{"id":533},[1976],{"type":29,"tag":427,"props":1977,"children":1979},{"className":1978},[],[1980],{"type":35,"value":533},{"type":29,"tag":38,"props":1982,"children":1983},{},[1984],{"type":35,"value":1985},"This section mainly defines the API routes for the FastAPI integration and the telemetry options I set up to view all of my programs traces. When building applications with LLMs, instrumenting for observability is key! Agent Intelligence Toolkit makes it really easy to hook up not just one observability tool, but really any number of observability tools! It all works through asynchronous calls, so it doesn't slow down the application.",{"type":29,"tag":38,"props":1987,"children":1988},{},[1989],{"type":29,"tag":192,"props":1990,"children":1993},{"alt":1991,"src":1992},"LLM observability","/static/mediation-simulator/Phoenix.png",[],{"type":29,"tag":38,"props":1995,"children":1996},{},[1997],{"type":35,"value":1998},"Defining the API routes was pretty straightforward. You define an AIQ Toolkit function that handles the route's behavior. These routes are also automatically added to the API's documentation page using OpenAPI/Swagger:",{"type":29,"tag":38,"props":2000,"children":2001},{},[2002],{"type":29,"tag":192,"props":2003,"children":2006},{"alt":2004,"src":2005},"API documentation","/static/mediation-simulator/fastapi.png",[],{"type":29,"tag":123,"props":2008,"children":2009},{"id":1041},[2010],{"type":29,"tag":427,"props":2011,"children":2013},{"className":2012},[],[2014],{"type":35,"value":1041},{"type":29,"tag":38,"props":2016,"children":2017},{},[2018],{"type":35,"value":2019},"This section allows you to define different vector storage databases that your application uses. I used Milvus to store embeddings of case documents. Ultimately I wasn't able to incorporate these embeddings into my application.",{"type":29,"tag":123,"props":2021,"children":2022},{"id":1201},[2023],{"type":29,"tag":427,"props":2024,"children":2026},{"className":2025},[],[2027],{"type":35,"value":1201},{"type":29,"tag":38,"props":2029,"children":2030},{},[2031],{"type":35,"value":2032},"The LLMs section allows you to plug in to any LLM. I used a combination of LM Studio and NVIDIA NIMs to test my application. You can pretty much use any LLM that provides an OpenAI API interface. Local models have come a long way! New models like Qwen3 and Llama 3.1 have massive context windows (130k tokens!) which is a total game changer. These models are also getting a lot smarter. I was really impressed with how well these models followed my prompts. Using local models is nice because you will not be rate limited. I processed about 2 million prompt tokens and generated about 1.5 million completion tokens during the development of Mediation Simulator. As amazing as these new frontier models are now, I'm still bullish on the capabilities of (small) large language models that can run on consumer hardware like NVIDIA RTX GPUs.",{"type":29,"tag":123,"props":2034,"children":2035},{"id":1417},[2036],{"type":29,"tag":427,"props":2037,"children":2039},{"className":2038},[],[2040],{"type":35,"value":1417},{"type":29,"tag":38,"props":2042,"children":2043},{},[2044],{"type":35,"value":2045},"Figure out how memory works in the AIQ toolkit was a big \"ah-ha!\" moment for me. It allows for persisting chat messages between generations, and also storing arbitrary data that you can use in your workflows. I decided to use Redis (Redis Stack) to build a memory backend. Here's a quick look at what that code looks like:",{"type":29,"tag":514,"props":2047,"children":2051},{"code":2048,"language":2049,"meta":8,"className":2050,"style":8},"@register_memory(config_type=RedisMemoryConfig)\nasync def redis_memory(config: RedisMemoryConfig, builder: Builder):\n\n    class RedisMemoryEditor(MemoryEditor):\n        def __init__(self, config: RedisMemoryConfig):\n            self._conn_url = config.connection_url\n            self.redis = Redis.from_url(self._conn_url)\n\n        async def get_client(self, session_id: str) -> RedisChatMessageHistory:\n            conn = RedisChatMessageHistory(\n                session_id=session_id, redis_url=self._conn_url\n            )\n            return conn\n\n        # mediation session state management\n        async def add_messages(\n            self, items: Sequence[BaseMessage], session_id: str\n        ) -> None:\n            client = await self.get_client(session_id)\n            await client.aadd_messages(items)\n\n        async def get_messages(self, session_id: str) -> Sequence[BaseMessage]:\n            client = await self.get_client(session_id)\n            messages = await client.aget_messages()\n            return messages\n\n        # case generation state management\n        async def save_case_description(\n            self, case_description: str, case_id: str\n        ) -> None:\n            \"\"\"\n            sets the case description using the \u003Ccase_id>_case_description as the redis key\n            \"\"\"\n            self.redis.set(f\"{case_id}_case_description\", case_description)\n\n        ...\n","python","language-python shiki shiki-themes github-light github-dark monokai",[2052],{"type":29,"tag":427,"props":2053,"children":2054},{"__ignoreMap":8},[2055,2086,2130,2137,2166,2203,2226,2256,2263,2312,2329,2364,2372,2385,2392,2400,2421,2455,2472,2499,2512,2519,2564,2587,2608,2620,2627,2635,2655,2696,2711,2719,2727,2734,2780,2787],{"type":29,"tag":441,"props":2056,"children":2057},{"class":525,"line":526},[2058,2064,2069,2075,2081],{"type":29,"tag":441,"props":2059,"children":2061},{"style":2060},"--shiki-default:#6F42C1;--shiki-dark:#B392F0;--shiki-sepia:#A6E22E",[2062],{"type":35,"value":2063},"@register_memory",{"type":29,"tag":441,"props":2065,"children":2066},{"style":536},[2067],{"type":35,"value":2068},"(",{"type":29,"tag":441,"props":2070,"children":2072},{"style":2071},"--shiki-default:#E36209;--shiki-dark:#FFAB70;--shiki-sepia:#FD971F;--shiki-default-font-style:inherit;--shiki-dark-font-style:inherit;--shiki-sepia-font-style:italic",[2073],{"type":35,"value":2074},"config_type",{"type":29,"tag":441,"props":2076,"children":2078},{"style":2077},"--shiki-default:#D73A49;--shiki-dark:#F97583;--shiki-sepia:#F92672",[2079],{"type":35,"value":2080},"=",{"type":29,"tag":441,"props":2082,"children":2083},{"style":536},[2084],{"type":35,"value":2085},"RedisMemoryConfig)\n",{"type":29,"tag":441,"props":2087,"children":2088},{"class":525,"line":542},[2089,2095,2100,2105,2109,2115,2120,2125],{"type":29,"tag":441,"props":2090,"children":2092},{"style":2091},"--shiki-default:#D73A49;--shiki-dark:#F97583;--shiki-sepia:#66D9EF;--shiki-default-font-style:inherit;--shiki-dark-font-style:inherit;--shiki-sepia-font-style:italic",[2093],{"type":35,"value":2094},"async",{"type":29,"tag":441,"props":2096,"children":2097},{"style":2091},[2098],{"type":35,"value":2099}," def",{"type":29,"tag":441,"props":2101,"children":2102},{"style":2060},[2103],{"type":35,"value":2104}," redis_memory",{"type":29,"tag":441,"props":2106,"children":2107},{"style":536},[2108],{"type":35,"value":2068},{"type":29,"tag":441,"props":2110,"children":2112},{"style":2111},"--shiki-default:#24292E;--shiki-dark:#E1E4E8;--shiki-sepia:#FD971F;--shiki-default-font-style:inherit;--shiki-dark-font-style:inherit;--shiki-sepia-font-style:italic",[2113],{"type":35,"value":2114},"config",{"type":29,"tag":441,"props":2116,"children":2117},{"style":536},[2118],{"type":35,"value":2119},": RedisMemoryConfig, ",{"type":29,"tag":441,"props":2121,"children":2122},{"style":2111},[2123],{"type":35,"value":2124},"builder",{"type":29,"tag":441,"props":2126,"children":2127},{"style":536},[2128],{"type":35,"value":2129},": Builder):\n",{"type":29,"tag":441,"props":2131,"children":2132},{"class":525,"line":562},[2133],{"type":29,"tag":441,"props":2134,"children":2135},{"emptyLinePlaceholder":24},[2136],{"type":35,"value":1032},{"type":29,"tag":441,"props":2138,"children":2139},{"class":525,"line":575},[2140,2145,2151,2155,2161],{"type":29,"tag":441,"props":2141,"children":2142},{"style":2091},[2143],{"type":35,"value":2144},"    class",{"type":29,"tag":441,"props":2146,"children":2148},{"style":2147},"--shiki-default:#6F42C1;--shiki-dark:#B392F0;--shiki-sepia:#A6E22E;--shiki-default-text-decoration:inherit;--shiki-dark-text-decoration:inherit;--shiki-sepia-text-decoration:underline",[2149],{"type":35,"value":2150}," RedisMemoryEditor",{"type":29,"tag":441,"props":2152,"children":2153},{"style":536},[2154],{"type":35,"value":2068},{"type":29,"tag":441,"props":2156,"children":2158},{"style":2157},"--shiki-default:#6F42C1;--shiki-dark:#B392F0;--shiki-sepia:#A6E22E;--shiki-default-font-style:inherit;--shiki-dark-font-style:inherit;--shiki-sepia-font-style:italic;--shiki-default-text-decoration:inherit;--shiki-dark-text-decoration:inherit;--shiki-sepia-text-decoration:underline",[2159],{"type":35,"value":2160},"MemoryEditor",{"type":29,"tag":441,"props":2162,"children":2163},{"style":536},[2164],{"type":35,"value":2165},"):\n",{"type":29,"tag":441,"props":2167,"children":2168},{"class":525,"line":594},[2169,2174,2180,2184,2189,2194,2198],{"type":29,"tag":441,"props":2170,"children":2171},{"style":2091},[2172],{"type":35,"value":2173},"        def",{"type":29,"tag":441,"props":2175,"children":2177},{"style":2176},"--shiki-default:#005CC5;--shiki-dark:#79B8FF;--shiki-sepia:#66D9EF",[2178],{"type":35,"value":2179}," __init__",{"type":29,"tag":441,"props":2181,"children":2182},{"style":536},[2183],{"type":35,"value":2068},{"type":29,"tag":441,"props":2185,"children":2186},{"style":2111},[2187],{"type":35,"value":2188},"self",{"type":29,"tag":441,"props":2190,"children":2191},{"style":536},[2192],{"type":35,"value":2193},", ",{"type":29,"tag":441,"props":2195,"children":2196},{"style":2111},[2197],{"type":35,"value":2114},{"type":29,"tag":441,"props":2199,"children":2200},{"style":536},[2201],{"type":35,"value":2202},": RedisMemoryConfig):\n",{"type":29,"tag":441,"props":2204,"children":2205},{"class":525,"line":607},[2206,2212,2217,2221],{"type":29,"tag":441,"props":2207,"children":2209},{"style":2208},"--shiki-default:#005CC5;--shiki-dark:#79B8FF;--shiki-sepia:#FD971F",[2210],{"type":35,"value":2211},"            self",{"type":29,"tag":441,"props":2213,"children":2214},{"style":536},[2215],{"type":35,"value":2216},"._conn_url ",{"type":29,"tag":441,"props":2218,"children":2219},{"style":2077},[2220],{"type":35,"value":2080},{"type":29,"tag":441,"props":2222,"children":2223},{"style":536},[2224],{"type":35,"value":2225}," config.connection_url\n",{"type":29,"tag":441,"props":2227,"children":2228},{"class":525,"line":631},[2229,2233,2238,2242,2247,2251],{"type":29,"tag":441,"props":2230,"children":2231},{"style":2208},[2232],{"type":35,"value":2211},{"type":29,"tag":441,"props":2234,"children":2235},{"style":536},[2236],{"type":35,"value":2237},".redis ",{"type":29,"tag":441,"props":2239,"children":2240},{"style":2077},[2241],{"type":35,"value":2080},{"type":29,"tag":441,"props":2243,"children":2244},{"style":536},[2245],{"type":35,"value":2246}," Redis.from_url(",{"type":29,"tag":441,"props":2248,"children":2249},{"style":2208},[2250],{"type":35,"value":2188},{"type":29,"tag":441,"props":2252,"children":2253},{"style":536},[2254],{"type":35,"value":2255},"._conn_url)\n",{"type":29,"tag":441,"props":2257,"children":2258},{"class":525,"line":644},[2259],{"type":29,"tag":441,"props":2260,"children":2261},{"emptyLinePlaceholder":24},[2262],{"type":35,"value":1032},{"type":29,"tag":441,"props":2264,"children":2265},{"class":525,"line":658},[2266,2271,2275,2280,2284,2288,2292,2297,2301,2307],{"type":29,"tag":441,"props":2267,"children":2268},{"style":2091},[2269],{"type":35,"value":2270},"        async",{"type":29,"tag":441,"props":2272,"children":2273},{"style":2091},[2274],{"type":35,"value":2099},{"type":29,"tag":441,"props":2276,"children":2277},{"style":2060},[2278],{"type":35,"value":2279}," get_client",{"type":29,"tag":441,"props":2281,"children":2282},{"style":536},[2283],{"type":35,"value":2068},{"type":29,"tag":441,"props":2285,"children":2286},{"style":2111},[2287],{"type":35,"value":2188},{"type":29,"tag":441,"props":2289,"children":2290},{"style":536},[2291],{"type":35,"value":2193},{"type":29,"tag":441,"props":2293,"children":2294},{"style":2111},[2295],{"type":35,"value":2296},"session_id",{"type":29,"tag":441,"props":2298,"children":2299},{"style":536},[2300],{"type":35,"value":553},{"type":29,"tag":441,"props":2302,"children":2304},{"style":2303},"--shiki-default:#005CC5;--shiki-dark:#79B8FF;--shiki-sepia:#66D9EF;--shiki-default-font-style:inherit;--shiki-dark-font-style:inherit;--shiki-sepia-font-style:italic",[2305],{"type":35,"value":2306},"str",{"type":29,"tag":441,"props":2308,"children":2309},{"style":536},[2310],{"type":35,"value":2311},") -> RedisChatMessageHistory:\n",{"type":29,"tag":441,"props":2313,"children":2314},{"class":525,"line":671},[2315,2320,2324],{"type":29,"tag":441,"props":2316,"children":2317},{"style":536},[2318],{"type":35,"value":2319},"            conn ",{"type":29,"tag":441,"props":2321,"children":2322},{"style":2077},[2323],{"type":35,"value":2080},{"type":29,"tag":441,"props":2325,"children":2326},{"style":536},[2327],{"type":35,"value":2328}," RedisChatMessageHistory(\n",{"type":29,"tag":441,"props":2330,"children":2331},{"class":525,"line":684},[2332,2337,2341,2346,2351,2355,2359],{"type":29,"tag":441,"props":2333,"children":2334},{"style":2071},[2335],{"type":35,"value":2336},"                session_id",{"type":29,"tag":441,"props":2338,"children":2339},{"style":2077},[2340],{"type":35,"value":2080},{"type":29,"tag":441,"props":2342,"children":2343},{"style":536},[2344],{"type":35,"value":2345},"session_id, ",{"type":29,"tag":441,"props":2347,"children":2348},{"style":2071},[2349],{"type":35,"value":2350},"redis_url",{"type":29,"tag":441,"props":2352,"children":2353},{"style":2077},[2354],{"type":35,"value":2080},{"type":29,"tag":441,"props":2356,"children":2357},{"style":2208},[2358],{"type":35,"value":2188},{"type":29,"tag":441,"props":2360,"children":2361},{"style":536},[2362],{"type":35,"value":2363},"._conn_url\n",{"type":29,"tag":441,"props":2365,"children":2366},{"class":525,"line":697},[2367],{"type":29,"tag":441,"props":2368,"children":2369},{"style":536},[2370],{"type":35,"value":2371},"            )\n",{"type":29,"tag":441,"props":2373,"children":2374},{"class":525,"line":720},[2375,2380],{"type":29,"tag":441,"props":2376,"children":2377},{"style":2077},[2378],{"type":35,"value":2379},"            return",{"type":29,"tag":441,"props":2381,"children":2382},{"style":536},[2383],{"type":35,"value":2384}," conn\n",{"type":29,"tag":441,"props":2386,"children":2387},{"class":525,"line":737},[2388],{"type":29,"tag":441,"props":2389,"children":2390},{"emptyLinePlaceholder":24},[2391],{"type":35,"value":1032},{"type":29,"tag":441,"props":2393,"children":2394},{"class":525,"line":755},[2395],{"type":29,"tag":441,"props":2396,"children":2397},{"style":1181},[2398],{"type":35,"value":2399},"        # mediation session state management\n",{"type":29,"tag":441,"props":2401,"children":2402},{"class":525,"line":773},[2403,2407,2411,2416],{"type":29,"tag":441,"props":2404,"children":2405},{"style":2091},[2406],{"type":35,"value":2270},{"type":29,"tag":441,"props":2408,"children":2409},{"style":2091},[2410],{"type":35,"value":2099},{"type":29,"tag":441,"props":2412,"children":2413},{"style":2060},[2414],{"type":35,"value":2415}," add_messages",{"type":29,"tag":441,"props":2417,"children":2418},{"style":536},[2419],{"type":35,"value":2420},"(\n",{"type":29,"tag":441,"props":2422,"children":2423},{"class":525,"line":794},[2424,2428,2432,2437,2442,2446,2450],{"type":29,"tag":441,"props":2425,"children":2426},{"style":2111},[2427],{"type":35,"value":2211},{"type":29,"tag":441,"props":2429,"children":2430},{"style":536},[2431],{"type":35,"value":2193},{"type":29,"tag":441,"props":2433,"children":2434},{"style":2111},[2435],{"type":35,"value":2436},"items",{"type":29,"tag":441,"props":2438,"children":2439},{"style":536},[2440],{"type":35,"value":2441},": Sequence[BaseMessage], ",{"type":29,"tag":441,"props":2443,"children":2444},{"style":2111},[2445],{"type":35,"value":2296},{"type":29,"tag":441,"props":2447,"children":2448},{"style":536},[2449],{"type":35,"value":553},{"type":29,"tag":441,"props":2451,"children":2452},{"style":2303},[2453],{"type":35,"value":2454},"str\n",{"type":29,"tag":441,"props":2456,"children":2457},{"class":525,"line":810},[2458,2463,2468],{"type":29,"tag":441,"props":2459,"children":2460},{"style":536},[2461],{"type":35,"value":2462},"        ) -> ",{"type":29,"tag":441,"props":2464,"children":2465},{"style":556},[2466],{"type":35,"value":2467},"None",{"type":29,"tag":441,"props":2469,"children":2470},{"style":536},[2471],{"type":35,"value":539},{"type":29,"tag":441,"props":2473,"children":2474},{"class":525,"line":827},[2475,2480,2484,2489,2494],{"type":29,"tag":441,"props":2476,"children":2477},{"style":536},[2478],{"type":35,"value":2479},"            client ",{"type":29,"tag":441,"props":2481,"children":2482},{"style":2077},[2483],{"type":35,"value":2080},{"type":29,"tag":441,"props":2485,"children":2486},{"style":2077},[2487],{"type":35,"value":2488}," await",{"type":29,"tag":441,"props":2490,"children":2491},{"style":2208},[2492],{"type":35,"value":2493}," self",{"type":29,"tag":441,"props":2495,"children":2496},{"style":536},[2497],{"type":35,"value":2498},".get_client(session_id)\n",{"type":29,"tag":441,"props":2500,"children":2501},{"class":525,"line":844},[2502,2507],{"type":29,"tag":441,"props":2503,"children":2504},{"style":2077},[2505],{"type":35,"value":2506},"            await",{"type":29,"tag":441,"props":2508,"children":2509},{"style":536},[2510],{"type":35,"value":2511}," client.aadd_messages(items)\n",{"type":29,"tag":441,"props":2513,"children":2514},{"class":525,"line":865},[2515],{"type":29,"tag":441,"props":2516,"children":2517},{"emptyLinePlaceholder":24},[2518],{"type":35,"value":1032},{"type":29,"tag":441,"props":2520,"children":2521},{"class":525,"line":881},[2522,2526,2530,2535,2539,2543,2547,2551,2555,2559],{"type":29,"tag":441,"props":2523,"children":2524},{"style":2091},[2525],{"type":35,"value":2270},{"type":29,"tag":441,"props":2527,"children":2528},{"style":2091},[2529],{"type":35,"value":2099},{"type":29,"tag":441,"props":2531,"children":2532},{"style":2060},[2533],{"type":35,"value":2534}," get_messages",{"type":29,"tag":441,"props":2536,"children":2537},{"style":536},[2538],{"type":35,"value":2068},{"type":29,"tag":441,"props":2540,"children":2541},{"style":2111},[2542],{"type":35,"value":2188},{"type":29,"tag":441,"props":2544,"children":2545},{"style":536},[2546],{"type":35,"value":2193},{"type":29,"tag":441,"props":2548,"children":2549},{"style":2111},[2550],{"type":35,"value":2296},{"type":29,"tag":441,"props":2552,"children":2553},{"style":536},[2554],{"type":35,"value":553},{"type":29,"tag":441,"props":2556,"children":2557},{"style":2303},[2558],{"type":35,"value":2306},{"type":29,"tag":441,"props":2560,"children":2561},{"style":536},[2562],{"type":35,"value":2563},") -> Sequence[BaseMessage]:\n",{"type":29,"tag":441,"props":2565,"children":2566},{"class":525,"line":898},[2567,2571,2575,2579,2583],{"type":29,"tag":441,"props":2568,"children":2569},{"style":536},[2570],{"type":35,"value":2479},{"type":29,"tag":441,"props":2572,"children":2573},{"style":2077},[2574],{"type":35,"value":2080},{"type":29,"tag":441,"props":2576,"children":2577},{"style":2077},[2578],{"type":35,"value":2488},{"type":29,"tag":441,"props":2580,"children":2581},{"style":2208},[2582],{"type":35,"value":2493},{"type":29,"tag":441,"props":2584,"children":2585},{"style":536},[2586],{"type":35,"value":2498},{"type":29,"tag":441,"props":2588,"children":2589},{"class":525,"line":915},[2590,2595,2599,2603],{"type":29,"tag":441,"props":2591,"children":2592},{"style":536},[2593],{"type":35,"value":2594},"            messages ",{"type":29,"tag":441,"props":2596,"children":2597},{"style":2077},[2598],{"type":35,"value":2080},{"type":29,"tag":441,"props":2600,"children":2601},{"style":2077},[2602],{"type":35,"value":2488},{"type":29,"tag":441,"props":2604,"children":2605},{"style":536},[2606],{"type":35,"value":2607}," client.aget_messages()\n",{"type":29,"tag":441,"props":2609,"children":2610},{"class":525,"line":928},[2611,2615],{"type":29,"tag":441,"props":2612,"children":2613},{"style":2077},[2614],{"type":35,"value":2379},{"type":29,"tag":441,"props":2616,"children":2617},{"style":536},[2618],{"type":35,"value":2619}," messages\n",{"type":29,"tag":441,"props":2621,"children":2622},{"class":525,"line":946},[2623],{"type":29,"tag":441,"props":2624,"children":2625},{"emptyLinePlaceholder":24},[2626],{"type":35,"value":1032},{"type":29,"tag":441,"props":2628,"children":2629},{"class":525,"line":959},[2630],{"type":29,"tag":441,"props":2631,"children":2632},{"style":1181},[2633],{"type":35,"value":2634},"        # case generation state management\n",{"type":29,"tag":441,"props":2636,"children":2637},{"class":525,"line":972},[2638,2642,2646,2651],{"type":29,"tag":441,"props":2639,"children":2640},{"style":2091},[2641],{"type":35,"value":2270},{"type":29,"tag":441,"props":2643,"children":2644},{"style":2091},[2645],{"type":35,"value":2099},{"type":29,"tag":441,"props":2647,"children":2648},{"style":2060},[2649],{"type":35,"value":2650}," save_case_description",{"type":29,"tag":441,"props":2652,"children":2653},{"style":536},[2654],{"type":35,"value":2420},{"type":29,"tag":441,"props":2656,"children":2657},{"class":525,"line":990},[2658,2662,2666,2671,2675,2679,2683,2688,2692],{"type":29,"tag":441,"props":2659,"children":2660},{"style":2111},[2661],{"type":35,"value":2211},{"type":29,"tag":441,"props":2663,"children":2664},{"style":536},[2665],{"type":35,"value":2193},{"type":29,"tag":441,"props":2667,"children":2668},{"style":2111},[2669],{"type":35,"value":2670},"case_description",{"type":29,"tag":441,"props":2672,"children":2673},{"style":536},[2674],{"type":35,"value":553},{"type":29,"tag":441,"props":2676,"children":2677},{"style":2303},[2678],{"type":35,"value":2306},{"type":29,"tag":441,"props":2680,"children":2681},{"style":536},[2682],{"type":35,"value":2193},{"type":29,"tag":441,"props":2684,"children":2685},{"style":2111},[2686],{"type":35,"value":2687},"case_id",{"type":29,"tag":441,"props":2689,"children":2690},{"style":536},[2691],{"type":35,"value":553},{"type":29,"tag":441,"props":2693,"children":2694},{"style":2303},[2695],{"type":35,"value":2454},{"type":29,"tag":441,"props":2697,"children":2698},{"class":525,"line":1008},[2699,2703,2707],{"type":29,"tag":441,"props":2700,"children":2701},{"style":536},[2702],{"type":35,"value":2462},{"type":29,"tag":441,"props":2704,"children":2705},{"style":556},[2706],{"type":35,"value":2467},{"type":29,"tag":441,"props":2708,"children":2709},{"style":536},[2710],{"type":35,"value":539},{"type":29,"tag":441,"props":2712,"children":2713},{"class":525,"line":1026},[2714],{"type":29,"tag":441,"props":2715,"children":2716},{"style":588},[2717],{"type":35,"value":2718},"            \"\"\"\n",{"type":29,"tag":441,"props":2720,"children":2721},{"class":525,"line":1035},[2722],{"type":29,"tag":441,"props":2723,"children":2724},{"style":588},[2725],{"type":35,"value":2726},"            sets the case description using the \u003Ccase_id>_case_description as the redis key\n",{"type":29,"tag":441,"props":2728,"children":2729},{"class":525,"line":1048},[2730],{"type":29,"tag":441,"props":2731,"children":2732},{"style":588},[2733],{"type":35,"value":2718},{"type":29,"tag":441,"props":2735,"children":2736},{"class":525,"line":1061},[2737,2741,2746,2751,2756,2761,2765,2770,2775],{"type":29,"tag":441,"props":2738,"children":2739},{"style":2208},[2740],{"type":35,"value":2211},{"type":29,"tag":441,"props":2742,"children":2743},{"style":536},[2744],{"type":35,"value":2745},".redis.set(",{"type":29,"tag":441,"props":2747,"children":2748},{"style":2091},[2749],{"type":35,"value":2750},"f",{"type":29,"tag":441,"props":2752,"children":2753},{"style":588},[2754],{"type":35,"value":2755},"\"",{"type":29,"tag":441,"props":2757,"children":2758},{"style":556},[2759],{"type":35,"value":2760},"{",{"type":29,"tag":441,"props":2762,"children":2763},{"style":536},[2764],{"type":35,"value":2687},{"type":29,"tag":441,"props":2766,"children":2767},{"style":556},[2768],{"type":35,"value":2769},"}",{"type":29,"tag":441,"props":2771,"children":2772},{"style":588},[2773],{"type":35,"value":2774},"_case_description\"",{"type":29,"tag":441,"props":2776,"children":2777},{"style":536},[2778],{"type":35,"value":2779},", case_description)\n",{"type":29,"tag":441,"props":2781,"children":2782},{"class":525,"line":1078},[2783],{"type":29,"tag":441,"props":2784,"children":2785},{"emptyLinePlaceholder":24},[2786],{"type":35,"value":1032},{"type":29,"tag":441,"props":2788,"children":2789},{"class":525,"line":1096},[2790],{"type":29,"tag":441,"props":2791,"children":2792},{"style":556},[2793],{"type":35,"value":2794},"        ...\n",{"type":29,"tag":38,"props":2796,"children":2797},{},[2798,2800,2806],{"type":35,"value":2799},"I found that LangChain has a ",{"type":29,"tag":427,"props":2801,"children":2803},{"className":2802},[],[2804],{"type":35,"value":2805},"RedisChatMessageHistory",{"type":35,"value":2807}," class that made putting this backend together almost trivial. Redis Stack also ships with a web viewer which really came in handy for debugging my memory backend:",{"type":29,"tag":38,"props":2809,"children":2810},{},[2811],{"type":29,"tag":192,"props":2812,"children":2815},{"alt":2813,"src":2814},"Reis Memory Backend","/static/mediation-simulator/redis.png",[],{"type":29,"tag":38,"props":2817,"children":2818},{},[2819],{"type":35,"value":2820},"For storing other types of data, I was able to implement my own methods and store things like case data or other metadata for a mediation simulator session for things like current_speaker, number of session, current session, etc. I love Redis! The setup is also really easy, I just added a docker compose file:",{"type":29,"tag":514,"props":2822,"children":2824},{"code":2823,"language":517,"meta":8,"className":518,"style":8},"services:\n  redis:\n    image: redis/redis-stack:latest\n    volumes:\n      - redis-data:/data\n    container_name: redis\n    ports:\n      - 6379:6379\n      - 8001:8001  # RedisInsight port\n\nvolumes:\n  redis-data:\n",[2825],{"type":29,"tag":427,"props":2826,"children":2827},{"__ignoreMap":8},[2828,2840,2852,2869,2881,2893,2910,2922,2934,2951,2958,2970],{"type":29,"tag":441,"props":2829,"children":2830},{"class":525,"line":526},[2831,2836],{"type":29,"tag":441,"props":2832,"children":2833},{"style":530},[2834],{"type":35,"value":2835},"services",{"type":29,"tag":441,"props":2837,"children":2838},{"style":536},[2839],{"type":35,"value":539},{"type":29,"tag":441,"props":2841,"children":2842},{"class":525,"line":542},[2843,2848],{"type":29,"tag":441,"props":2844,"children":2845},{"style":530},[2846],{"type":35,"value":2847},"  redis",{"type":29,"tag":441,"props":2849,"children":2850},{"style":536},[2851],{"type":35,"value":539},{"type":29,"tag":441,"props":2853,"children":2854},{"class":525,"line":562},[2855,2860,2864],{"type":29,"tag":441,"props":2856,"children":2857},{"style":530},[2858],{"type":35,"value":2859},"    image",{"type":29,"tag":441,"props":2861,"children":2862},{"style":536},[2863],{"type":35,"value":553},{"type":29,"tag":441,"props":2865,"children":2866},{"style":588},[2867],{"type":35,"value":2868},"redis/redis-stack:latest\n",{"type":29,"tag":441,"props":2870,"children":2871},{"class":525,"line":575},[2872,2877],{"type":29,"tag":441,"props":2873,"children":2874},{"style":530},[2875],{"type":35,"value":2876},"    volumes",{"type":29,"tag":441,"props":2878,"children":2879},{"style":536},[2880],{"type":35,"value":539},{"type":29,"tag":441,"props":2882,"children":2883},{"class":525,"line":594},[2884,2888],{"type":29,"tag":441,"props":2885,"children":2886},{"style":536},[2887],{"type":35,"value":703},{"type":29,"tag":441,"props":2889,"children":2890},{"style":588},[2891],{"type":35,"value":2892},"redis-data:/data\n",{"type":29,"tag":441,"props":2894,"children":2895},{"class":525,"line":607},[2896,2901,2905],{"type":29,"tag":441,"props":2897,"children":2898},{"style":530},[2899],{"type":35,"value":2900},"    container_name",{"type":29,"tag":441,"props":2902,"children":2903},{"style":536},[2904],{"type":35,"value":553},{"type":29,"tag":441,"props":2906,"children":2907},{"style":588},[2908],{"type":35,"value":2909},"redis\n",{"type":29,"tag":441,"props":2911,"children":2912},{"class":525,"line":631},[2913,2918],{"type":29,"tag":441,"props":2914,"children":2915},{"style":530},[2916],{"type":35,"value":2917},"    ports",{"type":29,"tag":441,"props":2919,"children":2920},{"style":536},[2921],{"type":35,"value":539},{"type":29,"tag":441,"props":2923,"children":2924},{"class":525,"line":644},[2925,2929],{"type":29,"tag":441,"props":2926,"children":2927},{"style":536},[2928],{"type":35,"value":703},{"type":29,"tag":441,"props":2930,"children":2931},{"style":588},[2932],{"type":35,"value":2933},"6379:6379\n",{"type":29,"tag":441,"props":2935,"children":2936},{"class":525,"line":658},[2937,2941,2946],{"type":29,"tag":441,"props":2938,"children":2939},{"style":536},[2940],{"type":35,"value":703},{"type":29,"tag":441,"props":2942,"children":2943},{"style":588},[2944],{"type":35,"value":2945},"8001:8001",{"type":29,"tag":441,"props":2947,"children":2948},{"style":1181},[2949],{"type":35,"value":2950},"  # RedisInsight port\n",{"type":29,"tag":441,"props":2952,"children":2953},{"class":525,"line":671},[2954],{"type":29,"tag":441,"props":2955,"children":2956},{"emptyLinePlaceholder":24},[2957],{"type":35,"value":1032},{"type":29,"tag":441,"props":2959,"children":2960},{"class":525,"line":684},[2961,2966],{"type":29,"tag":441,"props":2962,"children":2963},{"style":530},[2964],{"type":35,"value":2965},"volumes",{"type":29,"tag":441,"props":2967,"children":2968},{"style":536},[2969],{"type":35,"value":539},{"type":29,"tag":441,"props":2971,"children":2972},{"class":525,"line":697},[2973,2978],{"type":29,"tag":441,"props":2974,"children":2975},{"style":530},[2976],{"type":35,"value":2977},"  redis-data",{"type":29,"tag":441,"props":2979,"children":2980},{"style":536},[2981],{"type":35,"value":539},{"type":29,"tag":123,"props":2983,"children":2984},{"id":1486},[2985],{"type":29,"tag":427,"props":2986,"children":2988},{"className":2987},[],[2989],{"type":35,"value":1486},{"type":29,"tag":38,"props":2991,"children":2992},{},[2993],{"type":35,"value":2994},"Functions are the building blocks of the AIQ Toolkit. You need to register the functions in your config file, then you can use them for different things, like the function that handles an API route, or the function that handles an agentic workflow. I defined some functions for RAG to allow my agents to look up case data, but I wasn't able to fully implement this in my main mediation simualator workflow. But the setup was easy!",{"type":29,"tag":123,"props":2996,"children":2997},{"id":1819},[2998],{"type":29,"tag":427,"props":2999,"children":3001},{"className":3000},[],[3002],{"type":35,"value":1819},{"type":29,"tag":38,"props":3004,"children":3005},{},[3006],{"type":35,"value":3007},"Embedders is a section that allows you to define embedding models that you would use together with RAG (for converting text to a vector embedding). Since I needed to make a lot of embeddings for all of the documents I generated for case facts, I used a locally hosted NVIDIA NIM:",{"type":29,"tag":514,"props":3009,"children":3011},{"code":3010,"language":517,"meta":8,"className":518,"style":8},"embedders:\n  nv-embedqa-e5-v5:\n    _type: nim\n    base_url: http://192.168.5.96:8000/v1\n    model_name: nvidia/nv-embedqa-e5-v5\n",[3012],{"type":29,"tag":427,"props":3013,"children":3014},{"__ignoreMap":8},[3015,3026,3037,3052,3067],{"type":29,"tag":441,"props":3016,"children":3017},{"class":525,"line":526},[3018,3022],{"type":29,"tag":441,"props":3019,"children":3020},{"style":530},[3021],{"type":35,"value":1819},{"type":29,"tag":441,"props":3023,"children":3024},{"style":536},[3025],{"type":35,"value":539},{"type":29,"tag":441,"props":3027,"children":3028},{"class":525,"line":542},[3029,3033],{"type":29,"tag":441,"props":3030,"children":3031},{"style":530},[3032],{"type":35,"value":1832},{"type":29,"tag":441,"props":3034,"children":3035},{"style":536},[3036],{"type":35,"value":539},{"type":29,"tag":441,"props":3038,"children":3039},{"class":525,"line":562},[3040,3044,3048],{"type":29,"tag":441,"props":3041,"children":3042},{"style":530},[3043],{"type":35,"value":581},{"type":29,"tag":441,"props":3045,"children":3046},{"style":536},[3047],{"type":35,"value":553},{"type":29,"tag":441,"props":3049,"children":3050},{"style":588},[3051],{"type":35,"value":1235},{"type":29,"tag":441,"props":3053,"children":3054},{"class":525,"line":575},[3055,3059,3063],{"type":29,"tag":441,"props":3056,"children":3057},{"style":530},[3058],{"type":35,"value":1244},{"type":29,"tag":441,"props":3060,"children":3061},{"style":536},[3062],{"type":35,"value":553},{"type":29,"tag":441,"props":3064,"children":3065},{"style":588},[3066],{"type":35,"value":1869},{"type":29,"tag":441,"props":3068,"children":3069},{"class":525,"line":594},[3070,3074,3078],{"type":29,"tag":441,"props":3071,"children":3072},{"style":530},[3073],{"type":35,"value":1262},{"type":29,"tag":441,"props":3075,"children":3076},{"style":536},[3077],{"type":35,"value":553},{"type":29,"tag":441,"props":3079,"children":3080},{"style":588},[3081],{"type":35,"value":1886},{"type":29,"tag":38,"props":3083,"children":3084},{},[3085],{"type":35,"value":3086},"I would have run into rate limits if I was using the hosted version, so being able to run this locally was important for my use case.",{"type":29,"tag":123,"props":3088,"children":3089},{"id":1903},[3090],{"type":29,"tag":427,"props":3091,"children":3093},{"className":3092},[],[3094],{"type":35,"value":1903},{"type":29,"tag":38,"props":3096,"children":3097},{},[3098],{"type":35,"value":3099},"The workflow is the main \"application\" part of the config file. It is the entrypoint for your application. In my case, the workflow invokes a LangGraph that does my simulation. First it loads data from my memory backend and when I'm using the interactive mode it gathers information from the request like path parameters so it knows what data fetch from memory (like the case id and session id).",{"type":29,"tag":38,"props":3101,"children":3102},{},[3103],{"type":35,"value":3104},"My mediation workflow code is a little bit messy. I tried to keep all of my prompting logic in separate files for simplicity. The trickiest part for me was serializing data between different formats: langgraph state, YAML files and Redis memory. I'm happy to have something now that is functional, but there are a lot of improvements and further refactoring that would make the code easier to read and maintain.",{"type":29,"tag":38,"props":3106,"children":3107},{},[3108],{"type":35,"value":3109},"That wraps up the tour of my main config file for mediation simulator! I also had another smaller config file for case generation. Here's a quick look at that:",{"type":29,"tag":514,"props":3111,"children":3113},{"code":3112,"language":517,"meta":8,"className":518,"style":8},"general:\n  use_uvloop: true\n  telemetry:\n    enabled: false\n    tracing:\n      phoenix:\n        _type: phoenix\n        endpoint: http://localhost:6006/v1/traces\n        project: mediation-simulator\n\nllms:\n  nim_llm:\n    _type: nim\n    base_url: http://192.168.5.96:1234/v1\n    model_name: qwen3-8b\n    max_tokens: 10000\n    temperature: 0.7\n  # nim_llm:\n  #   _type: nim\n  #   model_name: meta/llama-3.1-70b-instruct\n  #   max_tokens: 10000\n  #   temperature: 0.7\n\nmemory:\n  redis_memory:\n    _type: redis_memory\n    connection_url: redis://localhost:6379/0\n\nworkflow:\n  _type: case_generation\n  llm_name: nim_llm\n  data_dir: ./data\n",[3114],{"type":29,"tag":427,"props":3115,"children":3116},{"__ignoreMap":8},[3117,3128,3143,3154,3169,3180,3191,3206,3221,3237,3244,3255,3266,3281,3296,3311,3326,3341,3349,3357,3365,3373,3381,3388,3399,3410,3425,3440,3447,3458,3474,3490],{"type":29,"tag":441,"props":3118,"children":3119},{"class":525,"line":526},[3120,3124],{"type":29,"tag":441,"props":3121,"children":3122},{"style":530},[3123],{"type":35,"value":533},{"type":29,"tag":441,"props":3125,"children":3126},{"style":536},[3127],{"type":35,"value":539},{"type":29,"tag":441,"props":3129,"children":3130},{"class":525,"line":542},[3131,3135,3139],{"type":29,"tag":441,"props":3132,"children":3133},{"style":530},[3134],{"type":35,"value":548},{"type":29,"tag":441,"props":3136,"children":3137},{"style":536},[3138],{"type":35,"value":553},{"type":29,"tag":441,"props":3140,"children":3141},{"style":556},[3142],{"type":35,"value":559},{"type":29,"tag":441,"props":3144,"children":3145},{"class":525,"line":562},[3146,3150],{"type":29,"tag":441,"props":3147,"children":3148},{"style":530},[3149],{"type":35,"value":921},{"type":29,"tag":441,"props":3151,"children":3152},{"style":536},[3153],{"type":35,"value":539},{"type":29,"tag":441,"props":3155,"children":3156},{"class":525,"line":575},[3157,3161,3165],{"type":29,"tag":441,"props":3158,"children":3159},{"style":530},[3160],{"type":35,"value":934},{"type":29,"tag":441,"props":3162,"children":3163},{"style":536},[3164],{"type":35,"value":553},{"type":29,"tag":441,"props":3166,"children":3167},{"style":556},[3168],{"type":35,"value":943},{"type":29,"tag":441,"props":3170,"children":3171},{"class":525,"line":594},[3172,3176],{"type":29,"tag":441,"props":3173,"children":3174},{"style":530},[3175],{"type":35,"value":952},{"type":29,"tag":441,"props":3177,"children":3178},{"style":536},[3179],{"type":35,"value":539},{"type":29,"tag":441,"props":3181,"children":3182},{"class":525,"line":607},[3183,3187],{"type":29,"tag":441,"props":3184,"children":3185},{"style":530},[3186],{"type":35,"value":965},{"type":29,"tag":441,"props":3188,"children":3189},{"style":536},[3190],{"type":35,"value":539},{"type":29,"tag":441,"props":3192,"children":3193},{"class":525,"line":631},[3194,3198,3202],{"type":29,"tag":441,"props":3195,"children":3196},{"style":530},[3197],{"type":35,"value":978},{"type":29,"tag":441,"props":3199,"children":3200},{"style":536},[3201],{"type":35,"value":553},{"type":29,"tag":441,"props":3203,"children":3204},{"style":588},[3205],{"type":35,"value":987},{"type":29,"tag":441,"props":3207,"children":3208},{"class":525,"line":644},[3209,3213,3217],{"type":29,"tag":441,"props":3210,"children":3211},{"style":530},[3212],{"type":35,"value":996},{"type":29,"tag":441,"props":3214,"children":3215},{"style":536},[3216],{"type":35,"value":553},{"type":29,"tag":441,"props":3218,"children":3219},{"style":588},[3220],{"type":35,"value":1005},{"type":29,"tag":441,"props":3222,"children":3223},{"class":525,"line":658},[3224,3228,3232],{"type":29,"tag":441,"props":3225,"children":3226},{"style":530},[3227],{"type":35,"value":1014},{"type":29,"tag":441,"props":3229,"children":3230},{"style":536},[3231],{"type":35,"value":553},{"type":29,"tag":441,"props":3233,"children":3234},{"style":588},[3235],{"type":35,"value":3236},"mediation-simulator\n",{"type":29,"tag":441,"props":3238,"children":3239},{"class":525,"line":671},[3240],{"type":29,"tag":441,"props":3241,"children":3242},{"emptyLinePlaceholder":24},[3243],{"type":35,"value":1032},{"type":29,"tag":441,"props":3245,"children":3246},{"class":525,"line":684},[3247,3251],{"type":29,"tag":441,"props":3248,"children":3249},{"style":530},[3250],{"type":35,"value":1201},{"type":29,"tag":441,"props":3252,"children":3253},{"style":536},[3254],{"type":35,"value":539},{"type":29,"tag":441,"props":3256,"children":3257},{"class":525,"line":697},[3258,3262],{"type":29,"tag":441,"props":3259,"children":3260},{"style":530},[3261],{"type":35,"value":1214},{"type":29,"tag":441,"props":3263,"children":3264},{"style":536},[3265],{"type":35,"value":539},{"type":29,"tag":441,"props":3267,"children":3268},{"class":525,"line":720},[3269,3273,3277],{"type":29,"tag":441,"props":3270,"children":3271},{"style":530},[3272],{"type":35,"value":581},{"type":29,"tag":441,"props":3274,"children":3275},{"style":536},[3276],{"type":35,"value":553},{"type":29,"tag":441,"props":3278,"children":3279},{"style":588},[3280],{"type":35,"value":1235},{"type":29,"tag":441,"props":3282,"children":3283},{"class":525,"line":737},[3284,3288,3292],{"type":29,"tag":441,"props":3285,"children":3286},{"style":530},[3287],{"type":35,"value":1244},{"type":29,"tag":441,"props":3289,"children":3290},{"style":536},[3291],{"type":35,"value":553},{"type":29,"tag":441,"props":3293,"children":3294},{"style":588},[3295],{"type":35,"value":1253},{"type":29,"tag":441,"props":3297,"children":3298},{"class":525,"line":755},[3299,3303,3307],{"type":29,"tag":441,"props":3300,"children":3301},{"style":530},[3302],{"type":35,"value":1262},{"type":29,"tag":441,"props":3304,"children":3305},{"style":536},[3306],{"type":35,"value":553},{"type":29,"tag":441,"props":3308,"children":3309},{"style":588},[3310],{"type":35,"value":1271},{"type":29,"tag":441,"props":3312,"children":3313},{"class":525,"line":773},[3314,3318,3322],{"type":29,"tag":441,"props":3315,"children":3316},{"style":530},[3317],{"type":35,"value":1280},{"type":29,"tag":441,"props":3319,"children":3320},{"style":536},[3321],{"type":35,"value":553},{"type":29,"tag":441,"props":3323,"children":3324},{"style":556},[3325],{"type":35,"value":1289},{"type":29,"tag":441,"props":3327,"children":3328},{"class":525,"line":794},[3329,3333,3337],{"type":29,"tag":441,"props":3330,"children":3331},{"style":530},[3332],{"type":35,"value":1298},{"type":29,"tag":441,"props":3334,"children":3335},{"style":536},[3336],{"type":35,"value":553},{"type":29,"tag":441,"props":3338,"children":3339},{"style":556},[3340],{"type":35,"value":1307},{"type":29,"tag":441,"props":3342,"children":3343},{"class":525,"line":810},[3344],{"type":29,"tag":441,"props":3345,"children":3346},{"style":1181},[3347],{"type":35,"value":3348},"  # nim_llm:\n",{"type":29,"tag":441,"props":3350,"children":3351},{"class":525,"line":827},[3352],{"type":29,"tag":441,"props":3353,"children":3354},{"style":1181},[3355],{"type":35,"value":3356},"  #   _type: nim\n",{"type":29,"tag":441,"props":3358,"children":3359},{"class":525,"line":844},[3360],{"type":29,"tag":441,"props":3361,"children":3362},{"style":1181},[3363],{"type":35,"value":3364},"  #   model_name: meta/llama-3.1-70b-instruct\n",{"type":29,"tag":441,"props":3366,"children":3367},{"class":525,"line":865},[3368],{"type":29,"tag":441,"props":3369,"children":3370},{"style":1181},[3371],{"type":35,"value":3372},"  #   max_tokens: 10000\n",{"type":29,"tag":441,"props":3374,"children":3375},{"class":525,"line":881},[3376],{"type":29,"tag":441,"props":3377,"children":3378},{"style":1181},[3379],{"type":35,"value":3380},"  #   temperature: 0.7\n",{"type":29,"tag":441,"props":3382,"children":3383},{"class":525,"line":898},[3384],{"type":29,"tag":441,"props":3385,"children":3386},{"emptyLinePlaceholder":24},[3387],{"type":35,"value":1032},{"type":29,"tag":441,"props":3389,"children":3390},{"class":525,"line":915},[3391,3395],{"type":29,"tag":441,"props":3392,"children":3393},{"style":530},[3394],{"type":35,"value":1417},{"type":29,"tag":441,"props":3396,"children":3397},{"style":536},[3398],{"type":35,"value":539},{"type":29,"tag":441,"props":3400,"children":3401},{"class":525,"line":928},[3402,3406],{"type":29,"tag":441,"props":3403,"children":3404},{"style":530},[3405],{"type":35,"value":1430},{"type":29,"tag":441,"props":3407,"children":3408},{"style":536},[3409],{"type":35,"value":539},{"type":29,"tag":441,"props":3411,"children":3412},{"class":525,"line":946},[3413,3417,3421],{"type":29,"tag":441,"props":3414,"children":3415},{"style":530},[3416],{"type":35,"value":581},{"type":29,"tag":441,"props":3418,"children":3419},{"style":536},[3420],{"type":35,"value":553},{"type":29,"tag":441,"props":3422,"children":3423},{"style":588},[3424],{"type":35,"value":1451},{"type":29,"tag":441,"props":3426,"children":3427},{"class":525,"line":959},[3428,3432,3436],{"type":29,"tag":441,"props":3429,"children":3430},{"style":530},[3431],{"type":35,"value":1460},{"type":29,"tag":441,"props":3433,"children":3434},{"style":536},[3435],{"type":35,"value":553},{"type":29,"tag":441,"props":3437,"children":3438},{"style":588},[3439],{"type":35,"value":1469},{"type":29,"tag":441,"props":3441,"children":3442},{"class":525,"line":972},[3443],{"type":29,"tag":441,"props":3444,"children":3445},{"emptyLinePlaceholder":24},[3446],{"type":35,"value":1032},{"type":29,"tag":441,"props":3448,"children":3449},{"class":525,"line":990},[3450,3454],{"type":29,"tag":441,"props":3451,"children":3452},{"style":530},[3453],{"type":35,"value":1903},{"type":29,"tag":441,"props":3455,"children":3456},{"style":536},[3457],{"type":35,"value":539},{"type":29,"tag":441,"props":3459,"children":3460},{"class":525,"line":1008},[3461,3465,3469],{"type":29,"tag":441,"props":3462,"children":3463},{"style":530},[3464],{"type":35,"value":1916},{"type":29,"tag":441,"props":3466,"children":3467},{"style":536},[3468],{"type":35,"value":553},{"type":29,"tag":441,"props":3470,"children":3471},{"style":588},[3472],{"type":35,"value":3473},"case_generation\n",{"type":29,"tag":441,"props":3475,"children":3476},{"class":525,"line":1026},[3477,3482,3486],{"type":29,"tag":441,"props":3478,"children":3479},{"style":530},[3480],{"type":35,"value":3481},"  llm_name",{"type":29,"tag":441,"props":3483,"children":3484},{"style":536},[3485],{"type":35,"value":553},{"type":29,"tag":441,"props":3487,"children":3488},{"style":588},[3489],{"type":35,"value":1555},{"type":29,"tag":441,"props":3491,"children":3492},{"class":525,"line":1035},[3493,3497,3501],{"type":29,"tag":441,"props":3494,"children":3495},{"style":530},[3496],{"type":35,"value":1951},{"type":29,"tag":441,"props":3498,"children":3499},{"style":536},[3500],{"type":35,"value":553},{"type":29,"tag":441,"props":3502,"children":3503},{"style":588},[3504],{"type":35,"value":1960},{"type":29,"tag":38,"props":3506,"children":3507},{},[3508],{"type":35,"value":3509},"I added a lot of logging to my workflow in order to keep an eye on how the workflows progressed. Here's a sample of the logs from the CLI invocation of the mediation simulator program:",{"type":29,"tag":514,"props":3511,"children":3513},{"code":3512},"12:08:48 mediation.register INFO   ‚öñÔ∏è [MEDIATOR]: Mediator node called\n12:08:56 mediation.register INFO   üë§ [CLERK] Starting clerk node - Phase: JOINT_DISCUSSION_INFO_GATHERING, Turn: 3\n12:08:56 mediation.register INFO   ü§î [CLERK] Using LLM to decide next speaker\n12:09:12 mediation.register INFO   üéØ [CLERK] LLM selected next speaker: RESPONDING_PARTY\n12:09:12 mediation.register INFO   üìä [CLERK] Updated counters - Turn: 4, Phase turns: 4\n12:09:12 mediation.register INFO   üåö Responding party node called\n12:09:20 mediation.register INFO   üë§ [CLERK] Starting clerk node - Phase: JOINT_DISCUSSION_INFO_GATHERING, Turn: 4\n12:09:20 mediation.register INFO   ü§î [CLERK] Using LLM to decide next speaker\n12:09:23 mediation.register INFO   üéØ [CLERK] LLM selected next speaker: REQUESTING_PARTY\n12:09:23 mediation.register INFO   üìä [CLERK] Updated counters - Turn: 5, Phase turns: 5\n12:09:23 mediation.register INFO   üåù Requesting party node called\n12:09:31 mediation.register INFO   üë§ [CLERK] Starting clerk node - Phase: JOINT_DISCUSSION_INFO_GATHERING, Turn: 5\n12:09:31 mediation.register INFO   ‚è∞ [CLERK] Max turns (5) reached for current phase\n12:09:31 mediation.register INFO   üîÑ [CLERK] Transitioning from joint discussion to negotiation\n12:09:31 mediation.register INFO   üë®‚Äç‚öñÔ∏è [CLERK] Mediator will start the new phase\n12:09:31 mediation.register INFO   ‚öñÔ∏è [MEDIATOR]: Mediator node called\n12:09:40 mediation.register INFO   üë§ [CLERK] Starting clerk node - Phase: NEGOTIATION_BARGAINING, Turn: 5\n12:09:40 mediation.register INFO   ü§î [CLERK] Using LLM to decide next speaker\n12:09:48 mediation.register INFO   üéØ [CLERK] LLM selected next speaker: REQUESTING_PARTY\n12:09:48 mediation.register INFO   üìä [CLERK] Updated counters - Turn: 6, Phase turns: 1\n12:09:48 mediation.register INFO   üåù Requesting party node called\n12:09:56 mediation.register INFO   üë§ [CLERK] Starting clerk node - Phase: NEGOTIATION_BARGAINING, Turn: 6\n12:09:56 mediation.register INFO   ü§î [CLERK] Using LLM to decide next speaker\n12:09:58 mediation.register INFO   üéØ [CLERK] LLM selected next speaker: RESPONDING_PARTY\n12:09:58 mediation.register INFO   üìä [CLERK] Updated counters - Turn: 7, Phase turns: 2\n",[3514],{"type":29,"tag":427,"props":3515,"children":3516},{"__ignoreMap":8},[3517],{"type":35,"value":3512},{"type":29,"tag":38,"props":3519,"children":3520},{},[3521],{"type":35,"value":3522},"Config files can be as simple or as complex as they need to be depending on your workflow.",{"type":29,"tag":38,"props":3524,"children":3525},{},[3526],{"type":35,"value":3527},"The AgentIQ Toolkit is doing something really valuable by bringing patterns and components from these (and other) frameworks into a cohesive system. This allows for some truly interesting and powerful combinations. The examples provided are excellent and taught me a lot about new patterns for building agentic workflows. ReWOO agents, for instance, were a new concept for me, as was seeing how to effectively combine LangGraph with LlamaIndex.",{"type":29,"tag":38,"props":3529,"children":3530},{},[3531],{"type":35,"value":3532},"What I particularly appreciated was:",{"type":29,"tag":88,"props":3534,"children":3535},{},[3536,3546,3556],{"type":29,"tag":92,"props":3537,"children":3538},{},[3539,3544],{"type":29,"tag":44,"props":3540,"children":3541},{},[3542],{"type":35,"value":3543},"Standardized Patterns:",{"type":35,"value":3545}," AgentIQ promotes good practices for crucial aspects of AI development, like evaluations and telemetry/tracing.",{"type":29,"tag":92,"props":3547,"children":3548},{},[3549,3554],{"type":29,"tag":44,"props":3550,"children":3551},{},[3552],{"type":35,"value":3553},"YAML Configuration:",{"type":35,"value":3555}," I really like using YAML for configuring development environments, similar to Docker Compose. It standardizes things and vastly improves readability. The way AgentIQ allows registering functions that can be included in workflows via YAML config files is a great example of this.",{"type":29,"tag":92,"props":3557,"children":3558},{},[3559,3564],{"type":29,"tag":44,"props":3560,"children":3561},{},[3562],{"type":35,"value":3563},"A Learning Goldmine:",{"type":35,"value":3565}," Working through as many examples as possible was incredibly beneficial. Reading the code helped me grasp the patterns underpinning AgentIQ. You are pretty much guaranteed to learn something new!",{"type":29,"tag":38,"props":3567,"children":3568},{},[3569],{"type":35,"value":3570},"I'm so glad I took the plunge and got my feet wet with the AgentIQ Toolkit. It's been a fantastic learning resource.",{"type":29,"tag":123,"props":3572,"children":3574},{"id":3573},"mediation-competitions-but-for-llms",[3575],{"type":35,"value":3576},"Mediation Competitions, But for LLMs?",{"type":29,"tag":38,"props":3578,"children":3579},{},[3580],{"type":35,"value":3581},"One of the fun, forward-looking ideas this project sparks is the concept of \"mediation competitions, but for LLMs.\" Imagine pitting different LLMs against each other, representing the requesting and responding parties, to see how they fare in these complex negotiation scenarios!",{"type":29,"tag":123,"props":3583,"children":3585},{"id":3584},"whats-next",[3586],{"type":35,"value":3587},"What's Next?",{"type":29,"tag":38,"props":3589,"children":3590},{},[3591],{"type":35,"value":3592},"This hackathon project has been an incredible learning journey. Building Mediation Simulator has not only been a fun technical challenge but has also opened my eyes to the potential of AI agents in simulating complex human interactions. I'm excited to continue refining it and exploring more possibilities with the AgentIQ Toolkit!",{"type":29,"tag":3594,"props":3595,"children":3596},"style",{},[3597],{"type":35,"value":3598},"html .default .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .shiki span {color: var(--shiki-default);background: var(--shiki-default-bg);font-style: var(--shiki-default-font-style);font-weight: var(--shiki-default-font-weight);text-decoration: var(--shiki-default-text-decoration);}html .dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html.dark .shiki span {color: var(--shiki-dark);background: var(--shiki-dark-bg);font-style: var(--shiki-dark-font-style);font-weight: var(--shiki-dark-font-weight);text-decoration: var(--shiki-dark-text-decoration);}html .sepia .shiki span {color: var(--shiki-sepia);background: var(--shiki-sepia-bg);font-style: var(--shiki-sepia-font-style);font-weight: var(--shiki-sepia-font-weight);text-decoration: var(--shiki-sepia-text-decoration);}html.sepia .shiki span {color: var(--shiki-sepia);background: var(--shiki-sepia-bg);font-style: var(--shiki-sepia-font-style);font-weight: var(--shiki-sepia-font-weight);text-decoration: var(--shiki-sepia-text-decoration);}",{"title":8,"searchDepth":542,"depth":542,"links":3600},[3601,3607],{"id":73,"depth":542,"text":76,"children":3602},[3603,3604,3605,3606],{"id":125,"depth":562,"text":128},{"id":222,"depth":562,"text":225},{"id":309,"depth":562,"text":312},{"id":463,"depth":562,"text":466},{"id":499,"depth":542,"text":502,"children":3608},[3609,3610,3611,3612,3613,3614,3615,3616,3617],{"id":533,"depth":562,"text":533},{"id":1041,"depth":562,"text":1041},{"id":1201,"depth":562,"text":1201},{"id":1417,"depth":562,"text":1417},{"id":1486,"depth":562,"text":1486},{"id":1819,"depth":562,"text":1819},{"id":1903,"depth":562,"text":1903},{"id":3573,"depth":562,"text":3576},{"id":3584,"depth":562,"text":3587},"markdown","content:2025:05:27:mediation-simulator-project-for-nvidia-agent-intelligence-toolkit.md","content","2025/05/27/mediation-simulator-project-for-nvidia-agent-intelligence-toolkit.md","2025/05/27/mediation-simulator-project-for-nvidia-agent-intelligence-toolkit","md",{"_path":3625,"_dir":3626,"_draft":7,"_partial":7,"_locale":8,"title":3627,"description":3628,"date":3629,"image":3630,"tags":3631,"draft":7,"external":3642,"comments":24,"body":3645,"_type":3618,"_id":4052,"_source":3620,"_file":4053,"_stem":4054,"_extension":3623},"/2024/06/24/agents-of-inference-speed-of-light-nvidia-langchain-generative-ai-agents-developer-contest-update","24","Agents of Inference: Speed of Light -- Accelerating my Generative AI Agents project with NVIDIA NIMs, TensorRT and TensorRT-LLM","This article is a brief discusion on recent updates to my project for the Generative AI Agents Developer Contest by NVIDIA and LangChain","2024-06-24","/static/aoi/aoi_title.png",[14,3632,16,3633,3634,3635,3636,15,17,3637,3638,3639,3640,3641],"langchain","rtx","gpu","tensorrt","tensorrt-llm","llama","007","stable-diffusion","stable-video-diffusion","comfyui",[3643],{"link":3644,"site":23},"https://x.com/briancaffey/status/1802754703207583886",{"type":26,"children":3646,"toc":4045},[3647,3653,3667,3672,3676,3689,3695,3700,3713,3721,3734,3742,3750,3755,3763,3768,3776,3781,3789,3848,3853,3861,3866,3874,3888,3894,3899,3907,3920,3928,3933,3941,3946,3952,3966,3971,3979,3984,3992,3997,4005,4010,4015,4021,4026,4035,4040],{"type":29,"tag":71,"props":3648,"children":3650},{"id":3649},"tldr",[3651],{"type":35,"value":3652},"tl;dr",{"type":29,"tag":38,"props":3654,"children":3655},{},[3656,3658,3665],{"type":35,"value":3657},"\"Agents of Inference: Speed of Light\" is an update to my original entry for the Generative AI Agents Developer Contest by NVIDIA and LangChain. This update focuses on how I accelerated local text, image and video generation using TensorRT, TensorRT-LLM and NVIDIA NIMs. You can read the original article about \"Agents of Inference\" ",{"type":29,"tag":57,"props":3659,"children":3662},{"href":3660,"rel":3661},"https://briancaffey.github.io/2024/06/17/agents-of-inference-nvidia-and-langchain-generative-ai-agent-developer-contest",[60],[3663],{"type":35,"value":3664},"here",{"type":35,"value":3666},".",{"type":29,"tag":38,"props":3668,"children":3669},{},[3670],{"type":35,"value":3671},"Here's my original project submission post on ùïè that introduces the idea of generating short 007-style films using agents, LLMs and stable diffusion:",{"type":29,"tag":3673,"props":3674,"children":3675},"agents-of-inference-tweet",{},[],{"type":29,"tag":38,"props":3677,"children":3678},{},[3679,3681,3688],{"type":35,"value":3680},"Here's a link to the ",{"type":29,"tag":57,"props":3682,"children":3685},{"href":3683,"rel":3684},"https://github.com/briancaffey/agents-of-inference",[60],[3686],{"type":35,"value":3687},"Agents of Inference code repository on GitHub",{"type":35,"value":3666},{"type":29,"tag":71,"props":3690,"children":3692},{"id":3691},"nvidia-nim-inference-microservices",[3693],{"type":35,"value":3694},"NVIDIA NIM inference microservices",{"type":29,"tag":38,"props":3696,"children":3697},{},[3698],{"type":35,"value":3699},"I thought NVIDIA NIMs was one of the most exciting announcements from GTC 2024. I'm a big fan of using docker containers everywhere, and the idea of standardizing NVIDIA tools and dependencies seemed to make a lot of sense. I had previously struggled to get TensorRT-LLM installed on Windows using example repos provided by NVIDIA.",{"type":29,"tag":38,"props":3701,"children":3702},{},[3703,3705,3711],{"type":35,"value":3704},"A few weeks ago NVIDIA announced that NVIDIA NIMs can be downloaded and run anywhere. I was able to download this NIM for the ",{"type":29,"tag":427,"props":3706,"children":3708},{"className":3707},[],[3709],{"type":35,"value":3710},"meta/llama3-8b-instruct",{"type":35,"value":3712}," model:",{"type":29,"tag":38,"props":3714,"children":3715},{},[3716],{"type":29,"tag":192,"props":3717,"children":3720},{"alt":3718,"src":3719},"llama3 nim","/static/aoi/meta-llama3-nim.png",[],{"type":29,"tag":38,"props":3722,"children":3723},{},[3724,3726,3732],{"type":35,"value":3725},"Here are the logs for my NVIDIA NIM ",{"type":29,"tag":427,"props":3727,"children":3729},{"className":3728},[],[3730],{"type":35,"value":3731},"Meta/Llama-3-8B-Instruct",{"type":35,"value":3733}," running in docker container on Windows Subsystem for Linux on my NVIDIA GeForce RTX 4090 GPU-powered PC. Notice that it generates over 50 tokens per second!",{"type":29,"tag":38,"props":3735,"children":3736},{},[3737],{"type":29,"tag":192,"props":3738,"children":3741},{"alt":3739,"src":3740},"trt llama3 local","/static/aoi/trt-llama3.png",[],{"type":29,"tag":38,"props":3743,"children":3744},{},[3745],{"type":29,"tag":192,"props":3746,"children":3749},{"alt":3747,"src":3748},"token factory","/static/aoi/token-factory.png",[],{"type":29,"tag":38,"props":3751,"children":3752},{},[3753],{"type":35,"value":3754},"The one main hurdle I faced when running the NIM local was an error about no runnable profiles being available:",{"type":29,"tag":514,"props":3756,"children":3758},{"code":3757},"ERROR 06-23 15:41:21.19 utils.py:21] Could not find a profile that is currently runnable with the detected hardware. Please check the system information below and make sure you have enough free GPUs.\nSYSTEM INFO\n- Free GPUs: \u003CNone>\n- Non-free GPUs:\n  -  [2684:10de] (0) NVIDIA GeForce RTX 4090 [current utilization: 7%]\n",[3759],{"type":29,"tag":427,"props":3760,"children":3761},{"__ignoreMap":8},[3762],{"type":35,"value":3757},{"type":29,"tag":38,"props":3764,"children":3765},{},[3766],{"type":35,"value":3767},"This seemed odd, and I found another user with the same issue on the NVIDIA Developer Forum. I was able to get around this by going into the EUFI/BIOS of my PC and switch to integrated graphics:",{"type":29,"tag":38,"props":3769,"children":3770},{},[3771],{"type":29,"tag":192,"props":3772,"children":3775},{"alt":3773,"src":3774},"bios","/static/aoi/bios.jpg",[],{"type":29,"tag":38,"props":3777,"children":3778},{},[3779],{"type":35,"value":3780},"It was great to be able to run \"Agents of Inference\" using NVIDIA NIM because it is just as simple as running a docker container:",{"type":29,"tag":514,"props":3782,"children":3784},{"code":3783},"export CONTAINER_NAME=llama3-8b-instruct\nexport IMG_NAME=\"nvcr.io/nim/meta/${CONTAINER_NAME}:1.0.0\"\nexport LOCAL_NIM_CACHE=~/.cache/nim\nmkdir -p \"$LOCAL_NIM_CACHE\"\ndocker run -it --rm --name=$CONTAINER_NAME \\\n  --runtime=nvidia \\\n  --gpus all \\\n  --shm-size=16GB \\\n  -e NGC_API_KEY \\\n  -v \"$LOCAL_NIM_CACHE:/opt/nim/.cache\" \\\n  -u $(id -u) \\\n  -p 8000:8000 \\\n  $IMG_NAME\n",[3785],{"type":29,"tag":427,"props":3786,"children":3787},{"__ignoreMap":8},[3788],{"type":35,"value":3783},{"type":29,"tag":38,"props":3790,"children":3791},{},[3792,3794,3800,3802,3809,3811,3817,3819,3830,3832,3838,3840,3846],{"type":35,"value":3793},"Before getting this to work, I was able to get a ",{"type":29,"tag":427,"props":3795,"children":3797},{"className":3796},[],[3798],{"type":35,"value":3799},"/chat/completions",{"type":35,"value":3801}," endpoint working with the Llama3 model on my fork of the ",{"type":29,"tag":57,"props":3803,"children":3806},{"href":3804,"rel":3805},"https://github.com/briancaffey/trt-llm-as-openai-windows/commit/edaa15fd026fe95e645e3d4ae9718dc3ecc3bb65",[60],[3807],{"type":35,"value":3808},"trt-llm-as-openai-windows",{"type":35,"value":3810},". I borrowed code for the ",{"type":29,"tag":427,"props":3812,"children":3814},{"className":3813},[],[3815],{"type":35,"value":3816},"TrtLlmAPI",{"type":35,"value":3818}," from the ",{"type":29,"tag":57,"props":3820,"children":3823},{"href":3821,"rel":3822},"https://github.com/NVIDIA/ChatRTX",[60],[3824],{"type":29,"tag":427,"props":3825,"children":3827},{"className":3826},[],[3828],{"type":35,"value":3829},"NVIDIA/ChatRTX",{"type":35,"value":3831}," repo and a function from ",{"type":29,"tag":427,"props":3833,"children":3835},{"className":3834},[],[3836],{"type":35,"value":3837},"llama-index",{"type":35,"value":3839}," called ",{"type":29,"tag":427,"props":3841,"children":3843},{"className":3842},[],[3844],{"type":35,"value":3845},"messages_to_prompt_v3_instruct",{"type":35,"value":3847}," which encodes messages with special tokens for chat. This was an interesting exercise and it taught me a lot about how LLMs do chat. I would like to continue working on this fork and see how to implement streaming endpoints for the Llama 3 model.",{"type":29,"tag":38,"props":3849,"children":3850},{},[3851],{"type":35,"value":3852},"Here is how Llama 3 does the instruct prompting:",{"type":29,"tag":514,"props":3854,"children":3856},{"code":3855},"\u003C|begin_of_text|>\u003C|start_header_id|>system\u003C|end_header_id|>\n\nYou are a helpful AI assistant for travel tips and recommendations\u003C|eot_id|>\u003C|start_header_id|>user\u003C|end_header_id|>\n\nWhat can you help me with?\u003C|eot_id|>\u003C|start_header_id|>assistant\u003C|end_header_id|>\n",[3857],{"type":29,"tag":427,"props":3858,"children":3859},{"__ignoreMap":8},[3860],{"type":35,"value":3855},{"type":29,"tag":38,"props":3862,"children":3863},{},[3864],{"type":35,"value":3865},"Compare this with how it was done with Llama2 chat:",{"type":29,"tag":514,"props":3867,"children":3869},{"code":3868},"\u003Cs>[INST] \u003C\u003CSYS>>\n{{ system_prompt }}\n\u003C\u003C/SYS>>\n\n{{ user_message_1 }} [/INST] {{ model_answer_1 }} \u003C/s>\n\u003Cs>[INST] {{ user_message_2 }} [/INST]\n",[3870],{"type":29,"tag":427,"props":3871,"children":3872},{"__ignoreMap":8},[3873],{"type":35,"value":3868},{"type":29,"tag":38,"props":3875,"children":3876},{},[3877,3879,3886],{"type":35,"value":3878},"You can read more about the difference between Llama 2 and 3 on the ",{"type":29,"tag":57,"props":3880,"children":3883},{"href":3881,"rel":3882},"https://llama.meta.com/docs/model-cards-and-prompt-formats",[60],[3884],{"type":35,"value":3885},"Model Card & Prompt formats",{"type":35,"value":3887}," page on Meta's Llama website.",{"type":29,"tag":71,"props":3889,"children":3891},{"id":3890},"langsmith",[3892],{"type":35,"value":3893},"LangSmith",{"type":29,"tag":38,"props":3895,"children":3896},{},[3897],{"type":35,"value":3898},"I recently started using LangSmith. It is an awesome product and it ties in really well to doing prototype work like in my project \"Agents of Inference\". I wish I had started using it earlier in my development cycle! All you need to do is add an API key to your environment and your application automatically starts tracing LLM calls. It also works well with LangGraph and allows you to trace the execution path of your graph. Also it is good to be aware that there are other products similar to LangSmith like LangFuse. I also saw a really neat demo from Datadog at GTC showing an alpha version of their LLM tracing and observability product.",{"type":29,"tag":38,"props":3900,"children":3901},{},[3902],{"type":29,"tag":192,"props":3903,"children":3906},{"alt":3904,"src":3905},"langsmith screenshot","/static/aoi/langsmith.png",[],{"type":29,"tag":38,"props":3908,"children":3909},{},[3910,3912,3918],{"type":35,"value":3911},"LangSmith can also be helpful when the wrong JSON shape is parsed. I had a lot of difficulty with this in my project. When I used the Q4_K_M gguf quantized ",{"type":29,"tag":427,"props":3913,"children":3915},{"className":3914},[],[3916],{"type":35,"value":3917},"Meta-Llama-3 8B-Instruct",{"type":35,"value":3919}," model I had no issues with output parsing. Switching to the TensorRT-LLM model provided by the NIM resulted in some parsing errors. The application would report that JSON could not be parsed because the result contained text like: \"Here is the JSON that you requested\". I was able to get around this by changing the prompt template from:",{"type":29,"tag":514,"props":3921,"children":3923},{"code":3922},"Answer the user query.\n",[3924],{"type":29,"tag":427,"props":3925,"children":3926},{"__ignoreMap":8},[3927],{"type":35,"value":3922},{"type":29,"tag":38,"props":3929,"children":3930},{},[3931],{"type":35,"value":3932},"to",{"type":29,"tag":514,"props":3934,"children":3936},{"code":3935},"Don't include ANYTHING except for valid JSON in your response. Answer the user query.\n",[3937],{"type":29,"tag":427,"props":3938,"children":3939},{"__ignoreMap":8},[3940],{"type":35,"value":3935},{"type":29,"tag":38,"props":3942,"children":3943},{},[3944],{"type":35,"value":3945},"This was the most frustrating part of development, and I'm still getting occasional errors that I just skip over. I'm also probably have not exhausted all of the tools that LangChain provides to avoid these types of errors. Don't assume that output parsing that works with one model will work with another! This is another good reason to use something like LangSmith when developing LLM-based applications.",{"type":29,"tag":71,"props":3947,"children":3949},{"id":3948},"comfyui-tensorrt",[3950],{"type":35,"value":3951},"ComfyUI TensorRT",{"type":29,"tag":38,"props":3953,"children":3954},{},[3955,3957,3964],{"type":35,"value":3956},"My goal with \"Agents of Inference\" was to be able to test out how small upstream prompt changes can impact the quality and consistency of a series of generated images and videos. Iteration speed is very important! I was able to significantly speed up image and video generation by using the ",{"type":29,"tag":57,"props":3958,"children":3961},{"href":3959,"rel":3960},"https://github.com/comfyanonymous/ComfyUI_TensorRT",[60],[3962],{"type":35,"value":3963},"ComfyUI TensorRT custom nodes",{"type":35,"value":3965},". These nodes allow you to build engines with specifications for parameters that can be either static or dynamic. I had better luck with building dynamic engines. I was able to build and use engines for Stable Diffusion SDXL and Stable Video Diffusion XT.",{"type":29,"tag":38,"props":3967,"children":3968},{},[3969],{"type":35,"value":3970},"Building a TensorRT engine for ComfyUI can be done using the following workflow:",{"type":29,"tag":38,"props":3972,"children":3973},{},[3974],{"type":29,"tag":192,"props":3975,"children":3978},{"alt":3976,"src":3977},"trt comfyUI build process","/static/aoi/comfyui-trt-svd-xt.png",[],{"type":29,"tag":38,"props":3980,"children":3981},{},[3982],{"type":35,"value":3983},"The engines can then be used in custom workflows like the following:",{"type":29,"tag":38,"props":3985,"children":3986},{},[3987],{"type":29,"tag":192,"props":3988,"children":3991},{"alt":3989,"src":3990},"trt comfyui workflow","/static/aoi/svd-workflow-trt.png",[],{"type":29,"tag":38,"props":3993,"children":3994},{},[3995],{"type":35,"value":3996},"Once these workflows are configured and are working as expected, you can export them in API format (JSON) and use them to make API calls to the ComfyUI backend. The agents for stable diffusion and stable video diffusion made API calls in this way and it worked pretty well.",{"type":29,"tag":38,"props":3998,"children":3999},{},[4000],{"type":29,"tag":192,"props":4001,"children":4004},{"alt":4002,"src":4003},"comfy its","/static/aoi/comfy-its.png",[],{"type":29,"tag":38,"props":4006,"children":4007},{},[4008],{"type":35,"value":4009},"Using 50 iterations, I was able to generate 1024x576 images in 3 seconds or about 19 iterations per second (it/s). Videos",{"type":29,"tag":38,"props":4011,"children":4012},{},[4013],{"type":35,"value":4014},"ComfyUI is still early in development and it refers to itself as \"alpha software\" even though it has a large adoption by a very active community already. I'm excited to see what is next from the developers of ComfyUI.",{"type":29,"tag":71,"props":4016,"children":4018},{"id":4017},"speed-of-light",[4019],{"type":35,"value":4020},"Speed of Light",{"type":29,"tag":38,"props":4022,"children":4023},{},[4024],{"type":35,"value":4025},"\"Speed of Light\" is a term that I learned from a stable diffusion talk at GTC.",{"type":29,"tag":4027,"props":4028,"children":4029},"blockquote",{},[4030],{"type":29,"tag":38,"props":4031,"children":4032},{},[4033],{"type":35,"value":4034},"SOL analysis reveals how your code performs, and device utilization compared to relevant maximums.",{"type":29,"tag":38,"props":4036,"children":4037},{},[4038],{"type":35,"value":4039},"Adding TensorRT and TensorRT-LLM to inference services on my RTX PC helped increase the throughput of text, image and video generation for my \"Agents of Inference\" project. I'm looking forward to learning more about profiling and optimization techniques for both LLMs and Stable Diffusion workloads.",{"type":29,"tag":38,"props":4041,"children":4042},{},[4043],{"type":35,"value":4044},"Thanks again to NVIDIA and LangChain for organizing this contest! It was a lot of fun to learn about builing agents with LangChain and LangGraph and the latest developments from NVIDIA in Generative AI.",{"title":8,"searchDepth":542,"depth":542,"links":4046},[4047,4048,4049,4050,4051],{"id":3649,"depth":542,"text":3652},{"id":3691,"depth":542,"text":3694},{"id":3890,"depth":542,"text":3893},{"id":3948,"depth":542,"text":3951},{"id":4017,"depth":542,"text":4020},"content:2024:06:24:agents-of-inference-speed-of-light-nvidia-langchain-generative-ai-agents-developer-contest-update.md","2024/06/24/agents-of-inference-speed-of-light-nvidia-langchain-generative-ai-agents-developer-contest-update.md","2024/06/24/agents-of-inference-speed-of-light-nvidia-langchain-generative-ai-agents-developer-contest-update",{"_path":4056,"_dir":4057,"_draft":7,"_partial":7,"_locale":8,"title":4058,"description":4059,"date":4060,"image":3630,"tags":4061,"draft":7,"external":4062,"comments":24,"body":4064,"_type":3618,"_id":5532,"_source":3620,"_file":5533,"_stem":5534,"_extension":3623},"/2024/06/17/agents-of-inference-nvidia-and-langchain-generative-ai-agent-developer-contest","17","Agents of Inference: My submission for NVIDIA's Generative AI Agents Developer Contest by NVIDIA and LangChain","This article discusses my entry for NVIDIA's Generative AI Agents Developer Contest entry: Agents of Inference","2024-06-17",[14,3632,16,3633,3634,3635,3636,15,17,3637,3638,3639,3640,3641],[4063],{"link":3644,"site":23},{"type":26,"children":4065,"toc":5511},[4066,4072,4083,4087,4092,4097,4100,4110,4116,4121,4127,4132,4138,4143,4186,4194,4199,4205,4210,4223,4236,4248,4605,4610,4653,4658,4818,4844,4850,4855,4959,4987,4994,4999,5005,5010,5089,5095,5100,5202,5210,5215,5220,5272,5293,5299,5320,5366,5371,5376,5382,5395,5403,5409,5413,5418,5423,5429,5434,5440,5445,5451,5456,5464,5469,5475,5487,5492,5497,5502,5507],{"type":29,"tag":71,"props":4067,"children":4069},{"id":4068},"update",[4070],{"type":35,"value":4071},"Update",{"type":29,"tag":38,"props":4073,"children":4074},{},[4075,4077],{"type":35,"value":4076},"I recently posted another article about optimizing this project with TensorRT and TensorRT-LLM running on local NVIDIA NIM inference microservices, please have a look here: ",{"type":29,"tag":57,"props":4078,"children":4081},{"href":4079,"rel":4080},"https://briancaffey.github.io/2024/06/24/agents-of-inference-speed-of-light-nvidia-langchain-generative-ai-agents-developer-contest-update",[60],[4082],{"type":35,"value":4079},{"type":29,"tag":71,"props":4084,"children":4085},{"id":3649},[4086],{"type":35,"value":3652},{"type":29,"tag":38,"props":4088,"children":4089},{},[4090],{"type":35,"value":4091},"‚ÄúAgents of Inference‚Äù is my entry for the Generative AI Agents Developer Contest by NVIDIA and LangChain. This project aims to integrate techniques for generating text, images and video to create an application capable of producing short thematic films. In this article, I will detail how I developed the project leveraging LangGraph‚Äîa library for building stateful, multi-actor applications with LLMs--and hybrid AI workflows using NVIDIA AI-powered tools and technologies running on RTX PCs and in the cloud.",{"type":29,"tag":38,"props":4093,"children":4094},{},[4095],{"type":35,"value":4096},"Here's my project submission post on ùïè:",{"type":29,"tag":3673,"props":4098,"children":4099},{},[],{"type":29,"tag":38,"props":4101,"children":4102},{},[4103,4104,4109],{"type":35,"value":3680},{"type":29,"tag":57,"props":4105,"children":4107},{"href":3683,"rel":4106},[60],[4108],{"type":35,"value":3687},{"type":35,"value":3666},{"type":29,"tag":71,"props":4111,"children":4113},{"id":4112},"nvidias-generative-ai-agents-developer-contest",[4114],{"type":35,"value":4115},"NVIDIA's Generative AI Agents Developer Contest",{"type":29,"tag":38,"props":4117,"children":4118},{},[4119],{"type":35,"value":4120},"AI agents are having a moment. They are the building blocks for building \"applications that reason\", and LangChain is a company that provides a comprehensive set of tools for developing, deploying and monitoring AI agents. I have struggled to understand how I can build or use agents in my own projects, and with the contest I have been able to just scratch the surface of what is possible with AI agents--but I think it is a promising paradigm for developing AI-driven applications.",{"type":29,"tag":71,"props":4122,"children":4124},{"id":4123},"coming-up-with-an-idea",[4125],{"type":35,"value":4126},"Coming up with an idea",{"type":29,"tag":38,"props":4128,"children":4129},{},[4130],{"type":35,"value":4131},"I love stable diffusion. I closely follow the development of the three leading applications for generating images with stable dissuion models: Stable Diffusion WebUI, InvokeAI and ComfyUI. Write a prompt, instantly see the result, tweak the prompt and generate again. This is the basic process by which I have previously used stable diffusion. It is a satisfying mental exercise that feeds the creative and imaginative part of my brain. My idea for this project came from wanting to automate this process: use large language models to build cohesive scenes and detailed prompts and then feed them into my stable diffusion programs via API. Using LangChain and LangGraph allowed me to rapidly prototype the idea and start generating short feature films in the style of my favorite British Secret Agent: 007.",{"type":29,"tag":71,"props":4133,"children":4135},{"id":4134},"putting-together-the-puzzle-pieces",[4136],{"type":35,"value":4137},"Putting together the puzzle pieces",{"type":29,"tag":38,"props":4139,"children":4140},{},[4141],{"type":35,"value":4142},"Here's how I set up an MVP for my project project to get started. I set up a simple graph (a linked list, really) that included the following nodes. *Important: in this context, a node is an agent, and that agent is a simple Python function. It takes one parameter which is the state, a Python dictionary, that holds the output of LLM calls that the agents make. Not all nodes make LLM calls, some just run basic functions like initializing directories or calling external stable diffusion APIs.",{"type":29,"tag":88,"props":4144,"children":4145},{},[4146,4151,4156,4161,4166,4171,4176,4181],{"type":29,"tag":92,"props":4147,"children":4148},{},[4149],{"type":35,"value":4150},"Casting Agent ‚Üí come up with some characters",{"type":29,"tag":92,"props":4152,"children":4153},{},[4154],{"type":35,"value":4155},"Location Agent ‚Üí come up with some locations",{"type":29,"tag":92,"props":4157,"children":4158},{},[4159],{"type":35,"value":4160},"Synopsis Agent ‚Üí write a synopsis based on the characters and locations",{"type":29,"tag":92,"props":4162,"children":4163},{},[4164],{"type":35,"value":4165},"Scene Agent ‚Üí write some number of scenes based on the synopsis based on the synopsis",{"type":29,"tag":92,"props":4167,"children":4168},{},[4169],{"type":35,"value":4170},"Shot agent ‚Üí describe some number of camera shots for each scene based on the scene",{"type":29,"tag":92,"props":4172,"children":4173},{},[4174],{"type":35,"value":4175},"Photography agent ‚Üí take each shot description and generate and image",{"type":29,"tag":92,"props":4177,"children":4178},{},[4179],{"type":35,"value":4180},"Videography agent ‚Üí take each image generated by the photography agent and convert it to a 4 second clip using stable video diffusion",{"type":29,"tag":92,"props":4182,"children":4183},{},[4184],{"type":35,"value":4185},"Editor agent ‚Üí compile the movie clips together",{"type":29,"tag":38,"props":4187,"children":4188},{},[4189],{"type":29,"tag":192,"props":4190,"children":4193},{"alt":4191,"src":4192},"simple graph of agents of inference","/static/aoi/graph.png",[],{"type":29,"tag":38,"props":4195,"children":4196},{},[4197],{"type":35,"value":4198},"It may look simple, but there is a lot going on in this graph.",{"type":29,"tag":123,"props":4200,"children":4202},{"id":4201},"casting-and-location",[4203],{"type":35,"value":4204},"Casting and Location",{"type":29,"tag":38,"props":4206,"children":4207},{},[4208],{"type":35,"value":4209},"The first two agents in my graph are tasked with generating characters and locations that would appear in a British secret agent film. The prompts used for these agents are as follows:",{"type":29,"tag":4027,"props":4211,"children":4212},{},[4213],{"type":29,"tag":38,"props":4214,"children":4215},{},[4216,4221],{"type":29,"tag":44,"props":4217,"children":4218},{},[4219],{"type":35,"value":4220},"casting",{"type":35,"value":4222},": \"Come up with four to five characters who will appear in an upcoming British spy movie. The list should include the main character who is male, the villain, an attractive female actress who eventually falls in love with the main character, and some other characters as well.\"",{"type":29,"tag":4027,"props":4224,"children":4225},{},[4226],{"type":29,"tag":38,"props":4227,"children":4228},{},[4229,4234],{"type":29,"tag":44,"props":4230,"children":4231},{},[4232],{"type":35,"value":4233},"locations",{"type":35,"value":4235},": \"Provide three main locations that can be used in an international British Spy movie. The locations should include a variety of cities, remote environments, iconic landmarks, etc. The locations should make for good background scenes for an action movie with lots of stunts, chases, explosions, fights, etc. and other things you would find in an action movie. Be sure to include the country and a description of the environment where these places are.\"",{"type":29,"tag":38,"props":4237,"children":4238},{},[4239,4241,4246],{"type":35,"value":4240},"These agents leverage the LangChain Expression Language (LCEL) to generate ",{"type":29,"tag":44,"props":4242,"children":4243},{},[4244],{"type":35,"value":4245},"structured output",{"type":35,"value":4247}," based on Pydantic models. For",{"type":29,"tag":514,"props":4249,"children":4251},{"code":4250,"language":2049,"meta":8,"className":2050,"style":8},"class Character(BaseModel):\n    \"\"\"\n    The type for character that the casting agent casts for a role in the movie\n    \"\"\"\n    full_name: str = Field(description=\"The character's name\")\n    short_name: str = Field(description=\"The character's short name\")\n    background: str = Field(description=\"The character's background\")\n    physical_traits: str = Field(description=\"The physical traits of the character\")\n    ethnicity: str = Field(description=\"The character's ethnicity\")\n    gender: str = Field(description=\"The character's gender, either male of female\")\n    nationality: str = Field(description=\"The character's nationality\")\n    main_character: bool = Field(description=\"If the character is or is not the main character\")\n\n",[4252],{"type":29,"tag":427,"props":4253,"children":4254},{"__ignoreMap":8},[4255,4281,4289,4297,4304,4345,4382,4419,4456,4493,4530,4567],{"type":29,"tag":441,"props":4256,"children":4257},{"class":525,"line":526},[4258,4263,4268,4272,4277],{"type":29,"tag":441,"props":4259,"children":4260},{"style":2091},[4261],{"type":35,"value":4262},"class",{"type":29,"tag":441,"props":4264,"children":4265},{"style":2147},[4266],{"type":35,"value":4267}," Character",{"type":29,"tag":441,"props":4269,"children":4270},{"style":536},[4271],{"type":35,"value":2068},{"type":29,"tag":441,"props":4273,"children":4274},{"style":2157},[4275],{"type":35,"value":4276},"BaseModel",{"type":29,"tag":441,"props":4278,"children":4279},{"style":536},[4280],{"type":35,"value":2165},{"type":29,"tag":441,"props":4282,"children":4283},{"class":525,"line":542},[4284],{"type":29,"tag":441,"props":4285,"children":4286},{"style":588},[4287],{"type":35,"value":4288},"    \"\"\"\n",{"type":29,"tag":441,"props":4290,"children":4291},{"class":525,"line":562},[4292],{"type":29,"tag":441,"props":4293,"children":4294},{"style":588},[4295],{"type":35,"value":4296},"    The type for character that the casting agent casts for a role in the movie\n",{"type":29,"tag":441,"props":4298,"children":4299},{"class":525,"line":575},[4300],{"type":29,"tag":441,"props":4301,"children":4302},{"style":588},[4303],{"type":35,"value":4288},{"type":29,"tag":441,"props":4305,"children":4306},{"class":525,"line":594},[4307,4312,4316,4321,4326,4331,4335,4340],{"type":29,"tag":441,"props":4308,"children":4309},{"style":536},[4310],{"type":35,"value":4311},"    full_name: ",{"type":29,"tag":441,"props":4313,"children":4314},{"style":2303},[4315],{"type":35,"value":2306},{"type":29,"tag":441,"props":4317,"children":4318},{"style":2077},[4319],{"type":35,"value":4320}," =",{"type":29,"tag":441,"props":4322,"children":4323},{"style":536},[4324],{"type":35,"value":4325}," Field(",{"type":29,"tag":441,"props":4327,"children":4328},{"style":2071},[4329],{"type":35,"value":4330},"description",{"type":29,"tag":441,"props":4332,"children":4333},{"style":2077},[4334],{"type":35,"value":2080},{"type":29,"tag":441,"props":4336,"children":4337},{"style":588},[4338],{"type":35,"value":4339},"\"The character's name\"",{"type":29,"tag":441,"props":4341,"children":4342},{"style":536},[4343],{"type":35,"value":4344},")\n",{"type":29,"tag":441,"props":4346,"children":4347},{"class":525,"line":607},[4348,4353,4357,4361,4365,4369,4373,4378],{"type":29,"tag":441,"props":4349,"children":4350},{"style":536},[4351],{"type":35,"value":4352},"    short_name: ",{"type":29,"tag":441,"props":4354,"children":4355},{"style":2303},[4356],{"type":35,"value":2306},{"type":29,"tag":441,"props":4358,"children":4359},{"style":2077},[4360],{"type":35,"value":4320},{"type":29,"tag":441,"props":4362,"children":4363},{"style":536},[4364],{"type":35,"value":4325},{"type":29,"tag":441,"props":4366,"children":4367},{"style":2071},[4368],{"type":35,"value":4330},{"type":29,"tag":441,"props":4370,"children":4371},{"style":2077},[4372],{"type":35,"value":2080},{"type":29,"tag":441,"props":4374,"children":4375},{"style":588},[4376],{"type":35,"value":4377},"\"The character's short name\"",{"type":29,"tag":441,"props":4379,"children":4380},{"style":536},[4381],{"type":35,"value":4344},{"type":29,"tag":441,"props":4383,"children":4384},{"class":525,"line":631},[4385,4390,4394,4398,4402,4406,4410,4415],{"type":29,"tag":441,"props":4386,"children":4387},{"style":536},[4388],{"type":35,"value":4389},"    background: ",{"type":29,"tag":441,"props":4391,"children":4392},{"style":2303},[4393],{"type":35,"value":2306},{"type":29,"tag":441,"props":4395,"children":4396},{"style":2077},[4397],{"type":35,"value":4320},{"type":29,"tag":441,"props":4399,"children":4400},{"style":536},[4401],{"type":35,"value":4325},{"type":29,"tag":441,"props":4403,"children":4404},{"style":2071},[4405],{"type":35,"value":4330},{"type":29,"tag":441,"props":4407,"children":4408},{"style":2077},[4409],{"type":35,"value":2080},{"type":29,"tag":441,"props":4411,"children":4412},{"style":588},[4413],{"type":35,"value":4414},"\"The character's background\"",{"type":29,"tag":441,"props":4416,"children":4417},{"style":536},[4418],{"type":35,"value":4344},{"type":29,"tag":441,"props":4420,"children":4421},{"class":525,"line":644},[4422,4427,4431,4435,4439,4443,4447,4452],{"type":29,"tag":441,"props":4423,"children":4424},{"style":536},[4425],{"type":35,"value":4426},"    physical_traits: ",{"type":29,"tag":441,"props":4428,"children":4429},{"style":2303},[4430],{"type":35,"value":2306},{"type":29,"tag":441,"props":4432,"children":4433},{"style":2077},[4434],{"type":35,"value":4320},{"type":29,"tag":441,"props":4436,"children":4437},{"style":536},[4438],{"type":35,"value":4325},{"type":29,"tag":441,"props":4440,"children":4441},{"style":2071},[4442],{"type":35,"value":4330},{"type":29,"tag":441,"props":4444,"children":4445},{"style":2077},[4446],{"type":35,"value":2080},{"type":29,"tag":441,"props":4448,"children":4449},{"style":588},[4450],{"type":35,"value":4451},"\"The physical traits of the character\"",{"type":29,"tag":441,"props":4453,"children":4454},{"style":536},[4455],{"type":35,"value":4344},{"type":29,"tag":441,"props":4457,"children":4458},{"class":525,"line":658},[4459,4464,4468,4472,4476,4480,4484,4489],{"type":29,"tag":441,"props":4460,"children":4461},{"style":536},[4462],{"type":35,"value":4463},"    ethnicity: ",{"type":29,"tag":441,"props":4465,"children":4466},{"style":2303},[4467],{"type":35,"value":2306},{"type":29,"tag":441,"props":4469,"children":4470},{"style":2077},[4471],{"type":35,"value":4320},{"type":29,"tag":441,"props":4473,"children":4474},{"style":536},[4475],{"type":35,"value":4325},{"type":29,"tag":441,"props":4477,"children":4478},{"style":2071},[4479],{"type":35,"value":4330},{"type":29,"tag":441,"props":4481,"children":4482},{"style":2077},[4483],{"type":35,"value":2080},{"type":29,"tag":441,"props":4485,"children":4486},{"style":588},[4487],{"type":35,"value":4488},"\"The character's ethnicity\"",{"type":29,"tag":441,"props":4490,"children":4491},{"style":536},[4492],{"type":35,"value":4344},{"type":29,"tag":441,"props":4494,"children":4495},{"class":525,"line":671},[4496,4501,4505,4509,4513,4517,4521,4526],{"type":29,"tag":441,"props":4497,"children":4498},{"style":536},[4499],{"type":35,"value":4500},"    gender: ",{"type":29,"tag":441,"props":4502,"children":4503},{"style":2303},[4504],{"type":35,"value":2306},{"type":29,"tag":441,"props":4506,"children":4507},{"style":2077},[4508],{"type":35,"value":4320},{"type":29,"tag":441,"props":4510,"children":4511},{"style":536},[4512],{"type":35,"value":4325},{"type":29,"tag":441,"props":4514,"children":4515},{"style":2071},[4516],{"type":35,"value":4330},{"type":29,"tag":441,"props":4518,"children":4519},{"style":2077},[4520],{"type":35,"value":2080},{"type":29,"tag":441,"props":4522,"children":4523},{"style":588},[4524],{"type":35,"value":4525},"\"The character's gender, either male of female\"",{"type":29,"tag":441,"props":4527,"children":4528},{"style":536},[4529],{"type":35,"value":4344},{"type":29,"tag":441,"props":4531,"children":4532},{"class":525,"line":684},[4533,4538,4542,4546,4550,4554,4558,4563],{"type":29,"tag":441,"props":4534,"children":4535},{"style":536},[4536],{"type":35,"value":4537},"    nationality: ",{"type":29,"tag":441,"props":4539,"children":4540},{"style":2303},[4541],{"type":35,"value":2306},{"type":29,"tag":441,"props":4543,"children":4544},{"style":2077},[4545],{"type":35,"value":4320},{"type":29,"tag":441,"props":4547,"children":4548},{"style":536},[4549],{"type":35,"value":4325},{"type":29,"tag":441,"props":4551,"children":4552},{"style":2071},[4553],{"type":35,"value":4330},{"type":29,"tag":441,"props":4555,"children":4556},{"style":2077},[4557],{"type":35,"value":2080},{"type":29,"tag":441,"props":4559,"children":4560},{"style":588},[4561],{"type":35,"value":4562},"\"The character's nationality\"",{"type":29,"tag":441,"props":4564,"children":4565},{"style":536},[4566],{"type":35,"value":4344},{"type":29,"tag":441,"props":4568,"children":4569},{"class":525,"line":697},[4570,4575,4580,4584,4588,4592,4596,4601],{"type":29,"tag":441,"props":4571,"children":4572},{"style":536},[4573],{"type":35,"value":4574},"    main_character: ",{"type":29,"tag":441,"props":4576,"children":4577},{"style":2303},[4578],{"type":35,"value":4579},"bool",{"type":29,"tag":441,"props":4581,"children":4582},{"style":2077},[4583],{"type":35,"value":4320},{"type":29,"tag":441,"props":4585,"children":4586},{"style":536},[4587],{"type":35,"value":4325},{"type":29,"tag":441,"props":4589,"children":4590},{"style":2071},[4591],{"type":35,"value":4330},{"type":29,"tag":441,"props":4593,"children":4594},{"style":2077},[4595],{"type":35,"value":2080},{"type":29,"tag":441,"props":4597,"children":4598},{"style":588},[4599],{"type":35,"value":4600},"\"If the character is or is not the main character\"",{"type":29,"tag":441,"props":4602,"children":4603},{"style":536},[4604],{"type":35,"value":4344},{"type":29,"tag":38,"props":4606,"children":4607},{},[4608],{"type":35,"value":4609},"LCEL offers wonderful syntactic sugar, I can use this model in a parse and pip that into the output from the mode:",{"type":29,"tag":514,"props":4611,"children":4613},{"code":4612,"language":2049,"meta":8,"className":2050,"style":8},"chain = prompt | model | parser\n",[4614],{"type":29,"tag":427,"props":4615,"children":4616},{"__ignoreMap":8},[4617],{"type":29,"tag":441,"props":4618,"children":4619},{"class":525,"line":526},[4620,4625,4629,4634,4639,4644,4648],{"type":29,"tag":441,"props":4621,"children":4622},{"style":536},[4623],{"type":35,"value":4624},"chain ",{"type":29,"tag":441,"props":4626,"children":4627},{"style":2077},[4628],{"type":35,"value":2080},{"type":29,"tag":441,"props":4630,"children":4631},{"style":536},[4632],{"type":35,"value":4633}," prompt ",{"type":29,"tag":441,"props":4635,"children":4636},{"style":2077},[4637],{"type":35,"value":4638},"|",{"type":29,"tag":441,"props":4640,"children":4641},{"style":536},[4642],{"type":35,"value":4643}," model ",{"type":29,"tag":441,"props":4645,"children":4646},{"style":2077},[4647],{"type":35,"value":4638},{"type":29,"tag":441,"props":4649,"children":4650},{"style":536},[4651],{"type":35,"value":4652}," parser\n",{"type":29,"tag":38,"props":4654,"children":4655},{},[4656],{"type":35,"value":4657},"This results in our structured data:",{"type":29,"tag":514,"props":4659,"children":4663},{"code":4660,"language":4661,"meta":8,"className":4662,"style":8},"cast:\n- background: Former MI6 agent\n  ethnicity: British\n  full_name: James Alexander\n  gender: Male\n  main_character: true\n  nationality: British\n  physical_traits: Tall, dark hair, blue eyes\n  short_name: Jamie\n","yml","language-yml shiki shiki-themes github-light github-dark monokai",[4664],{"type":29,"tag":427,"props":4665,"children":4666},{"__ignoreMap":8},[4667,4679,4701,4718,4735,4752,4768,4784,4801],{"type":29,"tag":441,"props":4668,"children":4669},{"class":525,"line":526},[4670,4675],{"type":29,"tag":441,"props":4671,"children":4672},{"style":530},[4673],{"type":35,"value":4674},"cast",{"type":29,"tag":441,"props":4676,"children":4677},{"style":536},[4678],{"type":35,"value":539},{"type":29,"tag":441,"props":4680,"children":4681},{"class":525,"line":542},[4682,4687,4692,4696],{"type":29,"tag":441,"props":4683,"children":4684},{"style":536},[4685],{"type":35,"value":4686},"- ",{"type":29,"tag":441,"props":4688,"children":4689},{"style":530},[4690],{"type":35,"value":4691},"background",{"type":29,"tag":441,"props":4693,"children":4694},{"style":536},[4695],{"type":35,"value":553},{"type":29,"tag":441,"props":4697,"children":4698},{"style":588},[4699],{"type":35,"value":4700},"Former MI6 agent\n",{"type":29,"tag":441,"props":4702,"children":4703},{"class":525,"line":562},[4704,4709,4713],{"type":29,"tag":441,"props":4705,"children":4706},{"style":530},[4707],{"type":35,"value":4708},"  ethnicity",{"type":29,"tag":441,"props":4710,"children":4711},{"style":536},[4712],{"type":35,"value":553},{"type":29,"tag":441,"props":4714,"children":4715},{"style":588},[4716],{"type":35,"value":4717},"British\n",{"type":29,"tag":441,"props":4719,"children":4720},{"class":525,"line":575},[4721,4726,4730],{"type":29,"tag":441,"props":4722,"children":4723},{"style":530},[4724],{"type":35,"value":4725},"  full_name",{"type":29,"tag":441,"props":4727,"children":4728},{"style":536},[4729],{"type":35,"value":553},{"type":29,"tag":441,"props":4731,"children":4732},{"style":588},[4733],{"type":35,"value":4734},"James Alexander\n",{"type":29,"tag":441,"props":4736,"children":4737},{"class":525,"line":594},[4738,4743,4747],{"type":29,"tag":441,"props":4739,"children":4740},{"style":530},[4741],{"type":35,"value":4742},"  gender",{"type":29,"tag":441,"props":4744,"children":4745},{"style":536},[4746],{"type":35,"value":553},{"type":29,"tag":441,"props":4748,"children":4749},{"style":588},[4750],{"type":35,"value":4751},"Male\n",{"type":29,"tag":441,"props":4753,"children":4754},{"class":525,"line":607},[4755,4760,4764],{"type":29,"tag":441,"props":4756,"children":4757},{"style":530},[4758],{"type":35,"value":4759},"  main_character",{"type":29,"tag":441,"props":4761,"children":4762},{"style":536},[4763],{"type":35,"value":553},{"type":29,"tag":441,"props":4765,"children":4766},{"style":556},[4767],{"type":35,"value":559},{"type":29,"tag":441,"props":4769,"children":4770},{"class":525,"line":631},[4771,4776,4780],{"type":29,"tag":441,"props":4772,"children":4773},{"style":530},[4774],{"type":35,"value":4775},"  nationality",{"type":29,"tag":441,"props":4777,"children":4778},{"style":536},[4779],{"type":35,"value":553},{"type":29,"tag":441,"props":4781,"children":4782},{"style":588},[4783],{"type":35,"value":4717},{"type":29,"tag":441,"props":4785,"children":4786},{"class":525,"line":644},[4787,4792,4796],{"type":29,"tag":441,"props":4788,"children":4789},{"style":530},[4790],{"type":35,"value":4791},"  physical_traits",{"type":29,"tag":441,"props":4793,"children":4794},{"style":536},[4795],{"type":35,"value":553},{"type":29,"tag":441,"props":4797,"children":4798},{"style":588},[4799],{"type":35,"value":4800},"Tall, dark hair, blue eyes\n",{"type":29,"tag":441,"props":4802,"children":4803},{"class":525,"line":658},[4804,4809,4813],{"type":29,"tag":441,"props":4805,"children":4806},{"style":530},[4807],{"type":35,"value":4808},"  short_name",{"type":29,"tag":441,"props":4810,"children":4811},{"style":536},[4812],{"type":35,"value":553},{"type":29,"tag":441,"props":4814,"children":4815},{"style":588},[4816],{"type":35,"value":4817},"Jamie\n",{"type":29,"tag":38,"props":4819,"children":4820},{},[4821,4823,4829,4831,4842],{"type":35,"value":4822},"I saved the state for all \"Agents of Inference\" invocations in the ",{"type":29,"tag":427,"props":4824,"children":4826},{"className":4825},[],[4827],{"type":35,"value":4828},"output",{"type":35,"value":4830}," directory of my ",{"type":29,"tag":57,"props":4832,"children":4835},{"href":4833,"rel":4834},"https://github.com/briancaffey/agents-of-inference/tree/main/output",[60],[4836],{"type":29,"tag":427,"props":4837,"children":4839},{"className":4838},[],[4840],{"type":35,"value":4841},"agents-of-inference",{"type":35,"value":4843}," GitHub repo. I didn't commit the images and videos, but you can follow @AgentInference on X to see more of the results from my development process and future improvements, as well!",{"type":29,"tag":123,"props":4845,"children":4847},{"id":4846},"synopsis-agent",[4848],{"type":35,"value":4849},"Synopsis Agent",{"type":29,"tag":38,"props":4851,"children":4852},{},[4853],{"type":35,"value":4854},"With a cast of characters and locations selected, we need a synopsis to determine what happens. Here's the prompt:",{"type":29,"tag":514,"props":4856,"children":4858},{"code":4857,"language":517,"meta":8,"className":518,"style":8},"synopsis: |\n  Generate a synopsis for a British spy agent movie in the style of the James Bond series. The synopsis should include the following elements:\n  Protagonist: A charismatic and skilled British secret agent with a code name (e.g., \"Agent X\") who works for a top-secret government agency (e.g., MI6).\n  Antagonist: A formidable villain with a grand, sinister plan that threatens global security. The antagonist should have a unique, memorable persona and a well-defined motivation.\n  Mission: Outline the high-stakes mission that the protagonist must undertake to thwart the antagonist‚Äôs plan.\n  Gadgets and Vehicles: Mention the cutting-edge gadgets and vehicles that the protagonist uses throughout the mission. These should be inventive and integral to the plot.\n  Action Sequences: Include a brief description of some thrilling action sequences, such as car, boat, plane chases, hand-to-hand combat, and daring escapes, and dangerous situations.\n  Big Reveal: There is a big reveal toward the end of the storyline that is surprising and the reveal helps to move the story along.\n  Climactic Showdown: Describe the final confrontation between the protagonist and the antagonist. This should be intense and action-packed, leading to a satisfying resolution. Should include details about the main character is victorious.\n  Setting: Ensure that the settings are diverse and visually striking, adding to the overall excitement and suspense of the story. This should involve multiple locations in exotic environments, the wilderness, in dangerous situations, on board planes, trains, boats and fancy cars, etc.\n  Tone and Style: Maintain the sophisticated, suave, and adventurous tone that is characteristic of the James Bond series. Include elements of intrigue, romance, and humor.\n",[4859],{"type":29,"tag":427,"props":4860,"children":4861},{"__ignoreMap":8},[4862,4879,4887,4895,4903,4911,4919,4927,4935,4943,4951],{"type":29,"tag":441,"props":4863,"children":4864},{"class":525,"line":526},[4865,4870,4874],{"type":29,"tag":441,"props":4866,"children":4867},{"style":530},[4868],{"type":35,"value":4869},"synopsis",{"type":29,"tag":441,"props":4871,"children":4872},{"style":536},[4873],{"type":35,"value":553},{"type":29,"tag":441,"props":4875,"children":4876},{"style":2077},[4877],{"type":35,"value":4878},"|\n",{"type":29,"tag":441,"props":4880,"children":4881},{"class":525,"line":542},[4882],{"type":29,"tag":441,"props":4883,"children":4884},{"style":588},[4885],{"type":35,"value":4886},"  Generate a synopsis for a British spy agent movie in the style of the James Bond series. The synopsis should include the following elements:\n",{"type":29,"tag":441,"props":4888,"children":4889},{"class":525,"line":562},[4890],{"type":29,"tag":441,"props":4891,"children":4892},{"style":588},[4893],{"type":35,"value":4894},"  Protagonist: A charismatic and skilled British secret agent with a code name (e.g., \"Agent X\") who works for a top-secret government agency (e.g., MI6).\n",{"type":29,"tag":441,"props":4896,"children":4897},{"class":525,"line":575},[4898],{"type":29,"tag":441,"props":4899,"children":4900},{"style":588},[4901],{"type":35,"value":4902},"  Antagonist: A formidable villain with a grand, sinister plan that threatens global security. The antagonist should have a unique, memorable persona and a well-defined motivation.\n",{"type":29,"tag":441,"props":4904,"children":4905},{"class":525,"line":594},[4906],{"type":29,"tag":441,"props":4907,"children":4908},{"style":588},[4909],{"type":35,"value":4910},"  Mission: Outline the high-stakes mission that the protagonist must undertake to thwart the antagonist‚Äôs plan.\n",{"type":29,"tag":441,"props":4912,"children":4913},{"class":525,"line":607},[4914],{"type":29,"tag":441,"props":4915,"children":4916},{"style":588},[4917],{"type":35,"value":4918},"  Gadgets and Vehicles: Mention the cutting-edge gadgets and vehicles that the protagonist uses throughout the mission. These should be inventive and integral to the plot.\n",{"type":29,"tag":441,"props":4920,"children":4921},{"class":525,"line":631},[4922],{"type":29,"tag":441,"props":4923,"children":4924},{"style":588},[4925],{"type":35,"value":4926},"  Action Sequences: Include a brief description of some thrilling action sequences, such as car, boat, plane chases, hand-to-hand combat, and daring escapes, and dangerous situations.\n",{"type":29,"tag":441,"props":4928,"children":4929},{"class":525,"line":644},[4930],{"type":29,"tag":441,"props":4931,"children":4932},{"style":588},[4933],{"type":35,"value":4934},"  Big Reveal: There is a big reveal toward the end of the storyline that is surprising and the reveal helps to move the story along.\n",{"type":29,"tag":441,"props":4936,"children":4937},{"class":525,"line":658},[4938],{"type":29,"tag":441,"props":4939,"children":4940},{"style":588},[4941],{"type":35,"value":4942},"  Climactic Showdown: Describe the final confrontation between the protagonist and the antagonist. This should be intense and action-packed, leading to a satisfying resolution. Should include details about the main character is victorious.\n",{"type":29,"tag":441,"props":4944,"children":4945},{"class":525,"line":671},[4946],{"type":29,"tag":441,"props":4947,"children":4948},{"style":588},[4949],{"type":35,"value":4950},"  Setting: Ensure that the settings are diverse and visually striking, adding to the overall excitement and suspense of the story. This should involve multiple locations in exotic environments, the wilderness, in dangerous situations, on board planes, trains, boats and fancy cars, etc.\n",{"type":29,"tag":441,"props":4952,"children":4953},{"class":525,"line":684},[4954],{"type":29,"tag":441,"props":4955,"children":4956},{"style":588},[4957],{"type":35,"value":4958},"  Tone and Style: Maintain the sophisticated, suave, and adventurous tone that is characteristic of the James Bond series. Include elements of intrigue, romance, and humor.\n",{"type":29,"tag":38,"props":4960,"children":4961},{},[4962,4964,4970,4972,4978,4980,4985],{"type":35,"value":4963},"The synopsis to any good film is key, so I decided to use a feature of LangGraph that would allow a ",{"type":29,"tag":427,"props":4965,"children":4967},{"className":4966},[],[4968],{"type":35,"value":4969},"synopsis_review_agent",{"type":35,"value":4971}," to provide multiple rounds of feedback to the ",{"type":29,"tag":427,"props":4973,"children":4975},{"className":4974},[],[4976],{"type":35,"value":4977},"synopsis_agent",{"type":35,"value":4979}," to make it even better. Here's what the new graph look like after implementing the ",{"type":29,"tag":427,"props":4981,"children":4983},{"className":4982},[],[4984],{"type":35,"value":4969},{"type":35,"value":4986}," using conditional graph edges:",{"type":29,"tag":38,"props":4988,"children":4989},{},[4990],{"type":29,"tag":192,"props":4991,"children":4993},{"alt":4969,"src":4992},"/static/aoi/graph_with_cycle.png",[],{"type":29,"tag":38,"props":4995,"children":4996},{},[4997],{"type":35,"value":4998},"Conditional edges are a very powerful feature and I just used it in one part of my graph. Other parts of the graph could benefit from this as well, and they can allow for \"human-in-the-loop\" interactions which are becoming very popular in AI-powered applications.",{"type":29,"tag":123,"props":5000,"children":5002},{"id":5001},"scene-and-shot-agents",[5003],{"type":35,"value":5004},"Scene and shot agents",{"type":29,"tag":38,"props":5006,"children":5007},{},[5008],{"type":35,"value":5009},"With our perfected synopsis, we are ready to put more agents to work. The scene agent builds out the basic structure of the storyline. It provides a structured list of the main sections of the movie. The shot agent then loops over the scenes and creates a number of different shots for the given scene. This was an effective way to have consistent thematic content for shots within a scene. Here are the prompts I used for the scene and shot agents:",{"type":29,"tag":514,"props":5011,"children":5013},{"code":5012,"language":517,"meta":8,"className":518,"style":8},"scenes: |\n  Create a list of detailed scenes for an exciting and entertaining British spy film. The scenes should be comprehensive and include all scenes necessary for a complete film. Each scene should include the following elements:\n  Location: Describe the location and setting of the scene, including any notable landmarks, time of day, and general atmosphere.\n  Characters Involved: List the main characters present in the scene, with a brief description of their roles and appearances.\n  Description of What Happens: Provide a detailed account of the action, and key events that take place in the scene.\nshot: |\n  You are a film director working on a new British spy film and your writers have provided you with a scene. Your task is to come up with four to five shots that will be filmed during the scene. The shot descriptions needs to be specific and should include a varietry of closeup shots on characters, environment shots that consider the scene location and shots of specific items or other things that are featured in the scene. Each shot should also have a title. The description should be a brief densely worded block of text that captures the important elements of the scene. Consider the style of camera angle, lighting, character expressions, clothing, and other important visual elements for each shot. Be very descriptive. The description will be used to generate an image of the shot. Also, there should be at most one actor for each shot that contains people. Don't use the name of the character, instead use a physical description of the character based on their physical traits described below if needed. Also consider what the actor is wearing in the description.\n",[5014],{"type":29,"tag":427,"props":5015,"children":5016},{"__ignoreMap":8},[5017,5033,5041,5049,5057,5065,5081],{"type":29,"tag":441,"props":5018,"children":5019},{"class":525,"line":526},[5020,5025,5029],{"type":29,"tag":441,"props":5021,"children":5022},{"style":530},[5023],{"type":35,"value":5024},"scenes",{"type":29,"tag":441,"props":5026,"children":5027},{"style":536},[5028],{"type":35,"value":553},{"type":29,"tag":441,"props":5030,"children":5031},{"style":2077},[5032],{"type":35,"value":4878},{"type":29,"tag":441,"props":5034,"children":5035},{"class":525,"line":542},[5036],{"type":29,"tag":441,"props":5037,"children":5038},{"style":588},[5039],{"type":35,"value":5040},"  Create a list of detailed scenes for an exciting and entertaining British spy film. The scenes should be comprehensive and include all scenes necessary for a complete film. Each scene should include the following elements:\n",{"type":29,"tag":441,"props":5042,"children":5043},{"class":525,"line":562},[5044],{"type":29,"tag":441,"props":5045,"children":5046},{"style":588},[5047],{"type":35,"value":5048},"  Location: Describe the location and setting of the scene, including any notable landmarks, time of day, and general atmosphere.\n",{"type":29,"tag":441,"props":5050,"children":5051},{"class":525,"line":575},[5052],{"type":29,"tag":441,"props":5053,"children":5054},{"style":588},[5055],{"type":35,"value":5056},"  Characters Involved: List the main characters present in the scene, with a brief description of their roles and appearances.\n",{"type":29,"tag":441,"props":5058,"children":5059},{"class":525,"line":594},[5060],{"type":29,"tag":441,"props":5061,"children":5062},{"style":588},[5063],{"type":35,"value":5064},"  Description of What Happens: Provide a detailed account of the action, and key events that take place in the scene.\n",{"type":29,"tag":441,"props":5066,"children":5067},{"class":525,"line":607},[5068,5073,5077],{"type":29,"tag":441,"props":5069,"children":5070},{"style":530},[5071],{"type":35,"value":5072},"shot",{"type":29,"tag":441,"props":5074,"children":5075},{"style":536},[5076],{"type":35,"value":553},{"type":29,"tag":441,"props":5078,"children":5079},{"style":2077},[5080],{"type":35,"value":4878},{"type":29,"tag":441,"props":5082,"children":5083},{"class":525,"line":631},[5084],{"type":29,"tag":441,"props":5085,"children":5086},{"style":588},[5087],{"type":35,"value":5088},"  You are a film director working on a new British spy film and your writers have provided you with a scene. Your task is to come up with four to five shots that will be filmed during the scene. The shot descriptions needs to be specific and should include a varietry of closeup shots on characters, environment shots that consider the scene location and shots of specific items or other things that are featured in the scene. Each shot should also have a title. The description should be a brief densely worded block of text that captures the important elements of the scene. Consider the style of camera angle, lighting, character expressions, clothing, and other important visual elements for each shot. Be very descriptive. The description will be used to generate an image of the shot. Also, there should be at most one actor for each shot that contains people. Don't use the name of the character, instead use a physical description of the character based on their physical traits described below if needed. Also consider what the actor is wearing in the description.\n",{"type":29,"tag":123,"props":5090,"children":5092},{"id":5091},"stable-diffusion-and-stable-video-diffusion-agents",[5093],{"type":35,"value":5094},"Stable Diffusion and Stable Video Diffusion agents",{"type":29,"tag":38,"props":5096,"children":5097},{},[5098],{"type":35,"value":5099},"The stable diffusion agent makes an API call to a local instance of the Stable Diffusion WebUI API, saves the generated image and saves a reference to that image in the state:",{"type":29,"tag":514,"props":5101,"children":5103},{"code":5102,"language":517,"meta":8,"className":518,"style":8},"- description: A medium close-up shot of Ethan Jameson's face, with a concerned expression,\n    as he reads the message from Natalie Jackson. The lighting is dim, with only a\n    single lamp on his desk casting a warm glow. His eyes are narrowed, and his brow\n    is furrowed in concentration. He is wearing a dark blue suit and a white shirt.\n  image: 000.png\n  title: Ethan's Concerned Expression\n  video: 000.mp4\n",[5104],{"type":29,"tag":427,"props":5105,"children":5106},{"__ignoreMap":8},[5107,5127,5135,5143,5151,5168,5185],{"type":29,"tag":441,"props":5108,"children":5109},{"class":525,"line":526},[5110,5114,5118,5122],{"type":29,"tag":441,"props":5111,"children":5112},{"style":536},[5113],{"type":35,"value":4686},{"type":29,"tag":441,"props":5115,"children":5116},{"style":530},[5117],{"type":35,"value":4330},{"type":29,"tag":441,"props":5119,"children":5120},{"style":536},[5121],{"type":35,"value":553},{"type":29,"tag":441,"props":5123,"children":5124},{"style":588},[5125],{"type":35,"value":5126},"A medium close-up shot of Ethan Jameson's face, with a concerned expression,\n",{"type":29,"tag":441,"props":5128,"children":5129},{"class":525,"line":542},[5130],{"type":29,"tag":441,"props":5131,"children":5132},{"style":588},[5133],{"type":35,"value":5134},"    as he reads the message from Natalie Jackson. The lighting is dim, with only a\n",{"type":29,"tag":441,"props":5136,"children":5137},{"class":525,"line":562},[5138],{"type":29,"tag":441,"props":5139,"children":5140},{"style":588},[5141],{"type":35,"value":5142},"    single lamp on his desk casting a warm glow. His eyes are narrowed, and his brow\n",{"type":29,"tag":441,"props":5144,"children":5145},{"class":525,"line":575},[5146],{"type":29,"tag":441,"props":5147,"children":5148},{"style":588},[5149],{"type":35,"value":5150},"    is furrowed in concentration. He is wearing a dark blue suit and a white shirt.\n",{"type":29,"tag":441,"props":5152,"children":5153},{"class":525,"line":594},[5154,5159,5163],{"type":29,"tag":441,"props":5155,"children":5156},{"style":530},[5157],{"type":35,"value":5158},"  image",{"type":29,"tag":441,"props":5160,"children":5161},{"style":536},[5162],{"type":35,"value":553},{"type":29,"tag":441,"props":5164,"children":5165},{"style":588},[5166],{"type":35,"value":5167},"000.png\n",{"type":29,"tag":441,"props":5169,"children":5170},{"class":525,"line":607},[5171,5176,5180],{"type":29,"tag":441,"props":5172,"children":5173},{"style":530},[5174],{"type":35,"value":5175},"  title",{"type":29,"tag":441,"props":5177,"children":5178},{"style":536},[5179],{"type":35,"value":553},{"type":29,"tag":441,"props":5181,"children":5182},{"style":588},[5183],{"type":35,"value":5184},"Ethan's Concerned Expression\n",{"type":29,"tag":441,"props":5186,"children":5187},{"class":525,"line":631},[5188,5193,5197],{"type":29,"tag":441,"props":5189,"children":5190},{"style":530},[5191],{"type":35,"value":5192},"  video",{"type":29,"tag":441,"props":5194,"children":5195},{"style":536},[5196],{"type":35,"value":553},{"type":29,"tag":441,"props":5198,"children":5199},{"style":588},[5200],{"type":35,"value":5201},"000.mp4\n",{"type":29,"tag":38,"props":5203,"children":5204},{},[5205],{"type":29,"tag":192,"props":5206,"children":5209},{"alt":5207,"src":5208},"A medium close-up shot of Ethan Jameson's face","/static/aoi/ethan.png",[],{"type":29,"tag":38,"props":5211,"children":5212},{},[5213],{"type":35,"value":5214},"With the perfectly prompted image in hand, we can use Stable Video Diffusion to bring it to life. I prompted phind to come up with a FastAPI service that would accept an image in a post request and return a short video created with stable video diffusion using the diffusers library.",{"type":29,"tag":38,"props":5216,"children":5217},{},[5218],{"type":35,"value":5219},"Stable video diffusion can generate about 4 seconds of text at 7 frames per second. This isn't great, but I was able to use ffmpeg to do frame interpolation bringing the frame rate to a much smoother 14 fps using motion compensated interpolation (MCI):",{"type":29,"tag":514,"props":5221,"children":5225},{"code":5222,"language":5223,"meta":8,"className":5224,"style":8},"ffmpeg -i output/1718453390/final.mp4 -crf 10 -vf \"minterpolate=fps=14:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1\" output/1718453390/final.14fps.mp4\n","bash","language-bash shiki shiki-themes github-light github-dark monokai",[5226],{"type":29,"tag":427,"props":5227,"children":5228},{"__ignoreMap":8},[5229],{"type":29,"tag":441,"props":5230,"children":5231},{"class":525,"line":526},[5232,5237,5242,5247,5252,5257,5262,5267],{"type":29,"tag":441,"props":5233,"children":5234},{"style":2060},[5235],{"type":35,"value":5236},"ffmpeg",{"type":29,"tag":441,"props":5238,"children":5239},{"style":556},[5240],{"type":35,"value":5241}," -i",{"type":29,"tag":441,"props":5243,"children":5244},{"style":588},[5245],{"type":35,"value":5246}," output/1718453390/final.mp4",{"type":29,"tag":441,"props":5248,"children":5249},{"style":556},[5250],{"type":35,"value":5251}," -crf",{"type":29,"tag":441,"props":5253,"children":5254},{"style":556},[5255],{"type":35,"value":5256}," 10",{"type":29,"tag":441,"props":5258,"children":5259},{"style":556},[5260],{"type":35,"value":5261}," -vf",{"type":29,"tag":441,"props":5263,"children":5264},{"style":588},[5265],{"type":35,"value":5266}," \"minterpolate=fps=14:mi_mode=mci:mc_mode=aobmc:me_mode=bidir:vsbmc=1\"",{"type":29,"tag":441,"props":5268,"children":5269},{"style":588},[5270],{"type":35,"value":5271}," output/1718453390/final.14fps.mp4\n",{"type":29,"tag":38,"props":5273,"children":5274},{},[5275,5277,5283,5285,5291],{"type":35,"value":5276},"Finally, the ",{"type":29,"tag":427,"props":5278,"children":5280},{"className":5279},[],[5281],{"type":35,"value":5282},"editor_agent",{"type":35,"value":5284}," uses ",{"type":29,"tag":427,"props":5286,"children":5288},{"className":5287},[],[5289],{"type":35,"value":5290},"moviepy",{"type":35,"value":5292}," to join the clips together into a single video.",{"type":29,"tag":71,"props":5294,"children":5296},{"id":5295},"development-environment",[5297],{"type":35,"value":5298},"Development environment",{"type":29,"tag":38,"props":5300,"children":5301},{},[5302,5304,5310,5312,5318],{"type":35,"value":5303},"I struggled to optimize the ",{"type":29,"tag":427,"props":5305,"children":5307},{"className":5306},[],[5308],{"type":35,"value":5309},"meta-llama/Meta-Llama-3-8B-Instruct",{"type":35,"value":5311}," with TensorRT-LLM, so I ran LLM inference on a combination of older Llama2 TensorRT-LLM models, and ",{"type":29,"tag":427,"props":5313,"children":5315},{"className":5314},[],[5316],{"type":35,"value":5317},"Meta-Llama-3-8B-Instruct",{"type":35,"value":5319}," on LM Studio (which I found to be painfully slow compared to TensorRT-LLM).",{"type":29,"tag":38,"props":5321,"children":5322},{},[5323,5325,5331,5333,5339,5341,5347,5349,5356,5358,5364],{"type":35,"value":5324},"If you provide an ",{"type":29,"tag":427,"props":5326,"children":5328},{"className":5327},[],[5329],{"type":35,"value":5330},"NVIDIA_API_KEY",{"type":35,"value":5332}," in the ",{"type":29,"tag":427,"props":5334,"children":5336},{"className":5335},[],[5337],{"type":35,"value":5338},".env",{"type":35,"value":5340}," file, LLM calls will be made using the ",{"type":29,"tag":427,"props":5342,"children":5344},{"className":5343},[],[5345],{"type":35,"value":5346},"meta/llam3-70b-instruct",{"type":35,"value":5348}," model on ",{"type":29,"tag":57,"props":5350,"children":5353},{"href":5351,"rel":5352},"https://build.nvidia.com/meta/llama3-70b",[60],[5354],{"type":35,"value":5355},"build.nvidia.com/meta/llama3-70b",{"type":35,"value":5357},". In fact, ",{"type":29,"tag":427,"props":5359,"children":5361},{"className":5360},[],[5362],{"type":35,"value":5363},"build.nvidia.com",{"type":35,"value":5365}," also provides stable diffusion and stable video diffusion inference via API. This would be very convenient in the event that my RTX PCs become compromised.",{"type":29,"tag":38,"props":5367,"children":5368},{},[5369],{"type":35,"value":5370},"My RTX 4090 GPU with 24 GB of memory was able to run lots of different inference servers concurrently (LLM, Stable Diffusion WebUI, ComfyUI, InvokeAI, Stable Video Diffusion FastAPI service), but I generally stuck to doing one type of inference at a time, otherwise things would grind to a hault or crash. I also experimented with ChatTTS, a new text-to-speech model.",{"type":29,"tag":38,"props":5372,"children":5373},{},[5374],{"type":35,"value":5375},"I developed this project on a MacBook Pro, and I used my RTX PC as if it were a remote service providing inference for text, images and video. This is a helpful mindset when working with hybrid AI workflows that leverage inference services both on local machines and in the cloud.",{"type":29,"tag":71,"props":5377,"children":5379},{"id":5378},"how-it-works",[5380],{"type":35,"value":5381},"How it works",{"type":29,"tag":38,"props":5383,"children":5384},{},[5385,5387,5393],{"type":35,"value":5386},"To run the program, you need to install python dependencies and then run an OpenAI compatible LLM and Stable Duffsion WebUI server with the ",{"type":29,"tag":427,"props":5388,"children":5390},{"className":5389},[],[5391],{"type":35,"value":5392},"--api",{"type":35,"value":5394}," flag. You also need to run the Stable Video Diffusion service. Apologies for any hardcoded local IP address in the source code. Deadlines, you know! With everything configured, you can run the following command:",{"type":29,"tag":514,"props":5396,"children":5398},{"code":5397},"~/git/github/agents-of-inference$ poetry run python agents_of_inference/main.py\n## üìÄ Using local models üìÄ ##\n## üé≠ Generating Cast üé≠ ##\n## üó∫Ô∏è Generating Locations üó∫Ô∏è ##\n## ‚úçÔ∏è Generating Synopsis ‚úçÔ∏è ##\n## going to synopsis_review_agent ##\n## üìë Reviewing Synopsis üìë ##\n## ‚úçÔ∏è Generating Synopsis ‚úçÔ∏è ##\n## going to synopsis_review_agent ##\n## üìë Reviewing Synopsis üìë ##\n## ‚úçÔ∏è Generating Synopsis ‚úçÔ∏è ##\n## going to scene_agent ##\n## üìí Generating Scenes üìí ##\n## üé¨ Generating Shots üé¨ ##\n## Generated 5 shots for scene 1/5 ##\n## Generated 5 shots for scene 2/5 ##\n## Generated 5 shots for scene 3/5 ##\n## Generated 5 shots for scene 4/5 ##\n## Generated 5 shots for scene 5/5 ##\n\n000/0025\nA medium shot of a bustling Tokyo street, with neon lights reflecting off wet pavement. Jim Thompson, dressed in a black leather jacket and dark jeans, walks purposefully through the crowd, his piercing blue eyes scanning the area. The sound design features the hum of traffic and chatter of pedestrians.\nGenerated image output/1718426686/images/000.png\n\n001/0025\nA tight close-up shot of Emily Chen's face, her piercing brown eyes intense as she briefs Jim on the situation. Her short black hair is styled neatly, and she wears a crisp white blouse with a silver necklace. The camera lingers on her lips as she speaks, emphasizing the importance of the information.\nGenerated image output/1718426686/images/001.png\n\nGenerated video output/1718426686/videos/000.mp4\n== stable video diffusion generation complete ==\nGenerated video output/1718426686/videos/001.mp4\n== stable video diffusion generation complete ==\n",[5399],{"type":29,"tag":427,"props":5400,"children":5401},{"__ignoreMap":8},[5402],{"type":35,"value":5397},{"type":29,"tag":71,"props":5404,"children":5406},{"id":5405},"demo-video-for-contest-submission",[5407],{"type":35,"value":5408},"Demo Video for Contest Submission",{"type":29,"tag":5410,"props":5411,"children":5412},"agents-of-inference-video",{},[],{"type":29,"tag":38,"props":5414,"children":5415},{},[5416],{"type":35,"value":5417},"Making this video was a lot of fun. The \"Agents of Inference\" highlight reel includes some of the most interesting, exciting and fun clips that I found in the dozens of short films it created. It is important to note that a lot of the content is not very good. Misunderstood prompts, color confusion (prompt includes green eyes, but other things in the scene are also conspicuously green), unrealistic or noisy motion from Stable Video Diffusion--these are some of the issues you will find in the films. Generating AI images sometimes feels like panning for gold: you go through a lot of sediment to get a few good flakes.",{"type":29,"tag":38,"props":5419,"children":5420},{},[5421],{"type":35,"value":5422},"Also, I added a few short animations that I made with Blender. The final scene shows the NVIDIA Omniverse orange humanoid from the barrel of a pistol. I think we are rapidly approaching a future where agents can generate full-scale theatrical movies by generating OpenUSD code, directly or indirectly. Maybe for the next NVIDIA Developer contest!",{"type":29,"tag":71,"props":5424,"children":5426},{"id":5425},"shortcomings-of-my-project",[5427],{"type":35,"value":5428},"Shortcomings of my project",{"type":29,"tag":38,"props":5430,"children":5431},{},[5432],{"type":35,"value":5433},"My goodness, how embarrasing. There are quite a few shortcomings that can be easily identified looking over the output and the source code. Here are a few:",{"type":29,"tag":123,"props":5435,"children":5437},{"id":5436},"character-variety",[5438],{"type":35,"value":5439},"Character variety",{"type":29,"tag":38,"props":5441,"children":5442},{},[5443],{"type":35,"value":5444},"When generating characters I would frequently see one named Dr. Sophia Patel who is apparently a brilliant cryptologist. Other characters would often have different names or backgrounds, but a saw Dr. Sophia Patel more often than not.",{"type":29,"tag":123,"props":5446,"children":5448},{"id":5447},"character-consistency",[5449],{"type":35,"value":5450},"Character consistency",{"type":29,"tag":38,"props":5452,"children":5453},{},[5454],{"type":35,"value":5455},"The characters are not consistent. This is a notoriously difficult problem to solve, but I made a lot of progress on it during this contest. I experimented with calling the ComfyUI API to run a custom workflow built with the ComfyUI graph-based workflow tool for face transfer:",{"type":29,"tag":38,"props":5457,"children":5458},{},[5459],{"type":29,"tag":192,"props":5460,"children":5463},{"alt":5461,"src":5462},"Dr. Sophia Patel","/static/aoi/sophia.png",[],{"type":29,"tag":38,"props":5465,"children":5466},{},[5467],{"type":35,"value":5468},"Using ComfyUI would be nice, but it wouldn't be as easy to tap into cloud APIs if my workflow heavily relied on ComfyUI server with custom models.",{"type":29,"tag":123,"props":5470,"children":5472},{"id":5471},"understanding-langchain",[5473],{"type":35,"value":5474},"Understanding LangChain",{"type":29,"tag":38,"props":5476,"children":5477},{},[5478,5480,5485],{"type":35,"value":5479},"I started out with the idea I would store all LLM calls to a local JSON to serve as a cache, allowing me to avoid regenerating responses from early in the workflow. This worked well, until I tried to serialize an Annotated list (required for cycles such as the one used with ",{"type":29,"tag":427,"props":5481,"children":5483},{"className":5482},[],[5484],{"type":35,"value":4969},{"type":35,"value":5486},"). I ended up wasting a lot of time trying to figure this out, and I came across some built-in LangChain features for storing state in memory and in Sqlite. I'm sure there are other areas where I used the wrong pattern, but I turned over a lot of stones and look forward to continuing development with LangChain.",{"type":29,"tag":71,"props":5488,"children":5489},{"id":3584},[5490],{"type":35,"value":5491},"What's next?",{"type":29,"tag":38,"props":5493,"children":5494},{},[5495],{"type":35,"value":5496},"Thank you to NVIDIA and LangChain for organizing this contest. It was a great way to explore a powerful toolset for automated content generation using AI agents.",{"type":29,"tag":38,"props":5498,"children":5499},{},[5500],{"type":35,"value":5501},"Video models like Dream Machine and Sora have made some big splashes on the internet and the results are remarkable. However, I'm still almost more interested in finding the limitations of quality content using open-source models on consumer hardware like RTX GPUs.",{"type":29,"tag":38,"props":5503,"children":5504},{},[5505],{"type":35,"value":5506},"I would also have loved to generate my own music for these films. I am a Suno poweruser and love the songs I have generated on that site. Will the gap between video and music generation on private, payed services and local machines? Or does it just need time to catch up? Hopefully a future installment of \"Agents of Inference\" will integrate music and voice, and can't wait to hear it!",{"type":29,"tag":3594,"props":5508,"children":5509},{},[5510],{"type":35,"value":3598},{"title":8,"searchDepth":542,"depth":542,"links":5512},[5513,5514,5515,5516,5517,5523,5524,5525,5526,5531],{"id":4068,"depth":542,"text":4071},{"id":3649,"depth":542,"text":3652},{"id":4112,"depth":542,"text":4115},{"id":4123,"depth":542,"text":4126},{"id":4134,"depth":542,"text":4137,"children":5518},[5519,5520,5521,5522],{"id":4201,"depth":562,"text":4204},{"id":4846,"depth":562,"text":4849},{"id":5001,"depth":562,"text":5004},{"id":5091,"depth":562,"text":5094},{"id":5295,"depth":542,"text":5298},{"id":5378,"depth":542,"text":5381},{"id":5405,"depth":542,"text":5408},{"id":5425,"depth":542,"text":5428,"children":5527},[5528,5529,5530],{"id":5436,"depth":562,"text":5439},{"id":5447,"depth":562,"text":5450},{"id":5471,"depth":562,"text":5474},{"id":3584,"depth":542,"text":5491},"content:2024:06:17:agents-of-inference-nvidia-and-langchain-generative-ai-agent-developer-contest.md","2024/06/17/agents-of-inference-nvidia-and-langchain-generative-ai-agent-developer-contest.md","2024/06/17/agents-of-inference-nvidia-and-langchain-generative-ai-agent-developer-contest",1748368251903]