<!doctype html>
<html data-n-head-ssr lang="en" data-n-head="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>Related subreddit graph exploration with NetworkX</title><meta data-n-head="ssr" charset="utf-8"><meta data-n-head="ssr" name="viewport" content="width=device-width,initial-scale=1"><meta data-n-head="ssr" data-hid="description" name="description" content="Brian Caffey's personal website"><meta data-n-head="ssr" name="robots" content="all"><meta data-n-head="ssr" property="og:title" content="Related subreddit graph exploration with NetworkX"><meta data-n-head="ssr" property="og:description" content="undefined"><meta data-n-head="ssr" property="og:image" content="https://briancaffey.github.io/static/subreddits.png"><link data-n-head="ssr" rel="icon" type="image/x-icon" href="/favicon.ico"><link rel="preload" href="/_nuxt/eff76a4.js" as="script"><link rel="preload" href="/_nuxt/35383e5.js" as="script"><link rel="preload" href="/_nuxt/e161084.js" as="script"><link rel="preload" href="/_nuxt/223edee.js" as="script"><link rel="preload" href="/_nuxt/64fe595.js" as="script"><style data-vue-ssr-id="38dfa7e4:0 f52d43e0:0 517a8dd7:0 fa7ff0ca:0 56b15182:0">/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{line-height:1.15;-webkit-text-size-adjust:100%}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}details{display:block}summary{display:list-item}[hidden],template{display:none}blockquote,dd,dl,figure,h1,h2,h3,h4,h5,h6,hr,p,pre{margin:0}button{background-color:transparent;background-image:none}button:focus{outline:1px dotted;outline:5px auto -webkit-focus-ring-color}fieldset,ol,ul{margin:0;padding:0}ol,ul{list-style:none}html{font-family:system-ui,-apple-system,Segoe UI,Roboto,Ubuntu,Cantarell,Noto Sans,sans-serif,BlinkMacSystemFont,"Segoe UI","Helvetica Neue",Arial,"Noto Sans","Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";line-height:1.5}*,:after,:before{box-sizing:border-box;border:0 solid #e2e8f0}hr{border-top-width:1px}img{border-style:solid}textarea{resize:vertical}input::-moz-placeholder,textarea::-moz-placeholder{color:#a0aec0}input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#a0aec0}input::placeholder,textarea::placeholder{color:#a0aec0}[role=button],button{cursor:pointer}table{border-collapse:collapse}h1,h2,h3,h4,h5,h6{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}button,input,optgroup,select,textarea{padding:0;line-height:inherit;color:inherit}code,kbd,pre,samp{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace}audio,canvas,embed,iframe,img,object,svg,video{display:block;vertical-align:middle}img,video{max-width:100%;height:auto}.container{width:100%}@media (min-width:640px){.container{max-width:640px}}@media (min-width:768px){.container{max-width:768px}}@media (min-width:1024px){.container{max-width:1024px}}@media (min-width:1280px){.container{max-width:1280px}}.bg-white{--bg-opacity:1;background-color:#fff;background-color:rgba(255,255,255,var(--bg-opacity))}.bg-red-300{--bg-opacity:1;background-color:#feb2b2;background-color:rgba(254,178,178,var(--bg-opacity))}.border-white{--border-opacity:1;border-color:#fff;border-color:rgba(255,255,255,var(--border-opacity))}.rounded{border-radius:.25rem}.rounded-md{border-radius:.375rem}.rounded-lg{border-radius:.5rem}.rounded-full{border-radius:9999px}.rounded-t{border-top-left-radius:.25rem;border-top-right-radius:.25rem}.border{border-width:1px}.cursor-pointer{cursor:pointer}.block{display:block}.inline-block{display:inline-block}.inline{display:inline}.flex{display:flex}.table{display:table}.grid{display:grid}.contents{display:contents}.hidden{display:none}.flex-wrap{flex-wrap:wrap}.items-center{align-items:center}.justify-end{justify-content:flex-end}.justify-center{justify-content:center}.flex-1{flex:1 1 0%}.font-bold{font-weight:700}.h-3{height:.75rem}.h-4{height:1rem}.h-12{height:3rem}.h-32{height:8rem}.h-64{height:16rem}.text-sm{font-size:.875rem}.text-xl{font-size:1.25rem}.text-2xl{font-size:1.5rem}.text-3xl{font-size:1.875rem}.leading-8{line-height:2rem}.leading-9{line-height:2.25rem}.m-2{margin:.5rem}.m-4{margin:1rem}.mx-1{margin-left:.25rem;margin-right:.25rem}.my-4{margin-top:1rem;margin-bottom:1rem}.mx-auto{margin-left:auto;margin-right:auto}.mt-1{margin-top:.25rem}.mt-2{margin-top:.5rem}.mt-4{margin-top:1rem}.mb-4{margin-bottom:1rem}.-ml-1{margin-left:-.25rem}.-ml-3{margin-left:-.75rem}.-ml-20{margin-left:-5rem}.max-w-5xl{max-width:64rem}.max-w-6xl{max-width:72rem}.object-cover{-o-object-fit:cover;object-fit:cover}.p-3{padding:.75rem}.p-4{padding:1rem}.py-1{padding-top:.25rem;padding-bottom:.25rem}.px-1{padding-left:.25rem;padding-right:.25rem}.py-2{padding-top:.5rem;padding-bottom:.5rem}.px-2{padding-left:.5rem;padding-right:.5rem}.px-3{padding-left:.75rem;padding-right:.75rem}.py-4{padding-top:1rem;padding-bottom:1rem}.px-4{padding-left:1rem;padding-right:1rem}.py-8{padding-top:2rem;padding-bottom:2rem}.py-32{padding-top:8rem;padding-bottom:8rem}.pt-4{padding-top:1rem}.pr-4{padding-right:1rem}.pb-4{padding-bottom:1rem}.pt-8{padding-top:2rem}.pb-8{padding-bottom:2rem}.pt-16{padding-top:4rem}.static{position:static}.fixed{position:fixed}.absolute{position:absolute}.relative{position:relative}.inset-0{top:0;right:0;bottom:0;left:0}.top-0{top:0}.right-0{right:0}.bottom-0{bottom:0}.left-0{left:0}.resize{resize:both}.shadow{box-shadow:0 1px 3px 0 rgba(0,0,0,.1),0 1px 2px 0 rgba(0,0,0,.06)}.shadow-md{box-shadow:0 4px 6px -1px rgba(0,0,0,.1),0 2px 4px -1px rgba(0,0,0,.06)}.fill-current{fill:currentColor}.text-left{text-align:left}.text-center{text-align:center}.text-right{text-align:right}.text-black{--text-opacity:1;color:#000;color:rgba(0,0,0,var(--text-opacity))}.text-gray-500{--text-opacity:1;color:#a0aec0;color:rgba(160,174,192,var(--text-opacity))}.text-gray-600{--text-opacity:1;color:#718096;color:rgba(113,128,150,var(--text-opacity))}.text-red-400{--text-opacity:1;color:#fc8181;color:rgba(252,129,129,var(--text-opacity))}.text-red-600{--text-opacity:1;color:#e53e3e;color:rgba(229,62,62,var(--text-opacity))}.uppercase{text-transform:uppercase}.visible{visibility:visible}.w-3{width:.75rem}.w-4{width:1rem}.w-12{width:3rem}.w-32{width:8rem}.w-full{width:100%}.z-10{z-index:10}.gap-4{grid-gap:1rem;gap:1rem}.gap-6{grid-gap:1.5rem;gap:1.5rem}.gap-8{grid-gap:2rem;gap:2rem}.grid-cols-1{grid-template-columns:repeat(1,minmax(0,1fr))}.grid-cols-3{grid-template-columns:repeat(3,minmax(0,1fr))}.grid-cols-5{grid-template-columns:repeat(5,minmax(0,1fr))}.transform{--transform-translate-x:0;--transform-translate-y:0;--transform-rotate:0;--transform-skew-x:0;--transform-skew-y:0;--transform-scale-x:1;--transform-scale-y:1;transform:translateX(var(--transform-translate-x)) translateY(var(--transform-translate-y)) rotate(var(--transform-rotate)) skewX(var(--transform-skew-x)) skewY(var(--transform-skew-y)) scaleX(var(--transform-scale-x)) scaleY(var(--transform-scale-y))}.transition-all{transition-property:all}.transition{transition-property:background-color,border-color,color,fill,stroke,opacity,box-shadow,transform}.duration-150{transition-duration:.15s}.delay-150{transition-delay:.15s}@-webkit-keyframes spin{to{transform:rotate(1turn)}}@keyframes spin{to{transform:rotate(1turn)}}@-webkit-keyframes ping{75%,to{transform:scale(2);opacity:0}}@keyframes ping{75%,to{transform:scale(2);opacity:0}}@-webkit-keyframes pulse{50%{opacity:.5}}@keyframes pulse{50%{opacity:.5}}@-webkit-keyframes bounce{0%,to{transform:translateY(-25%);-webkit-animation-timing-function:cubic-bezier(.8,0,1,1);animation-timing-function:cubic-bezier(.8,0,1,1)}50%{transform:none;-webkit-animation-timing-function:cubic-bezier(0,0,.2,1);animation-timing-function:cubic-bezier(0,0,.2,1)}}@keyframes bounce{0%,to{transform:translateY(-25%);-webkit-animation-timing-function:cubic-bezier(.8,0,1,1);animation-timing-function:cubic-bezier(.8,0,1,1)}50%{transform:none;-webkit-animation-timing-function:cubic-bezier(0,0,.2,1);animation-timing-function:cubic-bezier(0,0,.2,1)}}@media (min-width:640px){.sm\:inline{display:inline}.sm\:hidden{display:none}.sm\:p-16{padding:4rem}.sm\:px-4{padding-left:1rem;padding-right:1rem}.sm\:w-2\/3{width:66.666667%}.sm\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}}@media (min-width:768px){.md\:flex{display:flex}.md\:hidden{display:none}.md\:px-4{padding-left:1rem;padding-right:1rem}.md\:w-1\/2{width:50%}.md\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}.md\:grid-cols-3{grid-template-columns:repeat(3,minmax(0,1fr))}}@media (min-width:1024px){.lg\:px-16{padding-left:4rem;padding-right:4rem}.lg\:px-32{padding-left:8rem;padding-right:8rem}.lg\:pl-64{padding-left:16rem}.lg\:grid-cols-2{grid-template-columns:repeat(2,minmax(0,1fr))}}@media (min-width:1280px){.xl\:pb-16{padding-bottom:4rem}}:root{--color:#243746;--color-primary:#158876;--color-secondary:#0e2233;--bg:#f3f5f4;--bg-secondary:#fff;--bg-code:#ddd;--border-color:#ddd}.dark-mode{--color:#ebf4f1;--color-primary:#41b38a;--color-secondary:#fdf9f3;--bg:#091a28;--bg-secondary:#071521;--bg-code:#ddd;--border-color:#0d2538}.sepia-mode{--color:#433422;--color-primary:#504231;--color-secondary:#504231;--bg:#f1e7d0;--bg-code:#ddd;--bg-secondary:#eae0c9;--border-color:#ded0bf}body{font-family:-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Open Sans","Helvetica Neue",sans-serif;background-color:#f3f5f4;background-color:var(--bg);color:#243746;color:var(--color);transition:background-color .3s}a{color:#158876;color:var(--color-primary)}.py-05{padding-top:.125rem;padding-bottom:.125rem}.markdown{--text-opacity:1;color:#1a202c;color:rgba(26,32,44,var(--text-opacity));line-height:1.5;color:#0e2233;color:var(--color-secondary)}.markdown .token.operator{background:0 0}.markdown>*+*{margin-top:0;margin-bottom:1rem}.markdown li+li{margin-top:.25rem}.markdown li>p+p{margin-top:1.5rem;color:#158876;color:var(--color-primary)}.markdown img{margin:auto}.markdown a,.markdown strong{font-weight:600}.markdown strong a{font-weight:700}.markdown h1{font-size:2.25rem}.markdown h1,.markdown h2{border-color:#158876;border-color:var(--color-primary);line-height:1.25;border-bottom-width:1px;font-weight:600;margin-bottom:1rem;margin-top:1.5rem;padding-bottom:.5rem}.markdown h2{font-size:1.5rem}.markdown h3{line-height:1.375;font-size:1.125rem}.markdown h3,.markdown h4{border-color:#158876;border-color:var(--color-primary);font-weight:600;margin-bottom:1rem;margin-top:1.5rem}.markdown h4{line-height:1;font-size:1rem}.markdown h5{border-color:#158876;border-color:var(--color-primary)}.markdown h5,.markdown h6{line-height:1.25;font-size:.875rem;font-weight:600;margin-bottom:1rem;margin-top:1.5rem}.markdown blockquote,.markdown h6{--text-opacity:1;color:#718096;color:rgba(113,128,150,var(--text-opacity))}.markdown blockquote{font-size:1rem;border-left-width:4px;--border-opacity:1;border-color:#e2e8f0;border-color:rgba(226,232,240,var(--border-opacity));padding-left:1rem;padding-right:1rem;border-color:#158876;border-color:var(--color-primary)}.markdown code{font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;font-size:.875rem;display:inline;background-color:#edf2f7;background-color:rgba(237,242,247,var(--bg-opacity));padding:.125rem .25rem;background-color:#ddd;background-color:var(--bg-code);color:#000}.markdown code,.markdown pre{--bg-opacity:1;border-radius:.25rem}.markdown pre{background-color:#f7fafc;background-color:rgba(247,250,252,var(--bg-opacity));padding:1rem}.markdown pre code{display:block;background-color:transparent;padding:0;overflow:visible;border-radius:0;color:#000}.markdown p{margin-bottom:10px}code[class*=language-],pre[class*=language-]{background:#ddd!important;background:var(--bg-code)!important;text-shadow:none!important}.markdown ul{list-style-type:disc}.markdown ol,.markdown ul{font-size:1rem;padding-left:2rem}.markdown ol{list-style-type:decimal}.markdown kbd{font-size:.75rem;display:inline-block;border-radius:.25rem;border-width:1px;padding:.125rem .25rem;vertical-align:middle;font-weight:400;font-family:Menlo,Monaco,Consolas,"Liberation Mono","Courier New",monospace;box-shadow:0 1px 3px 0 rgba(0,0,0,.1),0 1px 2px 0 rgba(0,0,0,.06)}.markdown table,td,th{font-size:1rem;border:1px solid #243746;border-color:var(--color)}.markdown table{overflow-x:scroll}.markdown td,.markdown th{border-width:1px;padding:.25rem .75rem}.markdown .highlight pre{--bg-opacity:1!important;background-color:#f7fafc!important;background-color:rgba(247,250,252,var(--bg-opacity))!important}.article-card{box-shadow:0 5px 10px 1px #0e2233;box-shadow:0 5px 10px 1px var(--color-secondary);height:100%}.article-card:hover{box-shadow:0 5px 15px 5px #0e2233;box-shadow:0 5px 15px 5px var(--color-secondary)}.blog-card-description,.blog-date{color:#0e2233;color:var(--color-secondary)}.blog-date{font-style:italic}hr{background-color:#243746;background-color:var(--color);border:none;height:1px}.menu-icon{background-color:#ddd;background-color:var(--border-color)}.menu-icon,.mobile-menu{color:#243746;color:var(--color)}.mobile-menu{background-color:#fff;background-color:var(--bg-secondary)}.btn{border-radius:1;border-color:#158876;border-color:var(--color-primary)}.btn:hover{background-color:#fff;background-color:var(--bg-secondary)}.hero{border-color:#158876;border-color:var(--color-primary)}.markdown{word-wrap:break-word}.markdown h2:before,.markdown h3:before{display:block;content:" ";margin-top:-85px;height:85px;visibility:hidden;pointer-events:none}.markdown h2>a,.markdown h3>a{margin-left:1.25rem}.markdown h2>a:before,.markdown h3>a:before{content:"#";font-weight:400;font-size:1.25rem;line-height:2rem;margin-left:-1.25rem;padding-right:.5rem;position:absolute;opacity:1}@media (min-width:1024px){.markdown h2>a,.markdown h3>a{margin-left:0}.markdown h2>a:before,.markdown h3>a:before{opacity:0}}.markdown h2:hover>a:before,.markdown h3:hover>a:before{opacity:1}& pre[class*=language-]{--bg-opacity:1;background-color:#2d3748;background-color:rgba(45,55,72,var(--bg-opacity));position:static}.mc{background-color:#f3f5f4;background-color:var(--bg);border-color:#158876;border-color:var(--color-primary);border-width:1px;color:#158876;color:var(--color-primary);justify-content:center;padding:5px 10px;border-radius:5px;width:100%}.mc-btn{color:#fff;color:var(--bg-secondary);background-color:#0e2233;background-color:var(--color-secondary);cursor:pointer}code[class*=language-],pre[class*=language-]{color:#000;background:0 0;text-shadow:0 1px #fff;font-family:Consolas,Monaco,"Andale Mono","Ubuntu Mono",monospace;font-size:1em;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.5;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-ms-hyphens:none;hyphens:none}code[class*=language-] ::-moz-selection,code[class*=language-]::-moz-selection,pre[class*=language-] ::-moz-selection,pre[class*=language-]::-moz-selection{text-shadow:none;background:#b3d4fc}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{text-shadow:none;background:#b3d4fc}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}pre[class*=language-]{padding:1em;margin:.5em 0;overflow:auto}:not(pre)>code[class*=language-],pre[class*=language-]{background:#f5f2f0}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#999}.token.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#905}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#690}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url{color:#9a6e3a;background:hsla(0,0%,100%,.5)}.token.atrule,.token.attr-value,.token.keyword{color:#07a}.token.class-name,.token.function{color:#dd4a68}.token.important,.token.regex,.token.variable{color:#e90}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}.nuxt-progress{position:fixed;top:0;left:0;right:0;height:2px;width:0;opacity:1;transition:width .1s,opacity .4s;background-color:#000;z-index:999999}.nuxt-progress.nuxt-progress-notransition{transition:none}.nuxt-progress-failed{background-color:red}html{font-family:"Source Sans Pro",-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,sans-serif;font-size:16px;word-spacing:1px;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased;box-sizing:border-box}*,:after,:before{box-sizing:border-box;margin:0}.button--green{display:inline-block;border-radius:4px;border:1px solid #3b8070;color:#3b8070;text-decoration:none;padding:10px 30px}.button--green:hover{color:#fff;background-color:#3b8070}.button--grey{display:inline-block;border-radius:4px;border:1px solid #35495e;color:#35495e;text-decoration:none;padding:10px 30px;margin-left:15px}.button--grey:hover{color:#fff;background-color:#35495e}</style><link rel="preload" href="/_nuxt/static/1612398539/2017/03/03/graph_subreddit.html/state.js" as="script"><link rel="preload" href="/_nuxt/static/1612398539/2017/03/03/graph_subreddit.html/payload.js" as="script"><link rel="preload" href="/_nuxt/static/1612398539/manifest.js" as="script">
  </head>
  <body>
    <script data-n-head="ssr" data-hid="nuxt-color-mode-script" data-pbody="true">!function (){"use strict";var e=window,s=document,t=s.documentElement,n=["dark","light"],o=function(e){for(var t=e+"=",n=s.cookie.split(";"),o=0;o<n.length;o++){for(var a=n[o];" "===a.charAt(0);)a=a.substring(1,a.length);if(0===a.indexOf(t))return a.substring(t.length,a.length)}return null}("nuxt-color-mode")||"system",a="system"===o?c():o;function i(e){var s=""+e+"-mode";t.classList?t.classList.add(s):t.className+=" "+s}function r(s){return e.matchMedia("(prefers-color-scheme"+s+")")}function c(){if(e.matchMedia&&"not all"!==r("").media)for(var s of n)if(r(":"+s).matches)return s;return"light"}i(a),e["__NUXT_COLOR_MODE__"]={preference:o,value:a,getColorScheme:c,addClass:i,removeClass:function(e){var s=""+e+"-mode";t.classList?t.classList.remove(s):t.className=t.className.replace(new RegExp(s,"g"),"")}}}();
</script><div data-server-rendered="true" id="__nuxt"><!----><div id="__layout"><div><div class="mx-auto grid grid-cols-3 py-2 px-2 sm:px-4 items-center max-w-6xl" data-v-b364ef96><div class="justify-left" data-v-b364ef96><a href="/" class="text-xl nuxt-link-active" data-v-b364ef96><span class="hidden sm:inline" data-v-b364ef96>Brian Caffey</span><span class="inline sm:hidden" data-v-b364ef96>JBC</span></a></div> <div class="justify-center flex" data-v-b364ef96><div class="grid items-center justify-center" data-v-b364ef96><ul class="flex px-4"><li class="md:px-4 px-1 cursor-pointer">
      🖥️
    </li><li class="md:px-4 px-1 cursor-pointer">
      🌞
    </li><li class="md:px-4 px-1 cursor-pointer">
      🌚
    </li><li class="md:px-4 px-1 cursor-pointer">
      ☕
    </li></ul></div></div> <div class="flex justify-end relative" data-v-b364ef96><div class="grid items-center justify-center" data-v-b364ef96><ul><li class="md:px-4 px-1 cursor-pointer">
      🇺🇸
    </li></ul> <div class="relative rounded-md -ml-3"><div class="absolute left-0 bg-white shadow-md rounded px-4 py-2 w-32 text mt-4 -ml-20" style="display:none"><a href="/2017/03/03/graph_subreddit.html" aria-current="page" class="nuxt-link-exact-active nuxt-link-active">🇺🇸 English</a><a href="/fr/2017/03/03/graph_subreddit.html">🇫🇷 Français</a><a href="/zh/2017/03/03/graph_subreddit.html">🇨🇳 简体中文</a><a href="/ru/2017/03/03/graph_subreddit.html">🇷🇺 Русский</a><a href="/jp/2017/03/03/graph_subreddit.html">🇯🇵 日本語</a></div></div></div>  
    <nav data-v-ec6a03a4 data-v-b364ef96><ul class="items-right justify-end hidden md:flex" data-v-ec6a03a4><li class="px-4" data-v-ec6a03a4><a href="/blog" data-v-ec6a03a4>Blog</a></li> <li class="px-4" data-v-ec6a03a4><a href="/projects" data-v-ec6a03a4>Projects</a></li> <li class="px-4" data-v-ec6a03a4><a href="/contact" data-v-ec6a03a4>Contact</a></li></ul> <div class="flex justify-end md:hidden z-1000" data-v-ec6a03a4><button class="flex items-center px-3 py-2 border rounded menu-icon" data-v-ec6a03a4><svg viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg" class="fill-current h-3 w-3" data-v-ec6a03a4><title data-v-ec6a03a4>Menu</title> <path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0v-2z" data-v-ec6a03a4></path></svg></button></div> <!----></nav></div></div> <article><img src="/static/subreddits.png" class="h-64 w-full object-cover"> <div class="mx-auto max-w-5xl px-2 sm:px-4 md:px-4 lg:px-16 mt-2"><h1 class="prose text-3xl leading-9">Related subreddit graph exploration with NetworkX</h1> <div class="flex flex-wrap -ml-1 py-2" data-v-1f8089c5><a href="/blog/tags/reddit" data-v-2b5535c8 data-v-1f8089c5><div class="px-2 text-sm shadow rounded-lg bg-white mx-1 mt-1 uppercase cursor-pointer" data-v-2b5535c8>
    reddit 🏷️
    <!----></div></a><a href="/blog/tags/python" data-v-2b5535c8 data-v-1f8089c5><div class="px-2 text-sm shadow rounded-lg bg-white mx-1 mt-1 uppercase cursor-pointer" data-v-2b5535c8>
    python 🏷️
    <!----></div></a><a href="/blog/tags/scraping" data-v-2b5535c8 data-v-1f8089c5><div class="px-2 text-sm shadow rounded-lg bg-white mx-1 mt-1 uppercase cursor-pointer" data-v-2b5535c8>
    scraping 🏷️
    <!----></div></a><a href="/blog/tags/data" data-v-2b5535c8 data-v-1f8089c5><div class="px-2 text-sm shadow rounded-lg bg-white mx-1 mt-1 uppercase cursor-pointer" data-v-2b5535c8>
    data 🏷️
    <!----></div></a><a href="/blog/tags/graphs" data-v-2b5535c8 data-v-1f8089c5><div class="px-2 text-sm shadow rounded-lg bg-white mx-1 mt-1 uppercase cursor-pointer" data-v-2b5535c8>
    graphs 🏷️
    <!----></div></a></div> <!----> <p class="blog-date text-gray-500 mb-4">
      Last Updated on
      March 2, 2017
    </p> <!----> <div class="markdown nuxt-content"><h1 id="graphing-subreddits"><a href="#graphing-subreddits" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Graphing Subreddits</h1>
<p>This notebook explores some basic concepts of graph theory. A few weeks ago I set up a script to scrape data from <a href="reddit.com">reddit.com</a> with the goal of visualizing the network of related subreddits (forums on specific topics) and related data.</p>
<p>Reddit is home over 600,000 communities, known as subreddits, where people come to share information, opinions, links, etc. and discuss things in a open forum. Most subreddits display links to related subreddits. For example, /r/apple (the Apple subreddit) links to /r/iPhone, a subreddit all about the iPhone, and over a dozen other Apple-related subreddits.</p>
<p>If you visit reddit.com as a guest, you will see a list of popular subreddits. This list is located inside an <code>html</code> tag called <code>drop-choices</code>. Here it is:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">from</span> selenium <span class="token keyword">import</span> webdriver
<span class="token keyword">import</span> re
<span class="token keyword">import</span> time
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> bs4 <span class="token keyword">import</span> BeautifulSoup
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>PhantomJS<span class="token punctuation">(</span><span class="token punctuation">)</span>
driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'https://www.reddit.com/'</span><span class="token punctuation">)</span>
time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">4</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
html <span class="token operator">=</span> driver<span class="token punctuation">.</span>page_source<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

s <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>html<span class="token punctuation">)</span>
defaults <span class="token operator">=</span> s<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'div'</span><span class="token punctuation">,</span> attrs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'class'</span><span class="token punctuation">:</span><span class="token string">'drop-choices'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
subs <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">r"\/r\/[\w.]+\/?"</span><span class="token punctuation">)</span>
default_subreddits <span class="token operator">=</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>subs<span class="token punctuation">.</span>findall<span class="token punctuation">(</span><span class="token builtin">str</span><span class="token punctuation">(</span>defaults<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> x <span class="token keyword">in</span> default_subreddits<span class="token punctuation">:</span> <span class="token keyword">print</span> <span class="token string">'['</span> <span class="token operator">+</span> x <span class="token operator">+</span> <span class="token string">'](https://reddit.com'</span><span class="token operator">+</span> x <span class="token operator">+</span> <span class="token string">'), '</span><span class="token punctuation">,</span>
</code></pre></div>
<p>Here are the elements of <code>default_subreddits</code>:</p>
<blockquote>
<p><a href="https://reddit.com/r/LifeProTips/" rel="nofollow noopener noreferrer" target="_blank">/r/LifeProTips/</a>, <a href="https://reddit.com/r/Futurology/" rel="nofollow noopener noreferrer" target="_blank">/r/Futurology/</a>, <a href="https://reddit.com/r/OldSchoolCool/" rel="nofollow noopener noreferrer" target="_blank">/r/OldSchoolCool/</a>, <a href="https://reddit.com/r/mildlyinteresting/" rel="nofollow noopener noreferrer" target="_blank">/r/mildlyinteresting/</a>, <a href="https://reddit.com/r/askscience/" rel="nofollow noopener noreferrer" target="_blank">/r/askscience/</a>, <a href="https://reddit.com/r/UpliftingNews/" rel="nofollow noopener noreferrer" target="_blank">/r/UpliftingNews/</a>, <a href="https://reddit.com/r/aww/" rel="nofollow noopener noreferrer" target="_blank">/r/aww/</a>, <a href="https://reddit.com/r/GetMotivated/" rel="nofollow noopener noreferrer" target="_blank">/r/GetMotivated/</a>, <a href="https://reddit.com/r/personalfinance/" rel="nofollow noopener noreferrer" target="_blank">/r/personalfinance/</a>, <a href="https://reddit.com/r/gadgets/" rel="nofollow noopener noreferrer" target="_blank">/r/gadgets/</a>, <a href="https://reddit.com/r/science/" rel="nofollow noopener noreferrer" target="_blank">/r/science/</a>, <a href="https://reddit.com/r/dataisbeautiful/" rel="nofollow noopener noreferrer" target="_blank">/r/dataisbeautiful/</a>, <a href="https://reddit.com/r/DIY/" rel="nofollow noopener noreferrer" target="_blank">/r/DIY/</a>, <a href="https://reddit.com/r/AskReddit/" rel="nofollow noopener noreferrer" target="_blank">/r/AskReddit/</a>, <a href="https://reddit.com/r/space/" rel="nofollow noopener noreferrer" target="_blank">/r/space/</a>, <a href="https://reddit.com/r/nosleep/" rel="nofollow noopener noreferrer" target="_blank">/r/nosleep/</a>, <a href="https://reddit.com/r/Documentaries/" rel="nofollow noopener noreferrer" target="_blank">/r/Documentaries/</a>, <a href="https://reddit.com/r/todayilearned/" rel="nofollow noopener noreferrer" target="_blank">/r/todayilearned/</a>, <a href="https://reddit.com/r/television/" rel="nofollow noopener noreferrer" target="_blank">/r/television/</a>, <a href="https://reddit.com/r/IAmA/" rel="nofollow noopener noreferrer" target="_blank">/r/IAmA/</a>, <a href="https://reddit.com/r/Art/" rel="nofollow noopener noreferrer" target="_blank">/r/Art/</a>, <a href="https://reddit.com/r/EarthPorn/" rel="nofollow noopener noreferrer" target="_blank">/r/EarthPorn/</a>, <a href="https://reddit.com/r/books/" rel="nofollow noopener noreferrer" target="_blank">/r/books/</a>, <a href="https://reddit.com/r/gifs/" rel="nofollow noopener noreferrer" target="_blank">/r/gifs/</a>, <a href="https://reddit.com/r/Showerthoughts/" rel="nofollow noopener noreferrer" target="_blank">/r/Showerthoughts/</a>, <a href="https://reddit.com/r/blog/" rel="nofollow noopener noreferrer" target="_blank">/r/blog/</a>, <a href="https://reddit.com/r/news/" rel="nofollow noopener noreferrer" target="_blank">/r/news/</a>, <a href="https://reddit.com/r/Jokes/" rel="nofollow noopener noreferrer" target="_blank">/r/Jokes/</a>, <a href="https://reddit.com/r/TwoXChromosomes/" rel="nofollow noopener noreferrer" target="_blank">/r/TwoXChromosomes/</a>, <a href="https://reddit.com/r/videos/" rel="nofollow noopener noreferrer" target="_blank">/r/videos/</a>, <a href="https://reddit.com/r/philosophy/" rel="nofollow noopener noreferrer" target="_blank">/r/philosophy/</a>, <a href="https://reddit.com/r/nottheonion/" rel="nofollow noopener noreferrer" target="_blank">/r/nottheonion/</a>, <a href="https://reddit.com/r/explainlikeimfive/" rel="nofollow noopener noreferrer" target="_blank">/r/explainlikeimfive/</a>, <a href="https://reddit.com/r/movies/" rel="nofollow noopener noreferrer" target="_blank">/r/movies/</a>, <a href="https://reddit.com/r/Music/" rel="nofollow noopener noreferrer" target="_blank">/r/Music/</a>, <a href="https://reddit.com/r/WritingPrompts/" rel="nofollow noopener noreferrer" target="_blank">/r/WritingPrompts/</a>, <a href="https://reddit.com/r/worldnews/" rel="nofollow noopener noreferrer" target="_blank">/r/worldnews/</a>, <a href="https://reddit.com/r/pics/" rel="nofollow noopener noreferrer" target="_blank">/r/pics/</a>, <a href="https://reddit.com/r/history/" rel="nofollow noopener noreferrer" target="_blank">/r/history/</a>, <a href="https://reddit.com/r/listentothis/" rel="nofollow noopener noreferrer" target="_blank">/r/listentothis/</a>, <a href="https://reddit.com/r/sports/" rel="nofollow noopener noreferrer" target="_blank">/r/sports/</a>, <a href="https://reddit.com/r/food/" rel="nofollow noopener noreferrer" target="_blank">/r/food/</a>, <a href="https://reddit.com/r/creepy/" rel="nofollow noopener noreferrer" target="_blank">/r/creepy/</a>, <a href="https://reddit.com/r/announcements/" rel="nofollow noopener noreferrer" target="_blank">/r/announcements/</a>, <a href="https://reddit.com/r/gaming/" rel="nofollow noopener noreferrer" target="_blank">/r/gaming/</a>, <a href="https://reddit.com/r/tifu/" rel="nofollow noopener noreferrer" target="_blank">/r/tifu/</a>, <a href="https://reddit.com/r/funny/" rel="nofollow noopener noreferrer" target="_blank">/r/funny/</a>, <a href="https://reddit.com/r/photoshopbattles/" rel="nofollow noopener noreferrer" target="_blank">/r/photoshopbattles/</a>, <a href="https://reddit.com/r/InternetIsBeautiful/" rel="nofollow noopener noreferrer" target="_blank">/r/InternetIsBeautiful/</a>,</p>
</blockquote>
<p>My goal here is to see how many subreddits we can reach as we branch off of these "default" subreddits into their related subreddits.</p>
<p>First, we need to set up data structures to hold data for subreddits and their related subreddits. And we need to define an algorithm for collecting data.</p>
<p>Here's an intrdoduction to graphs from <a href="https://www.python.org/doc/essays/graphs/" rel="nofollow noopener noreferrer" target="_blank">python.org</a>:</p>
<blockquote>
<p>Few programming languages provide direct support for graphs as a data type, and Python is no exception. However, graphs are easily built out of lists and dictionaries. For instance, here's a simple graph (I can't use drawings in these columns, so I write down the graph's arcs):</p>
</blockquote>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>A -> B
A -> C
B -> C
B -> D
C -> D
D -> C
E -> F
F -> C
</code></pre></div>
<p>This graph has six nodes (A-F) and eight arcs. It can be represented by the following Python data structure:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>graph =     {'A': ['B', 'C'],
             'B': ['C', 'D'],
             'C': ['D'],
             'D': ['C'],
             'E': ['F'],
             'F': ['C']}
</code></pre></div>
<p>First let's define how we would go only one branch deep into this graph (i.e. find the related subreddits for <em>only</em> the default subreddits). To collect the data, I first looped through the default subreddits and save the html of each subreddit to its own text file. Here's a script with comments:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token comment">#first we navigate to the correct folder where we will store the first level of related subreddits</span>
os<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>expanduser<span class="token punctuation">(</span><span class="token string">'~/Documents/Projects/Data/Subreddits/one/'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token comment">#next we instantiate the webdriver we will be using: PhantomJS</span>
driver <span class="token operator">=</span> webdriver<span class="token punctuation">.</span>PhantomJS<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment">#loop through the list of default subreddits</span>
<span class="token keyword">for</span> num<span class="token punctuation">,</span> subreddit <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>default_subreddits<span class="token punctuation">)</span><span class="token punctuation">:</span>

    <span class="token comment">#for each subreddit, we append the /r/subreddit path to the base URL (reddit.com)</span>
    driver<span class="token punctuation">.</span>get<span class="token punctuation">(</span><span class="token string">'https://www.reddit.com'</span><span class="token operator">+</span>subreddit<span class="token punctuation">)</span>

    <span class="token comment">#wait for two seconds</span>
    time<span class="token punctuation">.</span>sleep<span class="token punctuation">(</span><span class="token number">2</span> <span class="token operator">+</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>random<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">#save the html of the loaded page to a variable: html</span>
    html <span class="token operator">=</span> driver<span class="token punctuation">.</span>page_source<span class="token punctuation">.</span>encode<span class="token punctuation">(</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span>

    <span class="token comment">#remove '/r/' from the subreddit name string</span>
    name <span class="token operator">=</span> subreddit<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token string">'/'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">]</span>

    <span class="token comment">#open a new file and give it the name of the subreddit we just scraped</span>
    subreddit_html_file <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>name<span class="token operator">+</span><span class="token string">'.txt'</span><span class="token punctuation">,</span> <span class="token string">'w+'</span><span class="token punctuation">)</span>

    <span class="token comment">#write the html contents to the file</span>
    subreddit_html_file<span class="token punctuation">.</span>write<span class="token punctuation">(</span>html<span class="token punctuation">)</span>

    <span class="token comment">#clost the file</span>
    subreddit_html_file<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">#print out the number and name of the subreddit we just scrapped to make sure things are working</span>
    <span class="token keyword">print</span> <span class="token builtin">str</span><span class="token punctuation">(</span>num<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' '</span> <span class="token operator">+</span> subreddit<span class="token punctuation">,</span>

</code></pre></div>
<p>Next, we want to go through each file and extract the information we want. Here's what we will be getting:</p>
<ul>
<li>Number of subscribers</li>
<li>Subreddit description</li>
<li>Date created</li>
<li>Related subreddits</li>
</ul>
<p>For this type of project, I prefer to loop through each page and creating several small dictionaries for each data point, then combine the small dictionaries into a large dictionary, and then append the dictionary to a list of dictionaries. Once I have looped through all of the pages, I can create a pandas DataFrame from the list of dictionaries. This allows me to easily manipulate the data. Here's the script that I used to do this:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token comment">#navigate to where the html files are stored (I moved them around a bit so it is not consistent with the script above)</span>
os<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span><span class="token string">'E://DATA/Subreddits/subreddits_html/'</span><span class="token punctuation">)</span>

<span class="token comment">#generate a list of files that we will loop through</span>
files <span class="token operator">=</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span><span class="token string">'E://DATA/Subreddits/subreddits_html/'</span><span class="token punctuation">)</span>

<span class="token comment">#set up an empty list that we will append dictionaries to</span>
dict_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

<span class="token comment">#loop through the files</span>
<span class="token keyword">for</span> file_ <span class="token keyword">in</span> files<span class="token punctuation">:</span>

    <span class="token comment">#print out the name of the current file in the loop</span>
    <span class="token keyword">print</span> file_<span class="token punctuation">,</span>

    <span class="token comment">#open the file</span>
    f <span class="token operator">=</span> <span class="token builtin">open</span><span class="token punctuation">(</span>file_<span class="token punctuation">,</span> <span class="token string">'r'</span><span class="token punctuation">)</span>
    <span class="token comment">#read the file contents to a local variable</span>
    html <span class="token operator">=</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">#create a BeautifulSoup object that we will use to parse the HTML</span>
    b <span class="token operator">=</span> BeautifulSoup<span class="token punctuation">(</span>html<span class="token punctuation">,</span> <span class="token string">'lxml'</span><span class="token punctuation">)</span>

    <span class="token comment">#get the subreddit name that we are working with (from the `file` variable)</span>
    subreddit_name <span class="token operator">=</span> <span class="token string">'/r/'</span> <span class="token operator">+</span> file_<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">.</span>lower<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token comment">#put the name into a dictionary</span>
    subreddit_name_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'subreddit'</span><span class="token punctuation">:</span>subreddit_name<span class="token punctuation">}</span>

    <span class="token comment">#get number of subscribers</span>
    subs <span class="token operator">=</span> b<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'span'</span><span class="token punctuation">,</span> attrs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'class'</span><span class="token punctuation">:</span><span class="token string">'subscribers'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token comment">#if the number of subscribers is displayed on the page, then we find it and add it to a dictionary</span>
    <span class="token keyword">if</span> subs<span class="token punctuation">:</span>
        subs <span class="token operator">=</span> b<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'span'</span><span class="token punctuation">,</span> attrs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'class'</span><span class="token punctuation">:</span><span class="token string">'subscribers'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'span'</span><span class="token punctuation">,</span> attrs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'class'</span><span class="token punctuation">:</span><span class="token string">'number'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">','</span><span class="token punctuation">,</span> <span class="token string">''</span><span class="token punctuation">)</span>
        subs_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'subscribers'</span><span class="token punctuation">:</span><span class="token builtin">int</span><span class="token punctuation">(</span>subs<span class="token punctuation">)</span><span class="token punctuation">}</span>
    <span class="token comment">#if the number of subscribers is not displayed on the page, then we set the number of subscribers in the dictionary to None</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        subs_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'subscribers'</span><span class="token punctuation">:</span><span class="token boolean">None</span><span class="token punctuation">}</span>

    <span class="token comment">#similar process for the description: if the description is displayed, get it and save it to desc</span>
    <span class="token comment">#if it is not available, then desc will be set to `None`</span>
    desc <span class="token operator">=</span> b<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'div'</span><span class="token punctuation">,</span> attrs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'class'</span><span class="token punctuation">:</span><span class="token string">'md'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> desc<span class="token punctuation">:</span>
        desc <span class="token operator">=</span> b<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'div'</span><span class="token punctuation">,</span> attrs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'class'</span><span class="token punctuation">:</span><span class="token string">'md'</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">.</span>text
        desc <span class="token operator">=</span> desc<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'\n'</span><span class="token punctuation">,</span> <span class="token string">' '</span><span class="token punctuation">)</span>
    desc_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'description'</span><span class="token punctuation">:</span>desc<span class="token punctuation">}</span>

    <span class="token comment">#here we use regular expressions to find links anywhere on the page that have the structure: "/r/something/"</span>
    rel_subr <span class="token operator">=</span> re<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span><span class="token string">r"\/r\/[\w.]+\/?"</span><span class="token punctuation">)</span>
    <span class="token comment">#make a list of these links based on the "/r/something/" pattern</span>
    related_subreddits <span class="token operator">=</span> rel_subr<span class="token punctuation">.</span>findall<span class="token punctuation">(</span>html<span class="token punctuation">)</span>

    <span class="token comment">#save the list to a dictionary</span>
    subreddits_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">'related'</span><span class="token punctuation">:</span>related_subreddits<span class="token punctuation">}</span>

    <span class="token comment">#same processes for recording the date that the subreddit was created: get the date from an HTML element,</span>
    <span class="token comment">#then save it to a dictionary. There were two different formats available in the HTML so I grabbed both</span>
    age <span class="token operator">=</span> b<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'span'</span><span class="token punctuation">,</span> attrs<span class="token operator">=</span><span class="token punctuation">{</span><span class="token string">'class'</span><span class="token punctuation">:</span><span class="token string">'age'</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> age<span class="token punctuation">:</span>
        time1 <span class="token operator">=</span> age<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'time'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'title'</span><span class="token punctuation">]</span>
        time2 <span class="token operator">=</span> age<span class="token punctuation">.</span>find<span class="token punctuation">(</span><span class="token string">'time'</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token string">'datetime'</span><span class="token punctuation">]</span>

    <span class="token comment">#save the date to a dictionary</span>
    time_dict <span class="token operator">=</span> <span class="token punctuation">{</span><span class="token string">"date1"</span><span class="token punctuation">:</span>time1<span class="token punctuation">,</span> <span class="token string">"date2"</span><span class="token punctuation">:</span>time2<span class="token punctuation">}</span>

    <span class="token comment">#take all the dictionaries we just created and put them together into one big dictionary</span>
    dictionary <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span>subs_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span>desc_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span>subreddits_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span>subreddit_name_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">+</span>time_dict<span class="token punctuation">.</span>items<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token comment">#append the big dictionary to the list that we defined right before the beginning of the loop</span>
    dict_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>dictionary<span class="token punctuation">)</span>

    <span class="token comment">#deconstruct the Beautiful Soup object (this can eat up memory very quickly, so it is very important when processing lots of data)</span>
    b<span class="token punctuation">.</span>decompose<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment">#clost the file</span>
    f<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<p>Next, let's save the results into a csv file. This let's us load the results quickly without having to scrape everyting again. To do this we can use the pandas library.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
df0 <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>dict_list<span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
</code></pre></div>
<p>At this point, we can go through the <code>related</code> column in the DataFrame and put together a list of all the related subreddits. With this list, we can simply repeat the process over and over again. However, each time we start with a new list of subreddits, we want to make sure that they have not already been collected.</p>
<p>Next I will read in one DataFrame that represents related subreddits "three levels deep" relative to the default subreddits.</p>
<p><strong>Default --> Related --> Related --> Related</strong></p>
<p>This DataFrame represents the collection of subreddits from all of these "layers" of the graph.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
master_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_pickle<span class="token punctuation">(</span><span class="token string">'pickle/master_df.p'</span><span class="token punctuation">)</span>
</code></pre></div>
<p>Now we can do a quick visualization of the growth in number of subreddits since the website's start in 2005.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">import</span> warnings
warnings<span class="token punctuation">.</span>filterwarnings<span class="token punctuation">(</span><span class="token string">'ignore'</span><span class="token punctuation">)</span>
<span class="token operator">%</span>matplotlib inline
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np

master_df_ <span class="token operator">=</span> master_df<span class="token punctuation">[</span>master_df<span class="token punctuation">.</span>notnull<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span>
master_df_<span class="token punctuation">.</span>date1 <span class="token operator">=</span> pd<span class="token punctuation">.</span>to_datetime<span class="token punctuation">(</span>master_df_<span class="token punctuation">[</span><span class="token string">'date1'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

list_of_dates <span class="token operator">=</span> master_df_<span class="token punctuation">.</span>date1<span class="token punctuation">.</span>sort_values<span class="token punctuation">(</span><span class="token punctuation">)</span>

counts <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>list_of_dates<span class="token punctuation">)</span><span class="token punctuation">)</span>
_ <span class="token operator">=</span> plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>list_of_dates<span class="token punctuation">,</span> counts<span class="token punctuation">)</span>
_ <span class="token operator">=</span> plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Number of subreddits over time'</span><span class="token punctuation">)</span>
_ <span class="token operator">=</span> plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Date'</span><span class="token punctuation">)</span>
_ <span class="token operator">=</span> plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Cummulative Count'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>expanduser<span class="token punctuation">(</span><span class="token string">'~/Documents/GitHub/briancaffey.github.io/img/subreddit_graph/subreddits_count.png'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div>
<p><img alt="png" src="/img/subreddit_graph/subreddits_count.png"></p>
<h1 id="setting-up-a-graph-with-networkx"><a href="#setting-up-a-graph-with-networkx" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Setting up a graph with NetworkX</h1>
<p>Next we can start to look at the collection of reddits and related subreddits as a graph. I will be using a Python package for network and graph analysis called <a href="https://networkx.github.io" rel="nofollow noopener noreferrer" target="_blank">NetworkX</a>.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token comment">#Let's make sure that we have only unique entries in the dataframe.</span>
master_df_u <span class="token operator">=</span> master_df_<span class="token punctuation">.</span>drop_duplicates<span class="token punctuation">(</span><span class="token string">'subreddit'</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>master_df_u <span class="token operator">=</span> master_df_u<span class="token punctuation">.</span>drop<span class="token punctuation">(</span>master_df_u<span class="token punctuation">.</span>index<span class="token punctuation">[</span>master_df_u<span class="token punctuation">.</span>subreddit<span class="token operator">==</span><span class="token string">'/r/track__subreddits_'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token comment">#here we define a dictionary where the keys are subreddits and the values are lists of related subreddits</span>
graph <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span>y <span class="token keyword">for</span> x<span class="token punctuation">,</span> y <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>master_df_u<span class="token punctuation">.</span>subreddit<span class="token punctuation">,</span> master_df_u<span class="token punctuation">.</span>related<span class="token punctuation">)</span><span class="token punctuation">}</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token comment">#NetworkX comes with the python Anaconda distribution</span>
<span class="token keyword">import</span> networkx <span class="token keyword">as</span> nx
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>G<span class="token operator">=</span>nx<span class="token punctuation">.</span>Graph<span class="token punctuation">(</span><span class="token punctuation">)</span>
G<span class="token operator">=</span>nx<span class="token punctuation">.</span>from_dict_of_lists<span class="token punctuation">(</span>graph<span class="token punctuation">)</span>
<span class="token comment">#making the graph undirected takes all of the vertices between nodes and makes them bi-directional</span>
G1 <span class="token operator">=</span> G<span class="token punctuation">.</span>to_undirected<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>choice <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>master_df_u<span class="token punctuation">.</span>subreddit<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> choice
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>['/r/streetboarding' '/r/stephenking']
</code></pre></div>
<p>Let's test out some of the functions from NetworkX for graph analysis. First, let's take the two randomly selected nodes defined above and test to see if there exists a path between them:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>nx<span class="token punctuation">.</span>has_path<span class="token punctuation">(</span>G1<span class="token punctuation">,</span> choice<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> choice<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>True
</code></pre></div>
<h1 id="shortest-path"><a href="#shortest-path" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Shortest path</h1>
<p>Now let's see (at least one of) the shortest path that exists between these nodes:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>nx<span class="token punctuation">.</span>shortest_path<span class="token punctuation">(</span>G1<span class="token punctuation">,</span> choice<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> choice<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>['/r/streetboarding',
 '/r/freebord',
 '/r/adrenaline',
 '/r/imaginaryadrenaline',
 '/r/imaginarystephenking',
 '/r/stephenking']
</code></pre></div>
<p>Let's write a function that selects two random subreddits and then prints a shortest path if it exists:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">def</span> <span class="token function">short_path</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    choices <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>choice<span class="token punctuation">(</span>master_df_u<span class="token punctuation">.</span>subreddit<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>
    <span class="token keyword">if</span> nx<span class="token punctuation">.</span>has_path<span class="token punctuation">(</span>G1<span class="token punctuation">,</span> choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> choices<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
        path <span class="token operator">=</span> nx<span class="token punctuation">.</span>shortest_path<span class="token punctuation">(</span>G1<span class="token punctuation">,</span> choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> choices<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span> choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">' and '</span> <span class="token operator">+</span> choices<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">' are joined by: \n'</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span>
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span> <span class="token string">"No path exists between "</span> <span class="token operator">+</span> choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">+</span> <span class="token string">' and '</span> <span class="token operator">+</span> choices<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
</code></pre></div>
<p>Here's a collection of results from the <code>short_path</code> function defined above that start to paint a picuture of the broad set of topics covered by reddit.com:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/personalizationadvice and /r/beautifulfemales are joined by:
['/r/personalizationadvice', '/r/coloranalysis', '/r/fashion', '/r/redcarpet', '/r/gentlemanboners', '/r/beautifulfemales']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/caffeine and /r/shittyramen are joined by:
['/r/caffeine', '/r/toast', '/r/cooking', '/r/ramen', '/r/shittyramen']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/watchingcongress and /r/iwantthatonashirt are joined by:
['/r/watchingcongress', '/r/stand', '/r/snowden', '/r/undelete', '/r/trees', '/r/iwantthatonashirt']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/asksciencediscussion and /r/dogsonhardwoodfloors are joined by:
['/r/asksciencediscussion', '/r/badscience', '/r/badlinguistics', '/r/animalsbeingjerks', '/r/startledcats', '/r/dogsonhardwoodfloors']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/randommail and /r/mini are joined by:
['/r/randommail', '/r/spiceexchange', '/r/cameraswapping', '/r/itookapicture', '/r/carporn', '/r/mini']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/catsinsinks and /r/nzmovies are joined by:
['/r/catsinsinks', '/r/wetcats', '/r/tinysubredditoftheday', '/r/sheep', '/r/nzmetahub', '/r/nzmovies']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/thoriumreactor and /r/sailing are joined by:
['/r/thoriumreactor', '/r/energy', '/r/spev', '/r/sailing']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/deathnote and /r/vegetarianism are joined by:
['/r/deathnote', '/r/television', '/r/netflixbestof', '/r/naturefilms', '/r/environment', '/r/vegetarianism']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/mississippir4r and /r/mathematics are joined by:
['/r/mississippir4r', '/r/mississippi', '/r/prisonreform', '/r/socialscience', '/r/alltech', '/r/mathematics']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/britainsgottalent and /r/irelandbaldwin are joined by:
['/r/britainsgottalent', '/r/britishtv', '/r/that70sshow', '/r/mila_kunis', '/r/christinaricci', '/r/irelandbaldwin']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/the_donald and /r/ladybusiness are joined by:
['/r/the_donald', '/r/shitliberalssay', '/r/trollxchromosomes', '/r/ladybusiness']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/selfharm and /r/medlabprofessionals are joined by:
['/r/selfharm', '/r/adhd', '/r/neuroimaging', '/r/pharmacy', '/r/medlabprofessionals']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/coverart and /r/phillycraftbeer are joined by:
['/r/coverart', '/r/nostalgia', '/r/upvotedbecausegirl', '/r/wtf', '/r/remindsmeofdf', '/r/beer', '/r/phillycraftbeer']
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>short_path<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/hotguyswithlonghair and /r/castles are joined by:
['/r/hotguyswithlonghair', '/r/majesticmanes', '/r/ladyboners', '/r/imaginaryladyboners', '/r/imaginarycastles', '/r/castles']
</code></pre></div>
<p>Taking a look <a href="http://networkx.readthedocs.io/en/networkx-1.11/_modules/networkx/algorithms/shortest_paths/unweighted.html?highlight=bidirectional_shortest_path" rel="nofollow noopener noreferrer" target="_blank">under the hood</a> of NetworkX and examining the algorith that finds the <a href="http://networkx.readthedocs.io/en/networkx-1.11/_modules/networkx/algorithms/shortest_paths/generic.html#shortest_path" rel="nofollow noopener noreferrer" target="_blank">shortest path</a> between any two nodes in a graph, we find that it simply boils down to:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>def shortest_path(G, source=None, target=None, weight=None):
    paths=nx.bidirectional_shortest_path(G,source,target)
    return paths
</code></pre></div>
<p>You can read more about the <code>bidirectional_shortest_path</code> function <a href="http://networkx.readthedocs.io/en/networkx-1.11/_modules/networkx/algorithms/shortest_paths/unweighted.html?highlight=bidirectional_shortest_path" rel="nofollow noopener noreferrer" target="_blank">here</a> in the NetworkX documentation.</p>
<p>When I was first experimenting with graph algorithms, I had an interesting result using an algorithm intruduced <a href="https://www.python.org/doc/essays/graphs/" rel="nofollow noopener noreferrer" target="_blank">here</a> in the Python documentation. Here's the algorithm:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">def</span> <span class="token function">find_path</span><span class="token punctuation">(</span>graph<span class="token punctuation">,</span> start<span class="token punctuation">,</span> end<span class="token punctuation">,</span> path<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    path <span class="token operator">=</span> path <span class="token operator">+</span> <span class="token punctuation">[</span>start<span class="token punctuation">]</span>
    <span class="token keyword">if</span> start <span class="token operator">==</span> end<span class="token punctuation">:</span>
        <span class="token keyword">return</span> path
    <span class="token keyword">if</span> <span class="token keyword">not</span> graph<span class="token punctuation">.</span>has_key<span class="token punctuation">(</span>start<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token boolean">None</span>
    <span class="token keyword">for</span> node <span class="token keyword">in</span> graph<span class="token punctuation">[</span>start<span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> node <span class="token keyword">not</span> <span class="token keyword">in</span> path<span class="token punctuation">:</span>
            newpath <span class="token operator">=</span> find_path<span class="token punctuation">(</span>graph<span class="token punctuation">,</span> node<span class="token punctuation">,</span> end<span class="token punctuation">,</span> path<span class="token punctuation">)</span>
            <span class="token keyword">if</span> newpath<span class="token punctuation">:</span> <span class="token keyword">return</span> newpath
    <span class="token keyword">return</span> <span class="token boolean">None</span>
</code></pre></div>
<p>The above algorthim uses a process called backtracking to exaustively try all possibilities until it returns a solution. It creates an interesting "random walk" through groups of related subreddits. Here's the result of calling the above function on our graph (only 2 layers deep) with two random nodes: /r/persianrap and /r/nosleep:</p>
<blockquote>
<p>/r/persianrap /r/middleeasternmusic /r/arabic /r/arabs /r/libyancrisis /r/syriancivilwar /r/yemenicrisis /r/sinaiinsurgency /r/jihadinfocus /r/credibledefense /r/geopolitics /r/forgottennews /r/libyanconflict /r/menaconflicts /r/iran /r/iranianlgbt /r/zoroastrianism /r/kurdistan /r/rojava /r/anarchism /r/imaginarypolitics /r/imaginaryimmortals /r/imaginaryclerics /r/imaginarylakes /r/imaginaryaliens /r/imaginarygnomes /r/imaginaryladyboners /r/imaginaryturtleworlds /r/imaginarysunnydale /r/imaginarydwarves /r/imaginarywizards /r/imaginaryvikings /r/imaginarycolorscapes /r/imaginarysteampunk /r/imaginarytemples /r/imaginaryblueprints /r/comicbookart /r/imaginarytechnology /r/mtgporn /r/imaginaryoldkingdom /r/imaginaryfactories /r/imaginaryfederation /r/imaginarylovers /r/imaginarynarnia /r/imaginarydwellings /r/imaginaryscience /r/imaginarytaverns /r/imaginarybattlefields /r/cityporn /r/japanpics /r/nationalphotosubs /r/austriapics /r/southkoreapics /r/taiwanpics /r/ghanapics /r/kenyapics /r/norwaypics /r/vzlapics /r/perupics /r/antarcticapics /r/greatlakespics /r/lakeporn /r/pornoverlords /r/thingscutinhalfporn /r/manufacturing /r/cnc /r/askengineers /r/sciencesubreddits /r/math /r/simulate /r/cosmology /r/reddittothefuture /r/scifi /r/lost /r/the100books /r/the100 /r/theblacklist /r/nbc /r/dundermifflin /r/sonsofanarchy /r/twentyfour /r/banshee /r/hbo /r/siliconvalleyhbo /r/siliconvalley /r/california /r/tahoe /r/skiing /r/snowshoeing /r/xcountryskiing /r/wintergear /r/skijumping /r/winter /r/bigmountain /r/mountaineering /r/campingandhiking /r/earthporn /r/nature /r/birding /r/invasivespecies /r/zoology /r/entomology /r/rainforest /r/botany /r/wildlife /r/allscience /r/earthscience /r/energy /r/biomass /r/renewablenews /r/syngas /r/climatenews /r/composting /r/vermiculture /r/organicfarming /r/livestock /r/animalwelfare /r/randomactsofpetfood /r/animalreddits /r/cockatiel /r/catpics /r/tortoises /r/whales /r/cetacea /r/lifeaquatic /r/hrw /r/green_peace /r/environmental_policy /r/conservation /r/depthhub /r/indepthsports /r/deeperhubbeta /r/lectures /r/spacepolicy /r/skylon /r/ula /r/isro /r/engineteststands /r/jupiters /r/imaginarystarscapes /r/spacequestions /r/spaceflight /r/moon /r/dione /r/europa /r/oortcloud /r/dwarfplanetceres /r/saturn /r/asteroidbelt /r/mars /r/rhea /r/venus /r/astrophys /r/spacevideos /r/transhuman /r/timereddits /r/virtualreality /r/vive /r/oculus /r/learnvrdev /r/unity3d /r/gamedev /r/crowdfunding /r/crowdsourcing /r/mturk /r/swagbucks /r/beermoney /r/flipping /r/shoplifting /r/thriftstorehauls /r/dvdcollection /r/televisionposterporn /r/concertposterporn /r/movieposterporn /r/lv426 /r/predator /r/arnoldschwarzenegger /r/alanpartridge /r/americandad /r/timanderic /r/homemovies /r/gravityfalls /r/homestarrunner /r/telltale /r/thewalkingdeadgame /r/thewalkingdeadgifs /r/twdnomansland /r/heycarl /r/twdroadtosurvival /r/thewalkingdead /r/zombies /r/guns /r/swissguns /r/opencarry /r/libertarian /r/geolibertarianism /r/basicincome /r/basicincomeactivism /r/mhoc /r/modelaustralia /r/rmtk /r/thenetherlands /r/tokkiefeesboek /r/nujijinactie /r/ik_ihe /r/youirl /r/fite_me_irl /r/2meirl4meirl /r/depression /r/randomactsofcards /r/philately /r/coins /r/coins4sale /r/ancientcoins /r/ancientrome /r/flatblue /r/bestofwritingprompts /r/writingprompts /r/promptoftheday /r/flashfiction /r/keepwriting /r/getmotivated /r/mentors /r/favors /r/recordthis /r/videography /r/animation /r/3dsmax /r/computergraphics /r/cinema4d /r/design /r/ui_design /r/designjobs /r/heavymind /r/wtfart /r/alternativeart /r/imaginaryninjas /r/imaginaryruins /r/isometric /r/imaginaryislands /r/imaginaryverse /r/icandrawthat /r/caricatures /r/imaginaryneweden /r/imaginaryequestria /r/imaginaryaww /r/imaginarycyberpunk /r/chinafuturism /r/scifirealism /r/inegentlemanboners /r/imaginarywtf /r/imaginaryelementals /r/imaginarydinosaurs /r/dinosaurs /r/speculativeevolution /r/hybridanimals /r/photoshopbattles /r/cutouts /r/battleshops /r/graphic_design /r/visualization /r/statistics /r/oncourtanalytics /r/nbaanalytics /r/nba /r/pacers /r/atlantahawks /r/basketball /r/mavericks /r/fcdallas /r/theticket /r/dallasstars /r/bostonbruins /r/patriots /r/tennesseetitans /r/nashvillesounds /r/predators /r/flyers /r/hockeyfandom /r/caps /r/nhl /r/detroitredwings /r/sabres /r/floridapanthers /r/habs /r/montrealimpact /r/alouettes /r/cfl /r/stadiumporn /r/nfl /r/madden /r/eurobowl /r/fantasyfb /r/fantasyfootball /r/49ers /r/footballgamefilm /r/footballstrategy /r/cfb /r/collegebaseball /r/mlbdraft /r/baseball /r/cubs /r/cardinals /r/saintlouisfc /r/stlouisblues /r/stlouis /r/stlouisbiking /r/mobicycling /r/bicycling /r/vintage_bicycles /r/miamibiking /r/fatbike /r/cycling /r/strava /r/phillycycling /r/wheelbuild /r/bikewrench /r/velo /r/bikepolo /r/bicycletouring /r/bicyclingcirclejerk /r/bikecommuting /r/ukbike /r/leedscycling /r/londoncycling /r/fixedgearbicycle /r/cyclingfashion /r/peloton /r/mtb /r/climbingporn /r/adrenaline /r/motocross /r/bmxracing /r/wake /r/snowboardingnoobs /r/freebord /r/snowboarding /r/sledding /r/outdoors /r/soposts /r/cordcutters /r/netflixviavpn /r/hulu /r/firetv /r/netflixbestof /r/raisinghope /r/madmen /r/earthsgottalent /r/bobsburgers /r/fringe /r/louie /r/theoriginals /r/iansomerhalder /r/kat_graham /r/indianaevans /r/janelevy /r/gagegolightly /r/sarahhyland /r/starlets /r/ninadobrev /r/kathrynnewton /r/arielwinter /r/ashleygreene /r/gentlemanboners /r/bandporn /r/musicpics /r/listentomusic /r/listentonew /r/subraddits /r/dtipics /r/damnthatsinteresting /r/interestingasfuck /r/unexpected /r/wtf /r/weird /r/animalsbeingderps /r/animalsbeingconfused /r/humansbeingbros /r/hulpdiensten /r/askle /r/protectandserve /r/good_cop_free_donut /r/bad_cop_follow_up /r/amifreetogo /r/copwatch /r/puppycide /r/underreportednews /r/mediaquotes /r/savedyouaclick /r/news /r/neutralnews /r/ask_politics /r/politicalopinions /r/gunsarecool /r/renewableenergy /r/web_design /r/somebodymakethis /r/somethingimade /r/crafts /r/kidscrafts /r/daddit /r/formulafeeders /r/boobsandbottles /r/csectioncentral /r/predaddit /r/dadbloggers /r/mombloggers /r/cutekids /r/bigfeats /r/scienceparents /r/lv9hrvv /r/sahp /r/tryingforababy /r/waiting_to_try /r/pcos /r/infertility /r/birthparents /r/tfabchartstalkers /r/firsttimettc /r/cautiousbtb /r/ttchealthy /r/xxketo /r/ketoscience /r/ketogains /r/leangains /r/gettingshredded /r/bulkorcut /r/gainit /r/decidingtobebetter /r/zen /r/buddhism /r/astralprojection /r/spirituality /r/hinduism /r/yoga /r/veganfitness /r/posture /r/health /r/ukhealthcare /r/pharmacy /r/nursing /r/doctorswithoutborders /r/humanitarian /r/assistance /r/paranormalhelp /r/paranormal /r/333 /r/askparanormal /r/intelligence /r/blackhat /r/netsec /r/technology /r/newyorkfuturistparty /r/rad_decentralization /r/massachusettsfp /r/opensource /r/alabamafp /r/darknetplan /r/torrents /r/i2p /r/privacy /r/badgovnofreedom /r/censorship /r/governmentoppression /r/descentintotyranny /r/wikileaks /r/dncleaks /r/hillaryforprison /r/the_donald /r/shitredditsays /r/srsmythos /r/srstrees /r/entwives /r/lesbients /r/actuallesbians /r/lesbianromance /r/lesbianerotica /r/l4l /r/dyke /r/ladyladyboners /r/bisexual /r/bisexy /r/biwomen /r/pansexual /r/genderqueer /r/transspace /r/lgbtlibrary /r/lgbtnews /r/dixiequeer /r/lgbt /r/sex /r/helpmecope /r/bpd /r/rapecounseling /r/trueoffmychest /r/suicidewatch /r/bipolarsos /r/bipolar /r/mentalpod /r/adhd /r/hoarding /r/declutter /r/thrifty /r/tinyhouses /r/leanfire /r/lowcar /r/zerowaste /r/simpleliving /r/livingofftheland /r/hunting /r/animaltracking /r/survival /r/vedc /r/4x4 /r/classiccars /r/automotivetraining /r/autodetailing /r/cartalk /r/mercedes_benz /r/motorsports /r/rallycross /r/worldrallycross /r/blancpain /r/nascarhometracks /r/arcaracing /r/stadiumsupertrucks /r/hydroplanes /r/sailing /r/boatbuilding /r/woodworking /r/cottage_industry /r/farriers /r/blacksmith /r/bladesmith /r/knives /r/swissarmyknives /r/switzerland /r/bern /r/sanktgallen /r/liechtenstein /r/erasmus /r/de /r/germanpuns /r/schland /r/rvacka /r/sloensko /r/slovakia /r/belarus /r/andorra /r/europe /r/hungary /r/francophonie /r/thailand /r/vietnam /r/vietnampics /r/travel /r/geography /r/climate /r/drought /r/waterutilities /r/drylands /r/irrigation /r/water /r/onthewaterfront /r/wetlands /r/marinelife /r/ocean /r/seasteading /r/frontier_colonization /r/arcology /r/retrofuturism /r/goldenpath /r/politics /r/moderationtheory /r/wdp /r/outoftheloop /r/wherearetheynow /r/entertainment /r/portlandia /r/themichaeljfoxshow /r/backtothefuture /r/bladerunner /r/filmnoir /r/vintageladyboners /r/classicfilms /r/foreignmovies /r/britishfilms /r/canadianfilm /r/newjerseyfilm /r/newzealandfilm /r/newzealand /r/wellington /r/nzmetahub /r/newzealandhistory /r/scottishhistory /r/scots /r/scottishproblems /r/britishproblems /r/swedishproblems /r/pinsamt /r/sweden /r/svenskpolitik /r/arbetarrorelsen /r/socialism /r/shittydebatecommunism /r/shittysocialscience /r/shittyideasforadmins /r/shittytheoryofreddit /r/shittybuildingporn /r/shittylifeprotips /r/shittyshitredditsays /r/shittyquotesporn /r/shittyama /r/askashittyparent /r/shittyprogramming /r/shittyaskalawyer /r/badlegaladvice /r/badscience /r/badeconomics /r/badhistory /r/historicalrage /r/metarage /r/ragenovels /r/fffffffuuuuuuuuuuuu /r/gaaaaaaayyyyyyyyyyyy /r/lgbteens /r/needafriend /r/rant /r/showerthoughts /r/markmywords /r/calledit /r/futurewhatif /r/sportswhatif /r/alternatehistory /r/maps /r/xkcd /r/kerbalspaceprogram /r/spacesimgames /r/eve /r/scifigaming /r/masseffect /r/imaginarymasseffect /r/imaginaryvampires /r/imaginarytowers /r/imaginarybestof /r/pics /r/spaceporn /r/auroraporn /r/weatherporn /r/sfwpornnetwork /r/fwepp /r/shittyearthporn /r/shittyaskreddit /r/askashittyphilosopher /r/shittyaskhistory /r/shittysuboftheweek /r/shittyaskcooking /r/shittyhub /r/coolguides /r/trendingsubreddits /r/monkslookingatbeer /r/beerporn /r/beerwithaview /r/shittybeerwithaview /r/shittyfoodporn /r/enttreats /r/trees /r/eldertrees /r/vaporents /r/crainn /r/eirhub /r/fairepublicofireland /r/gaeltacht /r/westmeath /r/tipperary /r/limerick /r/kilkenny /r/ireland /r/irejobs /r/resumes /r/careerguidance /r/flatone /r/centralillinois /r/chicubs /r/whitesox /r/minnesotatwins /r/minnesotavikings /r/greenbaypackers /r/jaguars /r/miamidolphins /r/nflroundtable /r/detroitlions /r/forhonor /r/vikingstv /r/hannibaltv /r/thepathhulu /r/batesmotel /r/hannibal /r/hitchcock /r/silentmoviegifs /r/moviestunts /r/bollywoodrealism /r/indiamain /r/indianews /r/asia /r/oldindia /r/explorepakistan /r/churchporn /r/medievalporn /r/castles /r/historyporn /r/thewaywewere /r/1970s /r/classicmovietrailers /r/warmovies /r/moviecritic /r/trailers /r/liveaction /r/animedeals /r/dbz /r/toonami /r/regularshow /r/thelifeandtimesoftim /r/aquajail /r/modern_family /r/supernatural /r/mishacollins /r/jaredpadalecki /r/fandomnatural /r/fangirls /r/trollxgirlgamers /r/trollmedia /r/trollgaming /r/trollmua /r/justtrollxthings /r/trollxmoms /r/trollmeta /r/trollychromosome /r/oney /r/askwomen /r/okcupid /r/relationship_advice /r/help /r/bugs /r/redditdev /r/enhancement /r/yoursub /r/horrorreviewed /r/truecreepy /r/metatruereddit /r/truepolitics /r/truehub /r/truegaming /r/askgames /r/freegamesonandroid /r/androidapps /r/apphookup /r/browsemyreddit /r/findareddit /r/trap /r/naut /r/militaryfinance /r/army /r/militarystories /r/nationalguard /r/uscg /r/usa /r/murica /r/lonestar /r/whataburger /r/fastfood /r/cocacola /r/kelloggs /r/kellawwggs /r/awwducational /r/marinebiologygifs /r/biologygifs /r/chemicalreactiongifs /r/homechemistry /r/holdmybeaker /r/holdmybeer /r/movieoftheday /r/sharknado /r/syfy /r/killjoys /r/theexpanse /r/truedetective /r/boardwalkempire /r/mobcast /r/1920s /r/1960s /r/beatles /r/minimaluminiumalism /r/ghostsrights /r/botsrights /r/totallynotrobots /r/robotics /r/manna /r/singularity /r/futureporn /r/singularitarianism /r/automate /r/darkfuturology /r/controlproblem /r/aiethics /r/ainothuman /r/neuraljokes /r/3amjokes /r/mommajokes /r/antijokes /r/absolutelynotme_irl /r/toomeirlformeirl /r/meirl /r/tree_irl /r/fishpost /r/mod_irl /r/pics_irl /r/teleshits /r/bitstrips /r/stopbullyingcomics /r/animalsbeingjerks /r/surfinganimals /r/unorthocat /r/catsubs /r/stuffoncats /r/catsinbusinessattire /r/catsinsinks /r/catsonkeyboards /r/mechanicalkeyboards /r/hackedgadgets /r/techsupportmacgyver /r/techsupport /r/programming /r/algorithms /r/datamining /r/datasets /r/wordcloud /r/datavizrequests /r/funnycharts /r/mapporn /r/mapmaking /r/worldbuilding /r/scificoncepts /r/apocalypseporn /r/imaginaryjerk /r/braveryjerk /r/circlejerk /r/politicaldiscussion /r/politicalfactchecking /r/moderatepolitics /r/truereddit /r/malelifestyle /r/fitness /r/swimming /r/freediving /r/bikeshop /r/climbing /r/climbharder /r/bouldering /r/climbergirls /r/womenshredders /r/skatergirls /r/girlsurfers /r/kiteboarding /r/longboarding /r/streetboarding /r/letsgosnowboarding /r/spliddit /r/backcountry /r/wjdbbl2 /r/caving /r/nationalparks /r/parkrangers /r/thesca /r/searchandrescue /r/wildernessbackpacking /r/campinggear /r/flashlight /r/camping /r/yellowstone /r/wmnf /r/pacificcresttrail /r/cdt /r/ultralight /r/backpacking /r/travelpartners /r/adventures /r/libraryofshadows /r/shortscarystories /r/shortscarystoriesooc /r/nosleepooc /r/nosleep</p>
</blockquote>
<h1 id="centrality"><a href="#centrality" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Centrality</h1>
<p>Centrality is anohter important topic in graph theory. Here's a brief introduction to centrality from <a href="https://en.wikipedia.org/wiki/Centrality" rel="nofollow noopener noreferrer" target="_blank">Wikipedia</a>:</p>
<blockquote>
<p>In graph theory and network analysis, indicators of centrality identify the most important vertices within a graph. Applications include identifying the most influential person(s) in a social network, key infrastructure nodes in the Internet or urban networks, and super-spreaders of disease.</p>
</blockquote>
<p>There are several different methods of measuring centrality in a graph. Here I use <code>eigenvector_centrality_numpy</code>, a function included in NetworkX. It takes in a graph and returns a dictionary with graph nodes as keys and node centrality as values.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>centrality <span class="token operator">=</span> nx<span class="token punctuation">.</span>eigenvector_centrality_numpy<span class="token punctuation">(</span>G1<span class="token punctuation">)</span>
</code></pre></div>
<p>Let's see which subreddit has the highest centrality:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">print</span> <span class="token builtin">max</span><span class="token punctuation">(</span>centrality<span class="token punctuation">,</span> key<span class="token operator">=</span>centrality<span class="token punctuation">.</span>get<span class="token punctuation">)</span><span class="token punctuation">,</span> centrality<span class="token punctuation">[</span><span class="token builtin">max</span><span class="token punctuation">(</span>centrality<span class="token punctuation">,</span> key<span class="token operator">=</span>centrality<span class="token punctuation">.</span>get<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/imaginarybattlefields 0.0721530261127
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token builtin">len</span><span class="token punctuation">(</span>centrality<span class="token punctuation">)</span> <span class="token operator">==</span> <span class="token builtin">len</span><span class="token punctuation">(</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>centrality<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>True
</code></pre></div>
<p>Since all of the centrality values are unique, we can look up nodes by their centrality values.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>subr_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
<span class="token keyword">for</span> node <span class="token keyword">in</span> centrality<span class="token punctuation">:</span>
    subr_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token punctuation">(</span>node<span class="token punctuation">,</span> centrality<span class="token punctuation">[</span>node<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

sorted_subr_list <span class="token operator">=</span> subr_list<span class="token punctuation">.</span>sort<span class="token punctuation">(</span>key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">sorted</span><span class="token punctuation">(</span>subr_list<span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> x<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">200</span><span class="token punctuation">]</span><span class="token punctuation">:</span> <span class="token keyword">print</span> x<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/imaginarybattlefields /r/imaginarycityscapes /r/imaginarywastelands /r/imaginarywildlands /r/imaginaryleviathans /r/imaginarydragons /r/imaginarystarscapes /r/imaginarywesteros /r/imaginaryartifacts /r/imaginaryangels /r/imaginarymaps /r/imaginarybehemoths /r/imaginarydemons /r/imaginaryelves /r/imaginarycentaurs /r/imaginaryfuturewar /r/imaginarysoldiers /r/imaginaryhistory /r/imaginaryarmor /r/imaginarystarships /r/imaginarynetwork /r/imaginaryjedi /r/imaginarydinosaurs /r/imaginarysteampunk /r/imaginarycyberpunk /r/imaginaryarchers /r/imaginaryvehicles /r/imaginaryanime /r/imaginaryfallout /r/imaginaryastronauts /r/imaginarymusic /r/imaginaryfactories /r/imaginaryequestria /r/imaginarywarships /r/imaginaryazeroth /r/imaginaryarrakis /r/imaginarydisney /r/imaginarypolitics /r/imaginaryhorrors /r/imaginarywinterscapes /r/imaginaryseascapes /r/imaginarypirates /r/imaginarywarriors /r/imaginarymiddleearth /r/imaginarygallifrey /r/imaginarymechs /r/imaginarypropaganda /r/imaginarymerfolk /r/imaginaryvikings /r/imaginaryundead /r/imaginarybeasts /r/imaginarymutants /r/imaginaryruins /r/imaginarytamriel /r/imaginaryforests /r/imaginaryelementals /r/imaginaryskyscapes /r/imaginarymonuments /r/imaginarywaterfalls /r/imaginaryworlds /r/imaginarywizards /r/imaginaryinteriors /r/imaginaryhogwarts /r/imaginarytowers /r/imaginaryarchitecture /r/imaginaryweaponry /r/imaginarygaming /r/imaginarycastles /r/imaginaryrobotics /r/imaginarybooks /r/imaginarygnomes /r/imaginaryvillages /r/imaginarydeserts /r/imaginarywerewolves /r/imaginarydieselpunk /r/imaginaryvampires /r/imaginaryadrenaline /r/imaginarykanto /r/imaginarynatives /r/imaginaryrivers /r/imaginarytemples /r/imaginaryassassins /r/imaginaryvolcanoes /r/imaginaryclerics /r/imaginaryprisons /r/imaginarygiants /r/imaginarycowboys /r/imaginaryhumans /r/imaginarydwarves /r/imaginarycaves /r/imaginarytrolls /r/imaginarywalls /r/imaginarylakes /r/imaginarywitches /r/imaginaryorcs /r/imaginarycanyons /r/imaginaryasylums /r/imaginaryimmortals /r/imaginaryaliens /r/imaginarynobles /r/imaginaryspirits /r/imaginaryaetherpunk /r/imaginarytrees /r/imaginaryislands /r/imaginaryninjas /r/imaginaryscience /r/imaginarymountains /r/imaginaryknights /r/imaginarygoblins /r/imaginaryfaeries /r/imaginarygotham /r/imaginarycybernetics /r/imaginaryooo /r/imaginaryderelicts /r/imaginaryfood /r/imaginaryworldeaters /r/imaginarymindscapes /r/imaginaryaww /r/imaginarymarvel /r/imaginaryweather /r/imaginarynewnewyork /r/imaginaryspidey /r/imaginaryautumnscapes /r/imaginarywarhammer /r/imaginaryfeels /r/imaginarywitcher /r/imaginaryvessels /r/imaginarytaverns /r/imaginarybestof /r/imaginaryairships /r/imaginaryportals /r/imaginaryfashion /r/imaginarylovers /r/imaginarydc /r/imaginaryanimals /r/imaginaryhellscapes /r/imaginarycolorscapes /r/imaginarymonstergirls /r/imaginaryswamps /r/imaginarymythology /r/imaginaryscholars /r/imaginaryladyboners /r/imaginaryfuturism /r/imaginaryaviation /r/imaginarypathways /r/imaginarygatherings /r/imaginarybodyscapes /r/imaginaryoverwatch /r/imaginarydwellings /r/imaginarystephenking /r/specart /r/inegentlemanboners /r/comicbookart /r/imaginarymasseffect /r/imaginaryhalo /r/imaginaryjerk /r/backgroundart /r/futureporn /r/imaginarywallpapers /r/imaginaryfamilies /r/imaginarylibraries /r/imaginaryturtleworlds /r/imaginarydesigns /r/wallpapers /r/apocalypseporn /r/comicbookporn /r/isometric /r/imaginarybakerst /r/imaginaryverse /r/imaginarysunnydale /r/imaginaryfederation /r/imaginarysanctuary /r/starshipporn /r/imaginarystarcraft /r/imaginaryoldkingdom /r/imaginarynarnia /r/imaginarycybertron /r/gameworlds /r/imaginarycarnage /r/imaginaryboners /r/icandrawthat /r/imaginarycosmere /r/imaginaryaperture /r/armoredwomen /r/imaginarywtf /r/unusualart /r/imaginaryblueprints /r/alternativeart /r/sympatheticmonsters /r/adorabledragons /r/imaginarysummerscapes /r/imaginarygayboners /r/imaginarystash /r/artistoftheday /r/imaginaryglaciers /r/imaginaryhybrids /r/imaginaryadventurers /r/imaginarymetropolis /r/craftsoficeandfire /r/popartnouveau
</code></pre></div>
<p>There seems to be a network of "imaginary" subreddits that have the highest centrality. The members of this network probably all link to themselves as well as many other subreddits as the "imaginary" topics span a wide range content. This network may be drowning out other nodes that would otherwise have a high centrality relative to the rest of the subreddits. It might be interesting to eliminate these nodes from the graph and recalculate centrality. Let's look at the distribution of centrality values:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>_ <span class="token operator">=</span> plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">sorted</span><span class="token punctuation">(</span>centrality<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> reverse<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token number">1000</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
_ <span class="token operator">=</span> plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Subreddit Centrality (top 1000)'</span><span class="token punctuation">)</span>
_ <span class="token operator">=</span> plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Rank'</span><span class="token punctuation">)</span>
_ <span class="token operator">=</span> plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Centrality'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>savefig<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>expanduser<span class="token punctuation">(</span><span class="token string">'~/Documents/GitHub/briancaffey.github.io/img/subreddit_graph/centrality.png'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div>
<p><img alt="png" src="/img/subreddit_graph/centrality.png"></p>
<h1 id="connectedness"><a href="#connectedness" aria-hidden="true" tabindex="-1"><span class="icon icon-link"></span></a>Connectedness</h1>
<p>Let's take a look at the graph as a whole. One thing I'm not sure of is whether or not the entire graph is connected. This means that any node can be reached from any other node. Since we constructed the graph from 49 unrelated nodes, it is possible that the graph is unconnected. This would mean that one or more of the default subreddits and its subreddits is not connected with the rest of the graph. In searching for the shortest path I did not come across any pairs of nodes that did not have a path between themselves. I wouldn't be surprised if there are a handful of nodes that stand on their own.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token comment">#size of graph: nodes and edges (or, subreddits and connecting links)</span>
<span class="token keyword">print</span> <span class="token string">"Our graph has "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>nx<span class="token punctuation">.</span>number_of_nodes<span class="token punctuation">(</span>G1<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' nodes and '</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>nx<span class="token punctuation">.</span>number_of_edges<span class="token punctuation">(</span>G1<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">' edges.'</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>Our graph has 29854 nodes and 149491 edges.
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">print</span> <span class="token string">"True of False: our graph is connected... "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>nx<span class="token punctuation">.</span>is_connected<span class="token punctuation">(</span>G1<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'!'</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>True of False: our graph is connected... False!
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code>Gc <span class="token operator">=</span> <span class="token builtin">max</span><span class="token punctuation">(</span>nx<span class="token punctuation">.</span>connected_component_subgraphs<span class="token punctuation">(</span>G1<span class="token punctuation">)</span><span class="token punctuation">,</span> key<span class="token operator">=</span><span class="token builtin">len</span><span class="token punctuation">)</span>
<span class="token keyword">print</span> <span class="token string">"The largest connected component subgraph has "</span> <span class="token operator">+</span> <span class="token builtin">str</span><span class="token punctuation">(</span>nx<span class="token punctuation">.</span>number_of_nodes<span class="token punctuation">(</span>Gc<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">" nodes. "</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>The largest connected component subgraph has 29840 nodes.
</code></pre></div>
<p>There are 14 nodes that are not connected to the main connected component. Let's list them.</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">for</span> x <span class="token keyword">in</span> <span class="token builtin">list</span><span class="token punctuation">(</span><span class="token builtin">set</span><span class="token punctuation">(</span>nx<span class="token punctuation">.</span>to_dict_of_lists<span class="token punctuation">(</span>G1<span class="token punctuation">,</span> nodelist<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">-</span> <span class="token builtin">set</span><span class="token punctuation">(</span>nx<span class="token punctuation">.</span>to_dict_of_lists<span class="token punctuation">(</span>Gc<span class="token punctuation">,</span> nodelist<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">.</span>keys<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token keyword">print</span> x<span class="token punctuation">,</span>
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>/r/spacediscussions /r/wtfit.gif /r/space. /r/subreddit_graph /r/vidalia /r/listentothis. /r/history. /r/all. /r/ghostdriver /r/personalfinance. /r/toombscounty /r/gaming /r/science /r/books.
</code></pre></div>
<p>Some of the large communities on reddit include /r/books, /r/gaming and /r/science. These subreddits list related subreddits on separate wiki pages since there are many related subreddits for each one. They were most likely all captured in the subsequent levels of the graph, but they also did not link back to /r/science. Here's an example:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">for</span> x <span class="token keyword">in</span> master_df_u<span class="token punctuation">.</span>loc<span class="token punctuation">[</span>master_df_u<span class="token punctuation">.</span>subreddit<span class="token operator">==</span><span class="token string">'/r/physics'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>related<span class="token punctuation">:</span> <span class="token keyword">print</span> x
</code></pre></div>
<div class="nuxt-content-highlight"><pre class="line-numbers language-text"><code>['/r/physicsjokes', '/r/gradadmissions', '/r/homeworkhelp', '/r/scienceimages', '/r/askacademia', '/r/physicsgifs', '/r/physicsstudents', '/r/gradschool', '/r/askphysics', '/r/physics']
</code></pre></div>
<p>I've got some additional ideas to explore in another post on this topic, such as finding cliques and maximual cliques, and doing graph visualizations with D3.js. If you are interested in playing with the data, you can clone <a href="https://github.com/briancaffey/reddit-graph-analysis" rel="nofollow noopener noreferrer" target="_blank">my GitHub repo</a> and load the pickled DataFrames like this:</p>
<div class="nuxt-content-highlight"><pre class="line-numbers language-python"><code><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd
df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_pickle<span class="token punctuation">(</span><span class="token string">'pickle/master_df.p'</span><span class="token punctuation">)</span>
</code></pre></div></div> <div class="text-center pb-4 pt-8"><button class="mc-btn rounded py-1 px-2">
        Show Disqus Comments 💬
      </button></div> <!----> <h1></h1></div></article> <div class="mx-auto max-w-6xl p-4 lg:px-16 text-center" data-v-9723a4c2><hr class="mt-4" data-v-9723a4c2> <div class="mx-auto py-4" data-v-9723a4c2><div class="pb-4" data-v-9723a4c2>
      Join my mailing list to get updated whenever I publish a new article.
    </div> <div class="mx-auto" data-v-c067421e data-v-9723a4c2><div id="mc_embed_signup" class="mx-auto w-full md:w-1/2" data-v-c067421e><form id="mc-embedded-subscribe-form" action="https://github.us2.list-manage.com/subscribe/post?u=43a795784ca963e25903a0da6&id=9937fe4fc5" method="post" name="mc-embedded-subscribe-form" target="_blank" novalidate class="validate" data-v-c067421e><div id="mc_embed_signup_scroll" class="grid grid-cols-1 sm:grid-cols-2 gap-4 items-center" data-v-c067421e><input id="mce-EMAIL" type="email" name="EMAIL" placeholder="Enter your email address" class="rounded mc text-center" data-v-c067421e> <div aria-hidden="true" style="position:absolute;left:-5000px" data-v-c067421e><input name="b_43a795784ca963e25903a0da6_9937fe4fc5" tabindex="-1" data-v-c067421e></div> <div data-v-c067421e><input id="mc-embedded-subscribe" type="submit" name="subscribe" value="Subscribe" class="mc-btn rounded px-2 py-1 w-full" data-v-c067421e></div></div></form></div></div></div> <hr data-v-9723a4c2> <div class="py-4" data-v-9723a4c2>Thanks for checking out my site!</div> <div class="pb-4" data-v-9723a4c2>© 2020 Brian Caffey</div></div></div></div></div><script defer src="/_nuxt/static/1612398539/2017/03/03/graph_subreddit.html/state.js"></script><script src="/_nuxt/eff76a4.js" defer></script><script src="/_nuxt/64fe595.js" defer></script><script src="/_nuxt/35383e5.js" defer></script><script src="/_nuxt/e161084.js" defer></script><script src="/_nuxt/223edee.js" defer></script>
  </body>
</html>
